---
name: open-webui
description: Use this skill when working with Open WebUI - a user-friendly web interface for running LLMs locally with features like RAG, API endpoints, chat completions, and model management
---

# Open-Webui Skill

Comprehensive assistance with open-webui development, generated from official documentation.

## When to Use This Skill

This skill should be triggered when:
- Working with open-webui
- Asking about open-webui features or APIs
- Implementing open-webui solutions
- Debugging open-webui code
- Learning open-webui best practices

## Quick Reference

### Common Patterns

**Pattern 1:** API EndpointsThis guide provides essential information on how to interact with the API endpoints effectively to achieve seamless integration and automation using our models. Please note that this is an experimental setup and may undergo future updates for enhancement. Authentication‚Äã To ensure secure access to the API, authentication is required üõ°Ô∏è. You can authenticate your API requests using the Bearer Token mechanism. Obtain your API key from Settings > Account in the Open WebUI, or alternatively, use a JWT (JSON Web Token) for authentication. Swagger Documentation Links‚Äã importantMake sure to set the ENV environment variable to dev in order to access the Swagger documentation for any of these services. Without this configuration, the documentation will not be available. Access detailed API documentation for different services provided by Open WebUI: ApplicationDocumentation PathMain/docs Notable API Endpoints‚Äã üìú Retrieve All Models‚Äã Endpoint: GET /api/models Description: Fetches all models created or added via Open WebUI. Example: curl -H "Authorization: Bearer YOUR_API_KEY" http://localhost:3000/api/models üí¨ Chat Completions‚Äã Endpoint: POST /api/chat/completions Description: Serves as an OpenAI API compatible chat completion endpoint for models on Open WebUI including Ollama models, OpenAI models, and Open WebUI Function models. Curl Example: curl -X POST http://localhost:3000/api/chat/completions \-H "Authorization: Bearer YOUR_API_KEY" \-H "Content-Type: application/json" \-d '{ "model": "llama3.1", "messages": [ { "role": "user", "content": "Why is the sky blue?" } ] }' Python Example: import requestsdef chat_with_model(token): url = 'http://localhost:3000/api/chat/completions' headers = { 'Authorization': f'Bearer {token}', 'Content-Type': 'application/json' } data = { "model": "granite3.1-dense:8b", "messages": [ { "role": "user", "content": "Why is the sky blue?" } ] } response = requests.post(url, headers=headers, json=data) return response.json() ü¶ô Ollama API Proxy Support‚Äã If you want to interact directly with Ollama models‚Äîincluding for embedding generation or raw prompt streaming‚ÄîOpen WebUI offers a transparent passthrough to the native Ollama API via a proxy route. Base URL: /ollama/<api> Reference: Ollama API Documentation üîÅ Generate Completion (Streaming)‚Äã curl http://localhost:3000/ollama/api/generate \ -H "Authorization: Bearer YOUR_API_KEY" \ -H "Content-Type: application/json" \ -d '{ "model": "llama3.2", "prompt": "Why is the sky blue?"}' üì¶ List Available Models‚Äã curl http://localhost:3000/ollama/api/tags \ -H "Authorization: Bearer YOUR_API_KEY" üß† Generate Embeddings‚Äã curl -X POST http://localhost:3000/ollama/api/embed \ -H "Authorization: Bearer YOUR_API_KEY" \ -H "Content-Type: application/json" \ -d '{ "model": "llama3.2", "input": ["Open WebUI is great!", "Let'\''s generate embeddings."]}' infoWhen using the Ollama Proxy endpoints, you must include the Content-Type: application/json header for POST requests, or the API may fail to parse the body. Authorization headers are also required if your instance is secured. This is ideal for building search indexes, retrieval systems, or custom pipelines using Ollama models behind the Open WebUI. üß© Retrieval Augmented Generation (RAG)‚Äã The Retrieval Augmented Generation (RAG) feature allows you to enhance responses by incorporating data from external sources. Below, you will find the methods for managing files and knowledge collections via the API, and how to use them in chat completions effectively. Uploading Files‚Äã To utilize external data in RAG responses, you first need to upload the files. The content of the uploaded file is automatically extracted and stored in a vector database. Endpoint: POST /api/v1/files/ Curl Example: curl -X POST -H "Authorization: Bearer YOUR_API_KEY" -H "Accept: application/json" \-F "file=@/path/to/your/file" http://localhost:3000/api/v1/files/ Python Example: import requestsdef upload_file(token, file_path): url = 'http://localhost:3000/api/v1/files/' headers = { 'Authorization': f'Bearer {token}', 'Accept': 'application/json' } files = {'file': open(file_path, 'rb')} response = requests.post(url, headers=headers, files=files) return response.json() Adding Files to Knowledge Collections‚Äã After uploading, you can group files into a knowledge collection or reference them individually in chats. Endpoint: POST /api/v1/knowledge/{id}/file/add Curl Example: curl -X POST http://localhost:3000/api/v1/knowledge/{knowledge_id}/file/add \-H "Authorization: Bearer YOUR_API_KEY" \-H "Content-Type: application/json" \-d '{"file_id": "your-file-id-here"}' Python Example: import requestsdef add_file_to_knowledge(token, knowledge_id, file_id): url = f'http://localhost:3000/api/v1/knowledge/{knowledge_id}/file/add' headers = { 'Authorization': f'Bearer {token}', 'Content-Type': 'application/json' } data = {'file_id': file_id} response = requests.post(url, headers=headers, json=data) return response.json() Using Files and Collections in Chat Completions‚Äã You can reference both individual files or entire collections in your RAG queries for enriched responses. Using an Individual File in Chat Completions‚Äã This method is beneficial when you want to focus the chat model's response on the content of a specific file. Endpoint: POST /api/chat/completions Curl Example: curl -X POST http://localhost:3000/api/chat/completions \-H "Authorization: Bearer YOUR_API_KEY" \-H "Content-Type: application/json" \-d '{ "model": "gpt-4-turbo", "messages": [ {"role": "user", "content": "Explain the concepts in this document."} ], "files": [ {"type": "file", "id": "your-file-id-here"} ] }' Python Example: import requestsdef chat_with_file(token, model, query, file_id): url = 'http://localhost:3000/api/chat/completions' headers = { 'Authorization': f'Bearer {token}', 'Content-Type': 'application/json' } payload = { 'model': model, 'messages': [{'role': 'user', 'content': query}], 'files': [{'type': 'file', 'id': file_id}] } response = requests.post(url, headers=headers, json=payload) return response.json() Using a Knowledge Collection in Chat Completions‚Äã Leverage a knowledge collection to enhance the response when the inquiry may benefit from a broader context or multiple documents. Endpoint: POST /api/chat/completions Curl Example: curl -X POST http://localhost:3000/api/chat/completions \-H "Authorization: Bearer YOUR_API_KEY" \-H "Content-Type: application/json" \-d '{ "model": "gpt-4-turbo", "messages": [ {"role": "user", "content": "Provide insights on the historical perspectives covered in the collection."} ], "files": [ {"type": "collection", "id": "your-collection-id-here"} ] }' Python Example: import requestsdef chat_with_collection(token, model, query, collection_id): url = 'http://localhost:3000/api/chat/completions' headers = { 'Authorization': f'Bearer {token}', 'Content-Type': 'application/json' } payload = { 'model': model, 'messages': [{'role': 'user', 'content': query}], 'files': [{'type': 'collection', 'id': collection_id}] } response = requests.post(url, headers=headers, json=payload) return response.json() These methods enable effective utilization of external knowledge via uploaded files and curated knowledge collections, enhancing chat applications' capabilities using the Open WebUI API. Whether using files individually or within collections, you can customize the integration based on your specific needs. Advantages of Using Open WebUI as a Unified LLM Provider‚Äã Open WebUI offers a myriad of benefits, making it an essential tool for developers and businesses alike: Unified Interface: Simplify your interactions with different LLMs through a single, integrated platform. Ease of Implementation: Quick start integration with comprehensive documentation and community support. By following these guidelines, you can swiftly integrate and begin utilizing the Open WebUI API. Should you encounter any issues or have questions, feel free to reach out through our Discord Community or consult the FAQs. Happy coding! üåü

```
ENV
```

**Pattern 2:** Example:

```
curl -H "Authorization: Bearer YOUR_API_KEY" http://localhost:3000/api/models
```

**Pattern 3:** Curl Example:

```
curl -X POST http://localhost:3000/api/chat/completions \-H "Authorization: Bearer YOUR_API_KEY" \-H "Content-Type: application/json" \-d '{      "model": "llama3.1",      "messages": [        {          "role": "user",          "content": "Why is the sky blue?"        }      ]    }'
```

**Pattern 4:** Curl Example:

```
curl -X POST -H "Authorization: Bearer YOUR_API_KEY" -H "Accept: application/json" \-F "file=@/path/to/your/file" http://localhost:3000/api/v1/files/
```

**Pattern 5:** Backend-Controlled, UI-Compatible API FlowwarningThis tutorial is a community contribution and is not supported by the Open WebUI team. It serves only as a demonstration on how to customize Open WebUI for your specific use case. Want to contribute? Check out the contributing tutorial. Backend-Controlled, UI-Compatible API Flow This tutorial demonstrates how to implement server-side orchestration of Open WebUI conversations while ensuring that assistant replies appear properly in the frontend UI. This approach requires zero frontend involvement and allows complete backend control over the chat flow. This tutorial has been verified to work with Open WebUI version v0.6.15. Future versions may introduce changes in behavior or API structure. Prerequisites‚Äã Before following this tutorial, ensure you have: A running Open WebUI instance Valid API authentication token Access to the Open WebUI backend APIs Basic understanding of REST APIs and JSON Command-line tools: curl, jq (optional for JSON parsing) Overview‚Äã This tutorial describes a comprehensive 7-step process that enables server-side orchestration of Open WebUI conversations while ensuring that assistant replies appear properly in the frontend UI. Process Flow‚Äã The essential steps are: Create a new chat with a user message - Initialize the conversation with the user's input Enrich the chat response with an assistant message - Add assistant message to the response object in memory Update chat with assistant message - Send the enriched chat state to the server Trigger the assistant completion - Generate the actual AI response (with optional knowledge integration) Wait for response completion - Monitor the assistant response until fully generated Complete the assistant message - Mark the response as completed Fetch and process the final chat - Retrieve and parse the completed conversation This enables server-side orchestration while still making replies show up in the frontend UI exactly as if they were generated through normal user interaction. Implementation Guide‚Äã Critical Step: Enrich Chat Response with Assistant Message‚Äã The assistant message needs to be added to the chat response object in memory as a critical prerequisite before triggering the completion. This step is essential because the Open WebUI frontend expects assistant messages to exist in a specific structure. The assistant message must appear in both locations: chat.messages[] - The main message array chat.history.messages[<assistantId>] - The indexed message history Expected structure of the assistant message: { "id": "<uuid>", "role": "assistant", "content": "", "parentId": "<user-msg-id>", "modelName": "gpt-4o", "modelIdx": 0, "timestamp": "<currentTimestamp>"} Without this enrichment, the assistant's response will not appear in the frontend interface, even if the completion is successful. Step-by-Step Implementation‚Äã Step 1: Create Chat with User Message‚Äã This starts the chat and returns a chatId that will be used in subsequent requests. curl -X POST https://<host>/api/v1/chats/new \ -H "Authorization: Bearer <token>" \ -H "Content-Type: application/json" \ -d '{ "chat": { "title": "New Chat", "models": ["gpt-4o"], "messages": [ { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] } ], "history": { "current_id": "user-msg-id", "messages": { "user-msg-id": { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] } } } } }' Step 2: Enrich Chat Response with Assistant Message‚Äã Add the assistant message to the chat response object in memory. Note that this can be combined with Step 1 by including the assistant message in the initial chat creation: // Example implementation in Javapublic void enrichChatWithAssistantMessage(OWUIChatResponse chatResponse, String model) { OWUIMessage assistantOWUIMessage = buildAssistantMessage(chatResponse, model, "assistant", ""); assistantOWUIMessage.setParentId(chatResponse.getChat().getMessages().get(0).getId()); chatResponse.getChat().getMessages().add(assistantOWUIMessage); chatResponse.getChat().getHistory().getMessages().put(assistantOWUIMessage.getId(), assistantOWUIMessage);} noteNote: This step can be performed in memory on the response object, or combined with Step 1 by including both user and empty assistant messages in the initial chat creation. Step 3: Update Chat with Assistant Message‚Äã Send the enriched chat state containing both user and assistant messages to the server: curl -X POST https://<host>/api/v1/chats/<chatId> \ -H "Authorization: Bearer <token>" \ -H "Content-Type: application/json" \ -d '{ "chat": { "id": "<chatId>", "title": "New Chat", "models": ["gpt-4o"], "messages": [ { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] }, { "id": "assistant-msg-id", "role": "assistant", "content": "", "parentId": "user-msg-id", "modelName": "gpt-4o", "modelIdx": 0, "timestamp": 1720000001000 } ], "history": { "current_id": "assistant-msg-id", "messages": { "user-msg-id": { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] }, "assistant-msg-id": { "id": "assistant-msg-id", "role": "assistant", "content": "", "parentId": "user-msg-id", "modelName": "gpt-4o", "modelIdx": 0, "timestamp": 1720000001000 } } } } }' Step 4: Trigger Assistant Completion‚Äã Generate the actual AI response using the completion endpoint: curl -X POST https://<host>/api/chat/completions \ -H "Authorization: Bearer <token>" \ -H "Content-Type: application/json" \ -d '{ "chat_id": "<chatId>", "id": "assistant-msg-id", "messages": [ { "role": "user", "content": "Hi, what is the capital of France?" } ], "model": "gpt-4o", "stream": true, "background_tasks": { "title_generation": true, "tags_generation": false, "follow_up_generation": false }, "features": { "code_interpreter": false, "web_search": false, "image_generation": false, "memory": false }, "variables": { "{{USER_NAME}}": "", "{{USER_LANGUAGE}}": "en-US", "{{CURRENT_DATETIME}}": "2025-07-14T12:00:00Z", "{{CURRENT_TIMEZONE}}": "Europe" }, "session_id": "session-id" }' Step 4.1: Trigger Assistant Completion with Knowledge Integration (RAG)‚Äã For advanced use cases involving knowledge bases or document collections, include knowledge files in the completion request: curl -X POST https://<host>/api/chat/completions \ -H "Authorization: Bearer <token>" \ -H "Content-Type: application/json" \ -d '{ "chat_id": "<chatId>", "id": "assistant-msg-id", "messages": [ { "role": "user", "content": "Hi, what is the capital of France?" } ], "model": "gpt-4o", "stream": true, "files": [ { "id": "knowledge-collection-id", "type": "collection", "status": "processed" } ], "background_tasks": { "title_generation": true, "tags_generation": false, "follow_up_generation": false }, "features": { "code_interpreter": false, "web_search": false, "image_generation": false, "memory": false }, "variables": { "{{USER_NAME}}": "", "{{USER_LANGUAGE}}": "en-US", "{{CURRENT_DATETIME}}": "2025-07-14T12:00:00Z", "{{CURRENT_TIMEZONE}}": "Europe" }, "session_id": "session-id" }' Step 5: Wait for Assistant Response Completion‚Äã Assistant responses can be handled in two ways depending on your implementation needs: Option A: Stream Processing (Recommended)‚Äã If using stream: true in the completion request, you can process the streamed response in real-time and wait for the stream to complete. This is the approach used by the OpenWebUI web interface and provides immediate feedback. Option B: Polling Approach‚Äã For implementations that cannot handle streaming, poll the chat endpoint until the response is ready. Use a retry mechanism with exponential backoff: // Example implementation in Java@Retryable( retryFor = AssistantResponseNotReadyException.class, maxAttemptsExpression = "#{${webopenui.retries:50}}", backoff = @Backoff(delayExpression = "#{${webopenui.backoffmilliseconds:2000}}"))public String getAssistantResponseWhenReady(String chatId, ChatCompletedRequest chatCompletedRequest) { OWUIChatResponse response = owuiService.fetchFinalChatResponse(chatId); Optional<OWUIMessage> assistantMsg = extractAssistantResponse(response); if (assistantMsg.isPresent() && !assistantMsg.get().getContent().isBlank()) { owuiService.completeAssistantMessage(chatCompletedRequest); return assistantMsg.get().getContent(); } throw new AssistantResponseNotReadyException("Assistant response not ready yet for chatId: " + chatId);} For manual polling, you can use: # Poll every few seconds until assistant content is populatedwhile true; do response=$(curl -s -X GET https://<host>/api/v1/chats/<chatId> \ -H "Authorization: Bearer <token>") # Check if assistant message has content (response is ready) if echo "$response" | jq '.chat.messages[] | select(.role=="assistant" and .id=="assistant-msg-id") | .content' | grep -v '""' > /dev/null; then echo "Assistant response is ready!" break fi echo "Waiting for assistant response..." sleep 2done Step 6: Complete Assistant Message‚Äã Once the assistant response is ready, mark it as completed: curl -X POST https://<host>/api/chat/completed \ -H "Authorization: Bearer <token>" \ -H "Content-Type: application/json" \ -d '{ "chat_id": "<chatId>", "id": "assistant-msg-id", "session_id": "session-id", "model": "gpt-4o" }' Step 7: Fetch Final Chat‚Äã Retrieve the completed conversation: curl -X GET https://<host>/api/v1/chats/<chatId> \ -H "Authorization: Bearer <token>" Additional API Endpoints‚Äã Fetch Knowledge Collection‚Äã Retrieve knowledge base information for RAG integration: curl -X GET https://<host>/api/v1/knowledge/<knowledge-id> \ -H "Authorization: Bearer <token>" Fetch Model Information‚Äã Get details about a specific model: curl -X GET https://<host>/api/v1/models/model?id=<model-name> \ -H "Authorization: Bearer <token>" Send Additional Messages to Chat‚Äã For multi-turn conversations, you can send additional messages to an existing chat: curl -X POST https://<host>/api/v1/chats/<chatId> \ -H "Authorization: Bearer <token>" \ -H "Content-Type: application/json" \ -d '{ "chat": { "id": "<chatId>", "messages": [ { "id": "new-user-msg-id", "role": "user", "content": "Can you tell me more about this?", "timestamp": 1720000002000, "models": ["gpt-4o"] } ], "history": { "current_id": "new-user-msg-id", "messages": { "new-user-msg-id": { "id": "new-user-msg-id", "role": "user", "content": "Can you tell me more about this?", "timestamp": 1720000002000, "models": ["gpt-4o"] } } } } }' Response Processing‚Äã Parsing Assistant Responses‚Äã Assistant responses may be wrapped in markdown code blocks. Here's how to clean them: # Example raw response from assistantraw_response='```json{ "result": "The capital of France is Paris.", "confidence": 0.99}```'# Clean the response (remove markdown wrappers)cleaned_response=$(echo "$raw_response" | sed 's/^```json//' | sed 's/```$//' | sed 's/^[[:space:]]*//' | sed 's/[[:space:]]*$//')echo "$cleaned_response" | jq '.' This cleaning process handles: Removal of ````json` prefix Removal of ```` suffix Trimming whitespace JSON validation API Reference‚Äã DTO Structures‚Äã Chat DTO (Complete Structure)‚Äã { "id": "chat-uuid-12345", "title": "New Chat", "models": ["gpt-4o"], "files": [], "tags": [ { "id": "tag-id", "name": "important", "color": "#FF5733" } ], "params": { "temperature": 0.7, "max_tokens": 1000 }, "timestamp": 1720000000000, "messages": [ { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] }, { "id": "assistant-msg-id", "role": "assistant", "content": "", "parentId": "user-msg-id", "modelName": "gpt-4o", "modelIdx": 0, "timestamp": 1720000001000 } ], "history": { "current_id": "assistant-msg-id", "messages": { "user-msg-id": { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] }, "assistant-msg-id": { "id": "assistant-msg-id", "role": "assistant", "content": "", "parentId": "user-msg-id", "modelName": "gpt-4o", "modelIdx": 0, "timestamp": 1720000001000 } } }, "currentId": "assistant-msg-id"} ChatCompletionsRequest DTO‚Äã { "chat_id": "chat-uuid-12345", "id": "assistant-msg-id", "messages": [ { "role": "user", "content": "Hi, what is the capital of France?" } ], "model": "gpt-4o", "stream": true, "background_tasks": { "title_generation": true, "tags_generation": false, "follow_up_generation": false }, "features": { "code_interpreter": false, "web_search": false, "image_generation": false, "memory": false }, "variables": { "{{USER_NAME}}": "", "{{USER_LANGUAGE}}": "en-US", "{{CURRENT_DATETIME}}": "2025-07-14T12:00:00Z", "{{CURRENT_TIMEZONE}}": "Europe" }, "session_id": "session-uuid-67890", "filter_ids": [], "files": [ { "id": "knowledge-collection-id", "type": "collection", "status": "processed" } ]} ChatCompletedRequest DTO‚Äã { "model": "gpt-4o", "chat_id": "chat-uuid-12345", "id": "assistant-msg-id", "session_id": "session-uuid-67890", "messages": [ { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] }, { "id": "assistant-msg-id", "role": "assistant", "content": "The capital of France is Paris.", "parentId": "user-msg-id", "modelName": "gpt-4o", "modelIdx": 0, "timestamp": 1720000001000 } ]} ChatCompletionMessage DTO‚Äã { "role": "user", "content": "Hi, what is the capital of France?"} History DTO‚Äã { "current_id": "assistant-msg-id", "messages": { "user-msg-id": { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] }, "assistant-msg-id": { "id": "assistant-msg-id", "role": "assistant", "content": "The capital of France is Paris.", "parentId": "user-msg-id", "modelName": "gpt-4o", "modelIdx": 0, "timestamp": 1720000001000 } }} Message DTO (Complete Structure)‚Äã { "id": "msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"]} { "id": "assistant-msg-id", "role": "assistant", "content": "The capital of France is Paris.", "parentId": "user-msg-id", "modelName": "gpt-4o", "modelIdx": 0, "timestamp": 1720000001000} Response Examples‚Äã Create Chat Response‚Äã { "success": true, "chat": { "id": "chat-uuid-12345", "title": "New Chat", "models": ["gpt-4o"], "files": [], "tags": [], "params": {}, "timestamp": 1720000000000, "messages": [ { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] } ], "history": { "current_id": "user-msg-id", "messages": { "user-msg-id": { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] } } }, "currentId": "user-msg-id" }} Final Chat Response (After Completion)‚Äã { "id": "chat-uuid-12345", "title": "Capital of France Discussion", "models": ["gpt-4o"], "files": [], "tags": [ { "id": "auto-tag-1", "name": "geography", "color": "#4CAF50" } ], "params": {}, "timestamp": 1720000000000, "messages": [ { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] }, { "id": "assistant-msg-id", "role": "assistant", "content": "The capital of France is Paris. Paris is not only the capital but also the most populous city in France, known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral.", "parentId": "user-msg-id", "modelName": "gpt-4o", "modelIdx": 0, "timestamp": 1720000001000 } ], "history": { "current_id": "assistant-msg-id", "messages": { "user-msg-id": { "id": "user-msg-id", "role": "user", "content": "Hi, what is the capital of France?", "timestamp": 1720000000000, "models": ["gpt-4o"] }, "assistant-msg-id": { "id": "assistant-msg-id", "role": "assistant", "content": "The capital of France is Paris. Paris is not only the capital but also the most populous city in France, known for its iconic landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral.", "parentId": "user-msg-id", "modelName": "gpt-4o", "modelIdx": 0, "timestamp": 1720000001000 } } }, "currentId": "assistant-msg-id"} Tag DTO‚Äã { "id": "tag-uuid-123", "name": "geography", "color": "#4CAF50"} OWUIKnowledge DTO (Knowledge Collection)‚Äã { "id": "knowledge-collection-id", "type": "collection", "status": "processed", "name": "Geography Knowledge Base", "description": "Contains information about world geography and capitals", "created_at": 1720000000000, "updated_at": 1720000001000} Knowledge Collection Response‚Äã { "id": "knowledge-collection-id", "name": "Geography Knowledge Base", "description": "Contains information about world geography and capitals", "type": "collection", "status": "processed", "files_count": 15, "total_size": 2048576, "created_at": 1720000000000, "updated_at": 1720000001000, "metadata": { "indexing_status": "complete", "last_indexed": 1720000001000 }} Model Information Response‚Äã { "id": "gpt-4o", "name": "GPT-4 Optimized", "model": "gpt-4o", "base_model_id": "gpt-4o", "meta": { "description": "Most advanced GPT-4 model optimized for performance", "capabilities": ["text", "vision", "function_calling"], "context_length": 128000, "max_output_tokens": 4096 }, "params": { "temperature": 0.7, "top_p": 1.0, "frequency_penalty": 0.0, "presence_penalty": 0.0 }, "created_at": 1720000000000, "updated_at": 1720000001000} Field Reference Guide‚Äã Required vs Optional Fields‚Äã Chat Creation - Required Fields: title - Chat title (string) models - Array of model names (string[]) messages - Initial message array Chat Creation - Optional Fields: files - Knowledge files for RAG (defaults to empty array) tags - Chat tags (defaults to empty array) params - Model parameters (defaults to empty object) Message Structure - User Message: Required: id, role, content, timestamp, models Optional: parentId (for threading) Message Structure - Assistant Message: Required: id, role, content, parentId, modelName, modelIdx, timestamp Optional: Additional metadata fields ChatCompletionsRequest - Required Fields: chat_id - Target chat ID id - Assistant message ID messages - Array of ChatCompletionMessage model - Model identifier session_id - Session identifier ChatCompletionsRequest - Optional Fields: stream - Enable streaming (defaults to false) background_tasks - Control automatic tasks features - Enable/disable features variables - Template variables filter_ids - Pipeline filters files - Knowledge collections for RAG Field Constraints‚Äã Timestamps: Format: Unix timestamp in milliseconds Example: 1720000000000 (July 4, 2024, 00:00:00 UTC) UUIDs: All ID fields should use valid UUID format Example: 550e8400-e29b-41d4-a716-446655440000 Model Names: Must match available models in your Open WebUI instance Common examples: gpt-4o, gpt-3.5-turbo, claude-3-sonnet Session IDs: Can be any unique string identifier Recommendation: Use UUID format for consistency Knowledge File Status: Valid values: "processed", "processing", "error" Only use "processed" files for completions Important Notes‚Äã This workflow is compatible with Open WebUI + backend orchestration scenarios Critical: The assistant message enrichment must be done in memory on the response object, not via API call Alternative Approach: You can include both user and assistant messages in the initial chat creation (Step 1) instead of doing Step 2 separately No frontend code changes are required for this approach The stream: true parameter allows for real-time response streaming if needed Response Monitoring: Use streaming for real-time processing or polling for simpler implementations that cannot handle streams Background tasks like title generation can be controlled via the background_tasks object Session IDs help maintain conversation context across requests Knowledge Integration: Use the files array to include knowledge collections for RAG capabilities Response Parsing: Handle JSON responses that may be wrapped in markdown code blocks Error Handling: Implement proper retry mechanisms for network timeouts and server errors Summary‚Äã Use the Open WebUI backend APIs to: Start a chat - Create the initial conversation with user input Enrich with assistant message - Add assistant placeholder to the response object in memory (can be combined with Step 1) Update chat state - Send the enriched chat to the server Trigger a reply - Generate the AI response (with optional knowledge integration) Monitor completion - Wait for the assistant response using streaming or polling Complete the message - Mark the response as completed Fetch the final chat - Retrieve and parse the completed conversation Enhanced Capabilities: RAG Integration - Include knowledge collections for context-aware responses Asynchronous Processing - Handle long-running AI operations with streaming or polling Response Parsing - Clean and validate JSON responses from the assistant Session Management - Maintain conversation context across requests This enables backend-controlled workflows that still appear properly in the Web UI frontend chat interface, providing seamless integration between programmatic control and user experience. The key advantage of this approach is that it maintains full compatibility with the Open WebUI frontend while allowing complete backend orchestration of the conversation flow, including advanced features like knowledge integration and asynchronous response handling. Testing‚Äã You can test your implementation by following the step-by-step CURL examples provided above. Make sure to replace placeholder values with your actual: Host URL Authentication token Chat IDs Message IDs Model names tipStart with a simple user message and gradually add complexity like knowledge integration and advanced features once the basic flow is working.

```
curl
```

**Pattern 6:** DevelopmentWriting A Custom Toolkit‚Äã Toolkits are defined in a single Python file, with a top level docstring with metadata and a Tools class. Example Top-Level Docstring‚Äã """title: String Inverseauthor: Your Nameauthor_url: https://website.comgit_url: https://github.com/username/string-reverse.gitdescription: This tool calculates the inverse of a stringrequired_open_webui_version: 0.4.0requirements: langchain-openai, langgraph, ollama, langchain_ollamaversion: 0.4.0licence: MIT""" Tools Class‚Äã Tools have to be defined as methods within a class called Tools, with optional subclasses called Valves and UserValves, for example: class Tools: def __init__(self): """Initialize the Tool.""" self.valves = self.Valves() class Valves(BaseModel): api_key: str = Field("", description="Your API key here") def reverse_string(self, string: str) -> str: """ Reverses the input string. :param string: The string to reverse """ # example usage of valves if self.valves.api_key != "42": return "Wrong API key" return string[::-1] Type Hints‚Äã Each tool must have type hints for arguments. The types may also be nested, such as queries_and_docs: list[tuple[str, int]]. Those type hints are used to generate the JSON schema that is sent to the model. Tools without type hints will work with a lot less consistency. Valves and UserValves - (optional, but HIGHLY encouraged)‚Äã Valves and UserValves are used for specifying customizable settings of the Tool, you can read more on the dedicated Valves & UserValves page. Optional Arguments‚Äã Below is a list of optional arguments your tools can depend on: __event_emitter__: Emit events (see following section) __event_call__: Same as event emitter but can be used for user interactions __user__: A dictionary with user information. It also contains the UserValves object in __user__["valves"]. __metadata__: Dictionary with chat metadata __messages__: List of previous messages __files__: Attached files __model__: A dictionary with model information __oauth_token__: A dictionary containing the user's valid, automatically refreshed OAuth token payload. This is the new, recommended, and secure way to access user tokens for making authenticated API calls. The dictionary typically contains access_token, id_token, and other provider-specific data. For more information about __oauth_token__ and how to configure this token to be sent to tools, check out the OAuth section in the environment variable docs page and the SSO documentation. Just add them as argument to any method of your Tool class just like __user__ in the example above. Using the OAuth Token in a Tool‚Äã When building tools that need to interact with external APIs on the user's behalf, you can now directly access their OAuth token. This removes the need for fragile cookie scraping and ensures the token is always valid. Example: A tool that calls an external API using the user's access token. import httpxfrom typing import Optionalclass Tools: # ... other class setup ... async def get_user_profile_from_external_api(self, __oauth_token__: Optional[dict] = None) -> str: """ Fetches user profile data from a secure external API using their OAuth access token. :param __oauth_token__: Injected by Open WebUI, contains the user's token data. """ if not __oauth_token__ or "access_token" not in __oauth_token__: return "Error: User is not authenticated via OAuth or token is unavailable." access_token = __oauth_token__["access_token"] headers = { "Authorization": f"Bearer {access_token}", "Content-Type": "application/json" } try: async with httpx.AsyncClient() as client: response = await client.get("https://api.my-service.com/v1/profile", headers=headers) response.raise_for_status() # Raise an exception for bad status codes return f"API Response: {response.json()}" except httpx.HTTPStatusError as e: return f"Error: Failed to fetch data from API. Status: {e.response.status_code}" except Exception as e: return f"An unexpected error occurred: {e}" Event Emitters‚Äã Event Emitters are used to add additional information to the chat interface. Similarly to Filter Outlets, Event Emitters are capable of appending content to the chat. Unlike Filter Outlets, they are not capable of stripping information. Additionally, emitters can be activated at any stage during the Tool. ‚ö†Ô∏è CRITICAL: Function Calling Mode Compatibility Event Emitter behavior is significantly different depending on your function calling mode. The function calling mode is controlled by the function_calling parameter: Default Mode: Uses traditional function calling approach with wider model compatibility Native Mode: Leverages model's built-in tool-calling capabilities for reduced latency Before using event emitters, you must understand these critical limitations: Default Mode (function_calling = "default"): Full event emitter support with all event types working as expected Native Mode (function_calling = "native"): Limited event emitter support - many event types don't work properly due to native function calling bypassing Open WebUI's custom tool processing pipeline When to Use Each Mode: Use Default Mode when you need full event emitter functionality, complex tool interactions, or real-time UI updates Use Native Mode when you need reduced latency and basic tool calling without complex UI interactions Function Calling Mode Configuration‚Äã You can configure the function calling mode in two places: Model Settings: Go to Model page ‚Üí Advanced Params ‚Üí Function Calling (set to "Default" or "Native") Per-request basis: Set params.function_calling = "native" or "default" in your request If the model seems to be unable to call the tool, make sure it is enabled (either via the Model page or via the + sign next to the chat input field). Complete Event Type Compatibility Matrix‚Äã Here's the comprehensive breakdown of how each event type behaves across function calling modes: Event TypeDefault Mode FunctionalityNative Mode FunctionalityStatusstatus‚úÖ Full support - Updates status history during tool execution‚úÖ Identical - Tracks function execution statusCOMPATIBLEmessage‚úÖ Full support - Appends incremental content during streaming‚ùå BROKEN - Gets overwritten by native completion snapshotsINCOMPATIBLEchat:completion‚úÖ Full support - Handles streaming responses and completion data‚ö†Ô∏è LIMITED - Carries function results but may overwrite tool updatesPARTIALLY COMPATIBLEchat:message:delta‚úÖ Full support - Streams delta content during execution‚ùå BROKEN - Content gets replaced by native function snapshotsINCOMPATIBLEchat:message‚úÖ Full support - Replaces entire message content cleanly‚ùå BROKEN - Gets overwritten by subsequent native completionsINCOMPATIBLEreplace‚úÖ Full support - Replaces content with precise control‚ùå BROKEN - Replaced content gets overwritten immediatelyINCOMPATIBLEchat:message:files / files‚úÖ Full support - Handles file attachments in messages‚úÖ Identical - Processes files from function outputsCOMPATIBLEchat:message:error‚úÖ Full support - Displays error notifications‚úÖ Identical - Shows function call errorsCOMPATIBLEchat:message:follow_ups‚úÖ Full support - Shows follow-up suggestions‚úÖ Identical - Displays function-generated follow-upsCOMPATIBLEchat:title‚úÖ Full support - Updates chat title dynamically‚úÖ Identical - Updates title based on function interactionsCOMPATIBLEchat:tags‚úÖ Full support - Modifies chat tags‚úÖ Identical - Manages tags from function outputsCOMPATIBLEchat:tasks:cancel‚úÖ Full support - Cancels ongoing tasks‚úÖ Identical - Cancels native function executionsCOMPATIBLEcitation / source‚úÖ Full support - Handles citations with full metadata‚úÖ Identical - Processes function-generated citationsCOMPATIBLEnotification‚úÖ Full support - Shows toast notifications‚úÖ Identical - Displays function execution notificationsCOMPATIBLEconfirmation‚úÖ Full support - Requests user confirmations‚úÖ Identical - Confirms function executionsCOMPATIBLEexecute‚úÖ Full support - Executes code dynamically‚úÖ Identical - Runs function-generated codeCOMPATIBLEinput‚úÖ Full support - Requests user input with full UI‚úÖ Identical - Collects input for functionsCOMPATIBLE Why Native Mode Breaks Certain Event Types‚Äã In Native Mode, the server constructs content blocks from streaming model output and repeatedly emits "chat:completion" events with full serialized content snapshots. The client treats these snapshots as authoritative and completely replaces message content, effectively overwriting any prior tool-emitted updates like message, chat:message, or replace events. Technical Details: middleware.py adds tools directly to form data for native model handling Streaming handler emits repeated content snapshots via chat:completion events Client's chatCompletionEventHandler treats snapshots as complete replacements: message.content = content This causes tool-emitted content updates to flicker and disappear Best Practices and Recommendations‚Äã For Tools Requiring Real-time UI Updates: class Tools: def __init__(self): # Add a note about function calling mode requirements self.description = "This tool requires Default function calling mode for full functionality" async def interactive_tool(self, prompt: str, __event_emitter__=None) -> str: """ ‚ö†Ô∏è This tool requires function_calling = "default" for proper event emission """ if not __event_emitter__: return "Event emitter not available - ensure Default function calling mode is enabled" # Safe to use message events in Default mode await __event_emitter__({ "type": "message", "data": {"content": "Processing step 1..."} }) # ... rest of tool logic For Tools That Must Work in Both Modes: async def universal_tool(self, prompt: str, __event_emitter__=None, __metadata__=None) -> str: """ Tool designed to work in both Default and Native function calling modes """ # Check if we're in native mode (this is a rough heuristic) is_native_mode = __metadata__ and __metadata__.get("params", {}).get("function_calling") == "native" if __event_emitter__: if is_native_mode: # Use only compatible event types in native mode await __event_emitter__({ "type": "status", "data": {"description": "Processing in native mode...", "done": False} }) else: # Full event functionality in default mode await __event_emitter__({ "type": "message", "data": {"content": "Processing with full event support..."} }) # ... tool logic here if __event_emitter__: await __event_emitter__({ "type": "status", "data": {"description": "Completed successfully", "done": True} }) return "Tool execution completed" Troubleshooting Event Emitter Issues‚Äã Symptoms of Native Mode Conflicts: Tool-emitted messages appear briefly then disappear Content flickers during tool execution message or replace events seem to be ignored Status updates work but content updates don't persist Solutions: Switch to Default Mode: Change function_calling from "native" to "default" in model settings Use Compatible Event Types: Stick to status, citation, notification, and other compatible event types in native mode Implement Mode Detection: Add logic to detect function calling mode and adjust event usage accordingly Consider Hybrid Approaches: Use compatible events for core functionality and degrade gracefully Debugging Your Event Emitters: async def debug_events_tool(self, __event_emitter__=None, __metadata__=None) -> str: """Debug tool to test event emitter functionality""" if not __event_emitter__: return "No event emitter available" # Test various event types test_events = [ {"type": "status", "data": {"description": "Testing status events", "done": False}}, {"type": "message", "data": {"content": "Testing message events (may not work in native mode)"}}, {"type": "notification", "data": {"content": "Testing notification events"}}, ] mode_info = "Unknown" if __metadata__: mode_info = __metadata__.get("params", {}).get("function_calling", "default") await __event_emitter__({ "type": "status", "data": {"description": f"Function calling mode: {mode_info}", "done": False} }) for i, event in enumerate(test_events): await asyncio.sleep(1) # Space out events await __event_emitter__(event) await __event_emitter__({ "type": "status", "data": {"description": f"Sent event {i+1}/{len(test_events)}", "done": False} }) await __event_emitter__({ "type": "status", "data": {"description": "Event testing complete", "done": True} }) return f"Event testing completed in {mode_info} mode. Check for missing or flickering content." There are several specific event types with different behaviors: Status Events ‚úÖ FULLY COMPATIBLE‚Äã Status events work identically in both Default and Native function calling modes. This is the most reliable event type for providing real-time feedback during tool execution. Status events add live status updates to a message while it's performing steps. These can be emitted at any stage during tool execution. Status messages appear right above the message content and are essential for tools that delay the LLM response or process large amounts of information. Basic Status Event Structure: await __event_emitter__({ "type": "status", "data": { "description": "Message that shows up in the chat", "done": False, # False = still processing, True = completed "hidden": False # False = visible, True = auto-hide when done }}) Status Event Parameters: description: The status message text shown to users done: Boolean indicating if this status represents completion hidden: Boolean to auto-hide the status once done: True is set Basic Status Exampleasync def data_processing_tool( self, data_file: str, __user__: dict, __event_emitter__=None ) -> str: """ Processes a large data file with status updates ‚úÖ Works in both Default and Native function calling modes """ if not __event_emitter__: return "Processing completed (no status updates available)" # Step 1: Loading await __event_emitter__({ "type": "status", "data": {"description": "Loading data file...", "done": False} }) # Simulate loading time await asyncio.sleep(2) # Step 2: Processing await __event_emitter__({ "type": "status", "data": {"description": "Analyzing 10,000 records...", "done": False} }) # Simulate processing time await asyncio.sleep(3) # Step 3: Completion await __event_emitter__({ "type": "status", "data": {"description": "Analysis complete!", "done": True, "hidden": False} }) return "Data analysis completed successfully. Found 23 anomalies." Advanced Status with Error Handlingasync def api_integration_tool( self, endpoint: str, __event_emitter__=None ) -> str: """ Integrates with external API with comprehensive status tracking ‚úÖ Compatible with both function calling modes """ if not __event_emitter__: return "API integration completed (no status available)" try: await __event_emitter__({ "type": "status", "data": {"description": "Connecting to API...", "done": False} }) # Simulate API connection await asyncio.sleep(1.5) await __event_emitter__({ "type": "status", "data": {"description": "Authenticating...", "done": False} }) # Simulate authentication await asyncio.sleep(1) await __event_emitter__({ "type": "status", "data": {"description": "Fetching data...", "done": False} }) # Simulate data fetching await asyncio.sleep(2) # Success status await __event_emitter__({ "type": "status", "data": {"description": "API integration successful", "done": True} }) return "Successfully retrieved 150 records from the API" except Exception as e: # Error status - always visible for debugging await __event_emitter__({ "type": "status", "data": {"description": f"Error: {str(e)}", "done": True, "hidden": False} }) return f"API integration failed: {str(e)}" Multi-Step Progress Statusasync def batch_processor_tool( self, items: list, __event_emitter__=None ) -> str: """ Processes items in batches with detailed progress tracking ‚úÖ Works perfectly in both function calling modes """ if not __event_emitter__ or not items: return "Batch processing completed" total_items = len(items) batch_size = 10 completed = 0 for i in range(0, total_items, batch_size): batch = items[i:i + batch_size] batch_num = (i // batch_size) + 1 total_batches = (total_items + batch_size - 1) // batch_size # Update status for current batch await __event_emitter__({ "type": "status", "data": { "description": f"Processing batch {batch_num}/{total_batches} ({len(batch)} items)...", "done": False } }) # Simulate batch processing await asyncio.sleep(1) completed += len(batch) # Progress update progress_pct = int((completed / total_items) * 100) await __event_emitter__({ "type": "status", "data": { "description": f"Progress: {completed}/{total_items} items ({progress_pct}%)", "done": False } }) # Final completion status await __event_emitter__({ "type": "status", "data": { "description": f"Batch processing complete! Processed {total_items} items", "done": True } }) return f"Successfully processed {total_items} items in {total_batches} batches" Message Events ‚ö†Ô∏è DEFAULT MODE ONLY‚Äã warningüö® CRITICAL WARNING: Message events are INCOMPATIBLE with Native function calling mode! Message events (message, chat:message, chat:message:delta, replace) allow you to append or modify message content at any stage during tool execution. This enables embedding images, rendering web pages, streaming content updates, and creating rich interactive experiences. However, these event types have major compatibility issues: ‚úÖ Default Mode: Full functionality - content persists and displays properly ‚ùå Native Mode: BROKEN - content gets overwritten by completion snapshots and disappears Why Message Events Break in Native Mode: Native function calling emits repeated chat:completion events with full content snapshots that completely replace message content, causing any tool-emitted message updates to flicker and disappear. Safe Message Event Structure (Default Mode Only): await __event_emitter__({ "type": "message", # Also: "chat:message", "chat:message:delta", "replace" "data": {"content": "This content will be appended/replaced in the chat"}, # Note: message types do NOT require a "done" condition}) Message Event Types: message / chat:message:delta: Appends content to existing message chat:message / replace: Replaces entire message content Both types will be overwritten in Native mode Safe Message Streaming (Default Mode)async def streaming_content_tool( self, query: str, __event_emitter__=None, __metadata__=None ) -> str: """ Streams content updates during processing ‚ö†Ô∏è REQUIRES function_calling = "default" - Will not work in Native mode! """ # Check function calling mode (rough detection) mode = "unknown" if __metadata__: mode = __metadata__.get("params", {}).get("function_calling", "default") if mode == "native": return "‚ùå This tool requires Default function calling mode. Message streaming is not supported in Native mode due to content overwriting issues." if not __event_emitter__: return "Event emitter not available" # Stream progressive content updates content_chunks = [ "üîç **Phase 1: Research**\nGathering information about your query...\n\n", "üìä **Phase 2: Analysis**\nAnalyzing gathered data patterns...\n\n", "‚ú® **Phase 3: Synthesis**\nGenerating insights and recommendations...\n\n", "üìù **Phase 4: Final Report**\nCompiling comprehensive results...\n\n" ] accumulated_content = "" for i, chunk in enumerate(content_chunks): accumulated_content += chunk # Append this chunk to the message await __event_emitter__({ "type": "message", "data": {"content": chunk} }) # Show progress status await __event_emitter__({ "type": "status", "data": { "description": f"Processing phase {i+1}/{len(content_chunks)}...", "done": False } }) # Simulate processing time await asyncio.sleep(2) # Final completion await __event_emitter__({ "type": "status", "data": {"description": "Content streaming complete!", "done": True} }) return "Content streaming completed successfully. All phases processed." Dynamic Content Replacement (Default Mode)async def live_dashboard_tool( self, __event_emitter__=None, __metadata__=None ) -> str: """ Creates a live-updating dashboard using content replacement ‚ö†Ô∏è ONLY WORKS in Default function calling mode """ # Verify we're not in Native mode mode = __metadata__.get("params", {}).get("function_calling", "default") if __metadata__ else "default" if mode == "native": return """‚ùå **Native Mode Incompatibility**This dashboard tool cannot function in Native mode because:- Content replacement events get overwritten by completion snapshots- Live updates will flicker and disappear- Real-time data will not persist in the interface**Solution:** Switch to Default function calling mode in Model Settings ‚Üí Advanced Params ‚Üí Function Calling = "Default"""" if not __event_emitter__: return "Dashboard created (static mode - no live updates)" # Create initial dashboard initial_dashboard = """# üìä Live System Dashboard## System Status: üü° Initializing...### Current Metrics:- **CPU Usage**: Loading...- **Memory**: Loading...- **Active Users**: Loading...- **Response Time**: Loading...---*Last Updated: Initializing...*""" await __event_emitter__({ "type": "replace", "data": {"content": initial_dashboard} }) # Simulate live data updates updates = [ { "status": "üü¢ Online", "cpu": "23%", "memory": "64%", "users": "1,247", "response": "145ms" }, { "status": "üü¢ Optimal", "cpu": "18%", "memory": "61%", "users": "1,352", "response": "132ms" }, { "status": "üü° Busy", "cpu": "67%", "memory": "78%", "users": "1,891", "response": "234ms" } ] for i, data in enumerate(updates): await asyncio.sleep(3) # Simulate data collection delay updated_dashboard = f"""# üìä Live System Dashboard## System Status: {data['status']}### Current Metrics:- **CPU Usage**: {data['cpu']}- **Memory**: {data['memory']}- **Active Users**: {data['users']}- **Response Time**: {data['response']}---*Last Updated: {datetime.now().strftime('%H:%M:%S')}**Update {i+1}/{len(updates)}*""" # Replace entire dashboard content await __event_emitter__({ "type": "replace", "data": {"content": updated_dashboard} }) # Status update await __event_emitter__({ "type": "status", "data": {"description": f"Dashboard updated ({i+1}/{len(updates)})", "done": False} }) await __event_emitter__({ "type": "status", "data": {"description": "Live dashboard monitoring complete", "done": True} }) return "Dashboard monitoring session completed." Mode-Safe Message Toolasync def adaptive_content_tool( self, content_type: str, __event_emitter__=None, __metadata__=None ) -> str: """ Adapts behavior based on function calling mode ‚úÖ Provides best possible experience in both modes """ # Detect function calling mode mode = "default" # Default assumption if __metadata__: mode = __metadata__.get("params", {}).get("function_calling", "default") if not __event_emitter__: return f"Generated {content_type} content (no real-time updates available)" # Mode-specific behavior if mode == "native": # Use only compatible events in Native mode await __event_emitter__({ "type": "status", "data": {"description": f"Generating {content_type} content in Native mode...", "done": False} }) await asyncio.sleep(2) await __event_emitter__({ "type": "status", "data": {"description": "Content generation complete", "done": True} }) # Return content normally - no message events return f"""# {content_type.title()} Content**Mode**: Native Function Calling (Limited Event Support)Generated content here... This content is returned as the tool result rather than being streamed via message events.*Note: Live content updates are not available in Native mode due to event compatibility limitations.*""" else: # Default mode # Full message event functionality available await __event_emitter__({ "type": "status", "data": {"description": "Generating content with full streaming support...", "done": False} }) # Stream content progressively progressive_content = [ f"# {content_type.title()} Content\n\n**Mode**: Default Function Calling ‚úÖ\n\n", "## Section 1: Introduction\nStreaming content in real-time...\n\n", "## Section 2: Details\nAdding detailed information...\n\n", "## Section 3: Conclusion\nFinalizing content delivery...\n\n", "*‚úÖ Content streaming completed successfully!*" ] for i, chunk in enumerate(progressive_content): await __event_emitter__({ "type": "message", "data": {"content": chunk} }) await __event_emitter__({ "type": "status", "data": {"description": f"Streaming section {i+1}/{len(progressive_content)}...", "done": False} }) await asyncio.sleep(1.5) await __event_emitter__({ "type": "status", "data": {"description": "Content streaming complete!", "done": True} }) return "Content has been streamed above with full Default mode capabilities." Citations ‚úÖ FULLY COMPATIBLE‚Äã Citation events work identically in both Default and Native function calling modes. This event type provides source references and citations in the chat interface, allowing users to click and view source materials. Citations are essential for tools that retrieve information from external sources, databases, or documents. They provide transparency and allow users to verify information sources. Citation Event Structure: await __event_emitter__({ "type": "citation", "data": { "document": [content], # Array of content strings "metadata": [ # Array of metadata objects { "date_accessed": datetime.now().isoformat(), "source": title, "author": "Author Name", # Optional "publication_date": "2024-01-01", # Optional "url": "https://source-url.com" # Optional } ], "source": {"name": title, "url": url} # Primary source info }}) Important Citation Setup: When implementing custom citations, you must disable automatic citations in your Tools class: def __init__(self): self.citation = False # REQUIRED - prevents automatic citations from overriding custom ones warning‚ö†Ô∏è Critical Citation Warning: If you set self.citation = True (or don't set it to False), automatic citations will replace any custom citations you send. Always disable automatic citations when using custom citation events. Basic Citation Exampleclass Tools: def __init__(self): self.citation = False # Disable automatic citations async def research_tool( self, topic: str, __event_emitter__=None ) -> str: """ Researches a topic and provides proper citations ‚úÖ Works identically in both Default and Native modes """ if not __event_emitter__: return "Research completed (citations not available)" # Simulate research findings sources = [ { "title": "Advanced AI Systems", "url": "https://example.com/ai-systems", "content": "Artificial intelligence systems have evolved significantly...", "author": "Dr. Jane Smith", "date": "2024-03-15" }, { "title": "Machine Learning Fundamentals", "url": "https://example.com/ml-fundamentals", "content": "The core principles of machine learning include...", "author": "Prof. John Doe", "date": "2024-02-20" } ] # Emit citations for each source for source in sources: await __event_emitter__({ "type": "citation", "data": { "document": [source["content"]], "metadata": [ { "date_accessed": datetime.now().isoformat(), "source": source["title"], "author": source["author"], "publication_date": source["date"], "url": source["url"] } ], "source": { "name": source["title"], "url": source["url"] } } }) return f"Research on '{topic}' completed. Found {len(sources)} relevant sources with detailed citations." Advanced Multi-Source Citationsasync def comprehensive_analysis_tool( self, query: str, __event_emitter__=None ) -> str: """ Performs comprehensive analysis with multiple source types ‚úÖ Full compatibility across all function calling modes """ if not __event_emitter__: return "Analysis completed" # Multiple source types with rich metadata research_sources = { "academic": [ { "title": "Neural Network Architecture in Modern AI", "authors": ["Dr. Sarah Chen", "Prof. Michael Rodriguez"], "journal": "Journal of AI Research", "volume": "Vol. 45, Issue 2", "pages": "123-145", "doi": "10.1000/182", "date": "2024-01-15", "content": "This comprehensive study examines the evolution of neural network architectures..." } ], "web_sources": [ { "title": "Industry AI Implementation Trends", "url": "https://tech-insights.com/ai-trends-2024", "site_name": "TechInsights", "published": "2024-03-01", "content": "Recent industry surveys show that 78% of companies are implementing AI solutions..." } ], "reports": [ { "title": "Global AI Market Report 2024", "organization": "International Tech Research Institute", "report_number": "ITRI-2024-AI-001", "date": "2024-02-28", "content": "The global artificial intelligence market is projected to reach $1.8 trillion by 2030..." } ] } citation_count = 0 # Process academic sources for source in research_sources["academic"]: citation_count += 1 await __event_emitter__({ "type": "citation", "data": { "document": [source["content"]], "metadata": [ { "date_accessed": datetime.now().isoformat(), "source": source["title"], "authors": source["authors"], "journal": source["journal"], "volume": source["volume"], "pages": source["pages"], "doi": source["doi"], "publication_date": source["date"], "type": "academic_journal" } ], "source": { "name": f"{source['title']} - {source['journal']}", "url": f"https://doi.org/{source['doi']}" } } }) # Process web sources for source in research_sources["web_sources"]: citation_count += 1 await __event_emitter__({ "type": "citation", "data": { "document": [source["content"]], "metadata": [ { "date_accessed": datetime.now().isoformat(), "source": source["title"], "site_name": source["site_name"], "publication_date": source["published"], "url": source["url"], "type": "web_article" } ], "source": { "name": source["title"], "url": source["url"] } } }) # Process reports for source in research_sources["reports"]: citation_count += 1 await __event_emitter__({ "type": "citation", "data": { "document": [source["content"]], "metadata": [ { "date_accessed": datetime.now().isoformat(), "source": source["title"], "organization": source["organization"], "report_number": source["report_number"], "publication_date": source["date"], "type": "research_report" } ], "source": { "name": f"{source['title']} - {source['organization']}", "url": f"https://reports.example.com/{source['report_number']}" } } }) return f"""# Analysis CompleteComprehensive analysis of '{query}' has been completed using {citation_count} authoritative sources:- **{len(research_sources['academic'])}** Academic journal articles- **{len(research_sources['web_sources'])}** Industry web sources- **{len(research_sources['reports'])}** Research reportsAll sources have been properly cited and are available for review by clicking the citation links above.""" Database Citation Toolasync def database_query_tool( self, sql_query: str, __event_emitter__=None ) -> str: """ Queries database and provides data citations ‚úÖ Works perfectly in both function calling modes """ if not __event_emitter__: return "Database query executed" # Simulate database results with citation metadata query_results = [ { "record_id": "USR_001247", "data": "John Smith, Software Engineer, joined 2023-01-15", "table": "employees", "last_updated": "2024-03-10T14:30:00Z", "updated_by": "admin_user" }, { "record_id": "USR_001248", "data": "Jane Wilson, Product Manager, joined 2023-02-20", "table": "employees", "last_updated": "2024-03-08T09:15:00Z", "updated_by": "hr_system" } ] # Create citations for each database record for i, record in enumerate(query_results): await __event_emitter__({ "type": "citation", "data": { "document": [f"Database Record: {record['data']}"], "metadata": [ { "date_accessed": datetime.now().isoformat(), "source": f"Database Table: {record['table']}", "record_id": record['record_id'], "last_updated": record['last_updated'], "updated_by": record['updated_by'], "query": sql_query, "type": "database_record" } ], "source": { "name": f"Record {record['record_id']} - {record['table']}", "url": f"database://internal/tables/{record['table']}/{record['record_id']}" } } }) return f"""# Database Query ResultsExecuted query: `{sql_query}`Retrieved **{len(query_results)}** records with complete citation metadata. Each record includes:- Record ID and source table- Last modification timestamp- Update attribution- Full audit trailAll data sources have been properly cited for transparency and verification.""" Additional Compatible Event Types ‚úÖ‚Äã The following event types work identically in both Default and Native function calling modes: Notification Events await __event_emitter__({ "type": "notification", "data": {"content": "Toast notification message"}}) File Events await __event_emitter__({ "type": "files", # or "chat:message:files" "data": {"files": [{"name": "report.pdf", "url": "/files/report.pdf"}]}}) Follow-up Events await __event_emitter__({ "type": "chat:message:follow_ups", "data": {"follow_ups": ["What about X?", "Tell me more about Y"]}}) Title Update Events await __event_emitter__({ "type": "chat:title", "data": {"title": "New Chat Title"}}) Tag Events await __event_emitter__({ "type": "chat:tags", "data": {"tags": ["research", "analysis", "completed"]}}) Error Events await __event_emitter__({ "type": "chat:message:error", "data": {"content": "Error message to display"}}) Confirmation Events await __event_emitter__({ "type": "confirmation", "data": {"message": "Are you sure you want to continue?"}}) Input Request Events await __event_emitter__({ "type": "input", "data": {"prompt": "Please enter additional information:"}}) Code Execution Events await __event_emitter__({ "type": "execute", "data": {"code": "print('Hello from tool-generated code!')"}}) Comprehensive Function Calling Mode Guide‚Äã Choosing the right function calling mode is crucial for your tool's functionality. This guide helps you make an informed decision based on your specific requirements. Mode Comparison Overview: AspectDefault ModeNative ModeLatencyHigher - processes through Open WebUI pipelineLower - direct model handlingEvent Support‚úÖ Full - all event types work perfectly‚ö†Ô∏è Limited - many event types brokenComplexityHandles complex tool interactions wellBest for simple tool callsCompatibilityWorks with all modelsRequires models with native tool callingStreamingPerfect for real-time updatesPoor - content gets overwrittenCitations‚úÖ Full support‚úÖ Full supportStatus Updates‚úÖ Full support‚úÖ Full supportMessage Events‚úÖ Full support‚ùå Broken - content disappears Decision Framework: Do you need real-time content streaming, live updates, or dynamic message modification? Yes ‚Üí Use Default Mode (Native mode will break these features) No ‚Üí Either mode works Is your tool primarily for simple data retrieval or computation? Yes ‚Üí Native Mode is fine (lower latency) No ‚Üí Consider Default Mode for complex interactions Do you need maximum performance and minimal latency? Yes ‚Üí Native Mode (if compatible with your features) No ‚Üí Default Mode provides more features Are you building interactive experiences, dashboards, or multi-step workflows? Yes ‚Üí Default Mode required No ‚Üí Either mode works Recommended Usage Patterns: üèÜ Best Practices for Mode SelectionChoose Default Mode For: Tools with progressive content updates Interactive dashboards or live data displays Multi-step workflows with visual feedback Complex tool chains with intermediate results Educational tools that show step-by-step processes Any tool that needs message, replace, or chat:message events Choose Native Mode For: Simple API calls or database queries Basic calculations or data transformations Tools that only need status updates and citations Performance-critical applications where latency matters Simple retrieval tools without complex UI requirements Universal Compatibility Pattern:async def mode_adaptive_tool( self, query: str, __event_emitter__=None, __metadata__=None ) -> str: """ Tool that adapts its behavior based on function calling mode ‚úÖ Provides optimal experience in both modes """ # Detect current mode mode = "default" if __metadata__: mode = __metadata__.get("params", {}).get("function_calling", "default") is_native_mode = (mode == "native") if not __event_emitter__: return "Tool executed successfully (no event support)" # Always safe: status updates work in both modes await __event_emitter__({ "type": "status", "data": {"description": f"Running in {mode} mode...", "done": False} }) # Mode-specific logic if is_native_mode: # Native mode: use compatible events only await __event_emitter__({ "type": "status", "data": {"description": "Processing with native efficiency...", "done": False} }) # Simulate processing await asyncio.sleep(1) # Return results directly - no message streaming result = f"Query '{query}' processed successfully in Native mode." else: # Default mode: full event capabilities await __event_emitter__({ "type": "message", "data": {"content": f"üîç **Processing Query**: {query}\n\n"} }) await __event_emitter__({ "type": "status", "data": {"description": "Analyzing with full streaming...", "done": False} }) await asyncio.sleep(1) await __event_emitter__({ "type": "message", "data": {"content": "üìä **Results**: Analysis complete with detailed findings.\n\n"} }) result = "Query processed with full Default mode capabilities." # Final status (works in both modes) await __event_emitter__({ "type": "status", "data": {"description": "Processing complete!", "done": True} }) return result üîß Debugging Event Emitter IssuesCommon Issues and Solutions:Issue: Content appears then disappears Cause: Using message events in Native mode Solution: Switch to Default mode or use status events instead Issue: Tool seems unresponsive Cause: Function calling not enabled for model Solution: Enable tools in Model settings or via + button Issue: Events not firing at all Cause: __event_emitter__ parameter missing or None Solution: Ensure parameter is included in tool method signature Issue: Citations being overwritten Cause: self.citation = True (or not set to False) Solution: Set self.citation = False in __init__ method Diagnostic Tool:async def event_diagnostics_tool( self, __event_emitter__=None, __metadata__=None, __user__=None ) -> str: """ Comprehensive diagnostic tool for event emitter debugging """ report = ["# üîç Event Emitter Diagnostic Report\n"] # Check event emitter availability if __event_emitter__: report.append("‚úÖ Event emitter is available\n") else: report.append("‚ùå Event emitter is NOT available\n") return "".join(report) # Check metadata availability if __metadata__: mode = __metadata__.get("params", {}).get("function_calling", "default") report.append(f"‚úÖ Function calling mode: **{mode}**\n") else: report.append("‚ö†Ô∏è Metadata not available (mode unknown)\n") mode = "unknown" # Check user context if __user__: report.append("‚úÖ User context available\n") else: report.append("‚ö†Ô∏è User context not available\n") # Test compatible events (work in both modes) report.append("\n## Testing Compatible Events:\n") try: await __event_emitter__({ "type": "status", "data": {"description": "Testing status events...", "done": False} }) report.append("‚úÖ Status events: WORKING\n") except Exception as e: report.append(f"‚ùå Status events: FAILED - {str(e)}\n") try: await __event_emitter__({ "type": "notification", "data": {"content": "Test notification"} }) report.append("‚úÖ Notification events: WORKING\n") except Exception as e: report.append(f"‚ùå Notification events: FAILED - {str(e)}\n") # Test problematic events (broken in Native mode) report.append("\n## Testing Mode-Dependent Events:\n") try: await __event_emitter__({ "type": "message", "data": {"content": "**Test message event** - This should appear in Default mode only\n"} }) report.append("‚úÖ Message events: SENT (may disappear in Native mode)\n") except Exception as e: report.append(f"‚ùå Message events: FAILED - {str(e)}\n") # Final status await __event_emitter__({ "type": "status", "data": {"description": "Diagnostic complete", "done": True} }) # Mode-specific recommendations report.append("\n## Recommendations:\n") if mode == "native": report.append("""‚ö†Ô∏è **Native Mode Detected**: Limited event support- ‚úÖ Use: status, citation, notification, files events- ‚ùå Avoid: message, replace, chat:message events- üí° Switch to Default mode for full functionality""") elif mode == "default": report.append("""‚úÖ **Default Mode Detected**: Full event support available- All event types should work perfectly- Optimal for interactive and streaming tools""") else: report.append("""‚ùì **Unknown Mode**: Check your model configuration- Ensure function calling is enabled- Verify model supports tool calling""") return "".join(report) üìö Event Emitter Quick ReferenceAlways Compatible (Both Modes):# Status updates - perfect for progress trackingawait __event_emitter__({ "type": "status", "data": {"description": "Processing...", "done": False}})# Citations - essential for source attributionawait __event_emitter__({ "type": "citation", "data": { "document": ["Content"], "source": {"name": "Source", "url": "https://example.com"} }})# Notifications - user alertsawait __event_emitter__({ "type": "notification", "data": {"content": "Task completed!"}})Default Mode Only (Broken in Native):# ‚ö†Ô∏è These will flicker/disappear in Native mode# Progressive content streamingawait __event_emitter__({ "type": "message", "data": {"content": "Streaming content..."}})# Content replacementawait __event_emitter__({ "type": "replace", "data": {"content": "New complete content"}})# Delta updatesawait __event_emitter__({ "type": "chat:message:delta", "data": {"content": "Additional content"}})Mode Detection Pattern:def get_function_calling_mode(__metadata__): """Utility to detect current function calling mode""" if not __metadata__: return "unknown" return __metadata__.get("params", {}).get("function_calling", "default")# Usage in tools:mode = get_function_calling_mode(__metadata__)is_native = (mode == "native")can_stream_messages = not is_nativeEssential Imports:import asynciofrom datetime import datetimefrom typing import Optional, Callable, Awaitable Rich UI Element Embedding‚Äã Both External and Built-In Tools now support rich UI element embedding, allowing tools to return HTML content and interactive iframes that display directly within chat conversations. This feature enables tools to provide sophisticated visual interfaces, interactive widgets, charts, dashboards, and other rich web content. When a tool returns an HTMLResponse with the appropriate headers, the content will be embedded as an interactive iframe in the chat interface rather than displayed as plain text. Basic Usage‚Äã To embed HTML content, your tool should return an HTMLResponse with the Content-Disposition: inline header: from fastapi.responses import HTMLResponsedef create_visualization_tool(self, data: str) -> HTMLResponse: """ Creates an interactive data visualization that embeds in the chat. :param data: The data to visualize """ html_content = """ <!DOCTYPE html> <html> <head> <title>Data Visualization</title> <script src="https://cdn.plot.ly/plotly-latest.min.js"></script> </head> <body> <div id="chart" style="width:100%;height:400px;"></div> <script> // Your interactive chart code here Plotly.newPlot('chart', [{ y: [1, 2, 3, 4], type: 'scatter' }]); </script> </body> </html> """ headers = {"Content-Disposition": "inline"} return HTMLResponse(content=html_content, headers=headers) Advanced Features‚Äã The embedded iframes support auto-resizing and include configurable security settings. The system automatically handles: Auto-resizing: Embedded content automatically adjusts height based on its content Cross-origin communication: Safe message passing between the iframe and parent window Security sandbox: Configurable security restrictions for embedded content Security Considerations‚Äã When embedding external content, several security options can be configured through the UI settings: iframeSandboxAllowForms: Allow form submissions within embedded content iframeSandboxAllowSameOrigin: Allow same-origin requests (use with caution) iframeSandboxAllowPopups: Allow popup windows from embedded content Use Cases‚Äã Rich UI embedding is perfect for: Interactive dashboards: Real-time data visualization and controls Form interfaces: Complex input forms with validation and dynamic behavior Charts and graphs: Interactive plotting with libraries like Plotly, D3.js, or Chart.js Media players: Video, audio, or interactive media content Custom widgets: Specialized UI components for specific tool functionality External integrations: Embedding content from external services or APIs External Tool Example‚Äã For external tools served via HTTP endpoints: @app.post("/tools/dashboard")async def create_dashboard(): html = """ <div style="padding: 20px;"> <h2>System Dashboard</h2> <canvas id="myChart" width="400" height="200"></canvas> <script src="https://cdn.jsdelivr.net/npm/chart.js"></script> <script> const ctx = document.getElementById('myChart').getContext('2d'); new Chart(ctx, { type: 'line', data: { /* your chart data */ } }); </script> </div> """ return HTMLResponse( content=html, headers={"Content-Disposition": "inline"} ) The embedded content automatically inherits responsive design and integrates seamlessly with the chat interface, providing a native-feeling experience for users interacting with your tools. CORS and Direct Tools‚Äã Direct external tools are tools that run directly from the browser. In this case, the tool is called by JavaScript in the user's browser. Because we depend on the Content-Disposition header, when using CORS on a remote tool server, the Open WebUI cannot read that header due to Access-Control-Expose-Headers, which prevents certain headers from being read from the fetch result. To prevent this, you must set Access-Control-Expose-Headers to Content-Disposition. Check the example below of a tool using Node.js: const app = express();const cors = require('cors');app.use(cors())app.get('/tools/dashboard', (req,res) => { let html = ` <div style="padding: 20px;"> <h2>System Dashboard</h2> <canvas id="myChart" width="400" height="200"></canvas> <script src="https://cdn.jsdelivr.net/npm/chart.js"></script> <script> const ctx = document.getElementById('myChart').getContext('2d'); new Chart(ctx, { type: 'line', data: { /* your chart data */ } }); </script> </div> ` res.set({ 'Content-Disposition': 'inline' ,'Access-Control-Expose-Headers':'Content-Disposition' }) res.send(html)}) More info about the header: https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Access-Control-Expose-Headers External packages‚Äã In the Tools definition metadata you can specify custom packages. When you click Save the line will be parsed and pip install will be run on all requirements at once. warningüö® CRITICAL WARNING: Potential for Package Version ConflictsWhen multiple tools define different versions of the same package (e.g., Tool A requires pandas==1.5.0 and Tool B requires pandas==2.0.0), Open WebUI installs them in a non-deterministic order. This can lead to unpredictable behavior and break one or more of your tools.The only robust solution to this problem is to use an OpenAPI tool server.We strongly recommend using an OpenAPI tool server to avoid these dependency conflicts. Keep in mind that as pip is used in the same process as Open WebUI, the UI will be completely unresponsive during the installation. No measures are taken to handle package conflicts with Open WebUI's requirements. That means that specifying requirements can break Open WebUI if you're not careful. You might be able to work around this by specifying open-webui itself as a requirement. Example"""title: myToolNameauthor: myNamefunding_url: [any link here will be shown behind a `Heart` button for users to show their support to you]version: 1.0.0# the version is displayed in the UI to help users keep track of updates.license: GPLv3description: [recommended]requirements: package1>=2.7.0,package2,package3"""

```
Tools
```

**Pattern 7:** Choose Default Mode For: Tools with progressive content updates Interactive dashboards or live data displays Multi-step workflows with visual feedback Complex tool chains with intermediate results Educational tools that show step-by-step processes Any tool that needs message, replace, or chat:message events Choose Native Mode For: Simple API calls or database queries Basic calculations or data transformations Tools that only need status updates and citations Performance-critical applications where latency matters Simple retrieval tools without complex UI requirements Universal Compatibility Pattern:async def mode_adaptive_tool( self, query: str, __event_emitter__=None, __metadata__=None ) -> str: """ Tool that adapts its behavior based on function calling mode ‚úÖ Provides optimal experience in both modes """ # Detect current mode mode = "default" if __metadata__: mode = __metadata__.get("params", {}).get("function_calling", "default") is_native_mode = (mode == "native") if not __event_emitter__: return "Tool executed successfully (no event support)" # Always safe: status updates work in both modes await __event_emitter__({ "type": "status", "data": {"description": f"Running in {mode} mode...", "done": False} }) # Mode-specific logic if is_native_mode: # Native mode: use compatible events only await __event_emitter__({ "type": "status", "data": {"description": "Processing with native efficiency...", "done": False} }) # Simulate processing await asyncio.sleep(1) # Return results directly - no message streaming result = f"Query '{query}' processed successfully in Native mode." else: # Default mode: full event capabilities await __event_emitter__({ "type": "message", "data": {"content": f"üîç **Processing Query**: {query}\n\n"} }) await __event_emitter__({ "type": "status", "data": {"description": "Analyzing with full streaming...", "done": False} }) await asyncio.sleep(1) await __event_emitter__({ "type": "message", "data": {"content": "üìä **Results**: Analysis complete with detailed findings.\n\n"} }) result = "Query processed with full Default mode capabilities." # Final status (works in both modes) await __event_emitter__({ "type": "status", "data": {"description": "Processing complete!", "done": True} }) return result

```
message
```

**Pattern 8:** Environment Variable ConfigurationOverview‚Äã Open WebUI provides a large range of environment variables that allow you to customize and configure various aspects of the application. This page serves as a comprehensive reference for all available environment variables, providing their types, default values, and descriptions. As new variables are introduced, this page will be updated to reflect the growing configuration options. infoThis page is up-to-date with Open WebUI release version v0.6.42, but is still a work in progress to later include more accurate descriptions, listing out options available for environment variables, defaults, and improving descriptions. Important Note on PersistentConfig Environment Variables‚Äã noteWhen launching Open WebUI for the first time, all environment variables are treated equally and can be used to configure the application. However, for environment variables marked as PersistentConfig, their values are persisted and stored internally.After the initial launch, if you restart the container, PersistentConfig environment variables will no longer use the external environment variable values. Instead, they will use the internally stored values.In contrast, regular environment variables will continue to be updated and applied on each subsequent restart.You can update the values of PersistentConfig environment variables directly from within Open WebUI, and these changes will be stored internally. This allows you to manage these configuration settings independently of the external environment variables.Please note that PersistentConfig environment variables are clearly marked as such in the documentation below, so you can be aware of how they will behave.To disable this behavior and force Open WebUI to always use your environment variables (ignoring the database), set ENABLE_PERSISTENT_CONFIG to False.CRITICAL WARNING: When ENABLE_PERSISTENT_CONFIG is False, you may still be able to edit settings in the Admin UI. However, these changes are NOT saved permanently. They will persist only for the current session and will be lost when you restart the container, as the system will revert to the values defined in your environment variables. App/Backend‚Äã The following environment variables are used by backend/open_webui/config.py to provide Open WebUI startup configuration. Please note that some variables may have different default values depending on whether you're running Open WebUI directly or via Docker. For more information on logging environment variables, see our logging documentation. General‚Äã WEBUI_URL‚Äã Type: str Default: http://localhost:3000 Description: Specifies the URL where your Open WebUI installation is reachable. Needed for search engine support and OAuth/SSO. Persistence: This environment variable is a PersistentConfig variable. warningThis variable has to be set before you start using OAuth/SSO for authentication. Since this is a persistent config environment variable, you can only change it through one of the following options: Temporarily disabling persistent config using ENABLE_PERSISTENT_CONFIG Changing WEBUI_URL in the admin panel > settings and changing "WebUI URL". Failure to set WEBUI_URL before using OAuth/SSO will result in failure to log in. ENABLE_SIGNUP‚Äã Type: bool Default: True Description: Toggles user account creation. Persistence: This environment variable is a PersistentConfig variable. ENABLE_SIGNUP_PASSWORD_CONFIRMATION‚Äã Type: bool Default: False Description: If set to True, a "Confirm Password" field is added to the sign-up page to help users avoid typos when creating their password. ENABLE_LOGIN_FORM‚Äã Type: bool Default: True Description: Toggles email, password, sign-in and "or" (only when ENABLE_OAUTH_SIGNUP is set to True) elements. Persistence: This environment variable is a PersistentConfig variable. ENABLE_PASSWORD_AUTH‚Äã Type: bool Default: True Description: Allows both password and SSO authentication methods to coexist when set to True. When set to False, it disables all password-based login attempts on the /signin and /ldap endpoints, enforcing strict SSO-only authentication. Disable this setting in production environments with fully configured SSO to prevent credential-based account takeover attacks; keep it enabled if you require password authentication as a backup or have not yet completed SSO configuration. Should never be disabled if OAUTH/SSO is not being used. dangerThis should only ever be set to False when ENABLE_OAUTH_SIGNUP is also being used and set to True. Never disable this if OAUTH/SSO is not being used. Failure to do so will result in the inability to login. DEFAULT_LOCALE‚Äã Type: str Default: en Description: Sets the default locale for the application. Persistence: This environment variable is a PersistentConfig variable. DEFAULT_MODELS‚Äã Type: str Default: Empty string (' '), since None. Description: Sets a default Language Model. Persistence: This environment variable is a PersistentConfig variable. DEFAULT_PINNED_MODELS‚Äã Type: str Default: Empty string (' ') Description: Comma-separated list of model IDs to pin by default for new users who haven't customized their pinned models. This provides a pre-selected set of frequently used models in the model selector for new accounts. Example: gpt-4,claude-3-opus,llama-3-70b Persistence: This environment variable is a PersistentConfig variable. DEFAULT_USER_ROLE‚Äã Type: str Options: pending - New users are pending until their accounts are manually activated by an admin. user - New users are automatically activated with regular user permissions. admin - New users are automatically activated with administrator permissions. Default: pending Description: Sets the default role assigned to new users. Persistence: This environment variable is a PersistentConfig variable. DEFAULT_GROUP_ID‚Äã Type: str Default: Empty string (' ') Description: Sets the default group ID to assign to new users upon registration. Persistence: This environment variable is a PersistentConfig variable. PENDING_USER_OVERLAY_TITLE‚Äã Type: str Default: Empty string (' ') Description: Sets a custom title for the pending user overlay. Persistence: This environment variable is a PersistentConfig variable. PENDING_USER_OVERLAY_CONTENT‚Äã Type: str Default: Empty string (' ') Description: Sets a custom text content for the pending user overlay. Persistence: This environment variable is a PersistentConfig variable. ENABLE_CHANNELS‚Äã Type: bool Default: False Description: Enables or disables channel support. Persistence: This environment variable is a PersistentConfig variable. WEBHOOK_URL‚Äã Type: str Description: Sets a webhook for integration with Discord/Slack/Microsoft Teams. Persistence: This environment variable is a PersistentConfig variable. ENABLE_ADMIN_EXPORT‚Äã Type: bool Default: True Description: Controls whether admins can export data, chats and the database in the admin panel. Database exports only work for SQLite databases for now. ENABLE_ADMIN_CHAT_ACCESS‚Äã Type: bool Default: True Description: Enables admin users to directly access the chats of other users. When disabled, admins can no longer accesss user's chats in the admin panel. If you disable this, consider disabling ENABLE_ADMIN_EXPORT too, if you are using SQLite, as the exports also contain user chats. BYPASS_ADMIN_ACCESS_CONTROL‚Äã Type: bool Default: True Description: When disabled, admin users are treated like regular users for workspace access (models, knowledge, prompts and tools) and only see items they have explicit permission to access through the existing access control system. This also applies to the visibility of models in the model selector - admins will be treated as regular users: base models and custom models they do not have explicit permission to access, will be hidden. If set to True (Default), admins have access to all created items in the workspace area and all models in the model selector, regardless of access permissions. ENABLE_USER_WEBHOOKS‚Äã Type: bool Default: True Description: Enables or disables user webhooks. Persistence: This environment variable is a PersistentConfig variable. RESPONSE_WATERMARK‚Äã Type: str Default: Empty string (' ') Description: Sets a custom text that will be included when you copy a message in the chat. e.g., "This text is AI generated" -> will add "This text is AI generated" to every message, when copied. Persistence: This environment variable is a PersistentConfig variable. THREAD_POOL_SIZE‚Äã Type: int Default: 0 Description: Sets the thread pool size for FastAPI/AnyIO blocking calls. By default (when set to 0) FastAPI/AnyIO use 40 threads. In case of large instances and many concurrent users, it may be needed to increase THREAD_POOL_SIZE to prevent blocking. infoIf you are running larger instances, you WILL NEED to set this to a higher value like multiple hundreds if not thousands (e.g. 1000) otherwise your app may get stuck the default pool size (which is 40 threads) is full and will not react anymore. ENABLE_CUSTOM_MODEL_FALLBACK‚Äã Type: bool Default: False Description: Controls whether custom models should fall back to a default model if their assigned base model is missing. When set to True, if a custom model's base model is not found, the system will use the first model from the configured DEFAULT_MODELS list instead of returning an error. MODELS_CACHE_TTL‚Äã Type: int Default: 1 Description: Sets the cache time-to-live in seconds for model list responses from OpenAI and Ollama endpoints. This reduces API calls by caching the available models list for the specified duration. Set to empty string to disable caching entirely. infoThis caches the external model lists retrieved from configured OpenAI-compatible and Ollama API endpoints (not Open WebUI's internal model configurations). Higher values improve performance by reducing redundant API requests to external providers but may delay visibility of newly added or removed models on those endpoints. A value of 0 disables caching and forces fresh API calls each time. In high-traffic scenarios, increasing this value (e.g., to 300 seconds) can significantly reduce load on external API endpoints while still providing reasonably fresh model data. SHOW_ADMIN_DETAILS‚Äã Type: bool Default: True Description: Toggles whether to show admin user details in the interface. Persistence: This environment variable is a PersistentConfig variable. ENABLE_PUBLIC_ACTIVE_USERS_COUNT‚Äã Type: bool Default: True Description: Controls whether the active user count is visible to all users or restricted to administrators only. When set to False, only admin users can see how many users are currently active, reducing backend load and addressing privacy concerns in large deployments. Persistence: This environment variable is a PersistentConfig variable. ADMIN_EMAIL‚Äã Type: str Description: Sets the admin email shown by SHOW_ADMIN_DETAILS Persistence: This environment variable is a PersistentConfig variable. ENV‚Äã Type: str Options: dev - Enables the FastAPI API documentation on /docs prod - Automatically configures several environment variables Default: Backend Default: dev Docker Default: prod Description: Environment setting. ENABLE_PERSISTENT_CONFIG‚Äã Type: bool Default: True Description: Controls whether the system prioritizes configuration saved in the database over environment variables. True (Default): Values saved in the database (via the Admin UI) take precedence. If a value is set in the UI, the environment variable is ignored for that setting. False: Environment variables take precedence. The system will not load configuration from the database at startup if an environment variable is present (or it will use the default). CRITICAL WARNING: When set to False, you can still seemingly "change" settings in the Admin UI. These changes will apply to the current running session but will be lost upon restart. The system will revert to the values defined in your environment variables (or defaults) every time it boots up. Use Case: Set this to False if you want to strictly manage configuration via a docker-compose.yaml or .env file and prevent UI changes from persisting across restarts. CUSTOM_NAME‚Äã Type: str Description: Sets WEBUI_NAME but polls api.openwebui.com for metadata. WEBUI_NAME‚Äã Type: str Default: Open WebUI Description: Sets the main WebUI name. Appends (Open WebUI) if overridden. PORT‚Äã Type: int Default: 8080 Description: Sets the port to run Open WebUI from. infoIf you're running the application via Python and using the open-webui serve command, you cannot set the port using the PORT configuration. Instead, you must specify it directly as a command-line argument using the --port flag. For example:open-webui serve --port 9999This will run the Open WebUI on port 9999. The PORT environment variable is disregarded in this mode. ENABLE_REALTIME_CHAT_SAVE‚Äã Type: bool Default: False Description: When enabled, the system saves each chunk of streamed chat data to the database in real time to ensure maximum data persistency. This feature provides robust data recovery and allows accurate session tracking. However, the tradeoff is increased latency, as saving to the database introduces a delay. Disabling this feature can improve performance and reduce delays, but it risks potential data loss in the event of a system failure or crash. Use based on your application's requirements and acceptable tradeoffs. ENABLE_CHAT_RESPONSE_BASE64_IMAGE_URL_CONVERSION‚Äã Type: bool Default: False Description: When set to true, it automatically uploads base64-encoded images exceeding 1KB in markdown and converts them into image file URLs to reduce the size of response text. Some multimodal models directly output images as Base64 strings within the Markdown content. This results in larger response bodies, placing strain on CPU, network, Redis, and database resources. CHAT_RESPONSE_STREAM_DELTA_CHUNK_SIZE‚Äã Type: int Default: 1 Description: Sets a system-wide minimum value for the number of tokens to batch together before sending them to the client during a streaming response. This allows an administrator to enforce a baseline level of performance and stability across the entire system by preventing excessively small chunk sizes that can cause high CPU load. The final chunk size used for a response will be the highest value set among this global variable, the model's advanced parameters, or the per-chat settings. The default is 1, which applies no minimum batching at the global level. CHAT_STREAM_RESPONSE_CHUNK_MAX_BUFFER_SIZE‚Äã Type: int Default: Empty string (' '), which disables the limit (equivalent to None) Description: Sets the maximum buffer size in bytes for handling stream response chunks. When a single chunk exceeds this limit, the system returns an empty JSON object and skips subsequent oversized data until encountering normally-sized chunks. This prevents memory issues when dealing with extremely large responses from certain providers (e.g., models like gemini-2.5-flash-image or services returning extensive web search data exceeding). Set to an empty string or a negative value to disable chunk size limitations entirely. Recommended values are 16-20 MB (16777216) or larger depending on the image size of the image generation model (4K images may need even more). infoIt is recommended to set this to a high single-digit or low double-digit value if you run Open WebUI with high concurrency, many users, and very fast streaming models. BYPASS_MODEL_ACCESS_CONTROL‚Äã Type: bool Default: False Description: Bypasses model access control. When set to true, all users (and admins alike) will have access to all models, regardless of the model's privacy setting (Private, Public, Shared with certain groups). This is useful for smaller or individual Open WebUI installations where model access restrictions may not be needed. WEBUI_BUILD_HASH‚Äã Type: str Default: dev-build Description: Used for identifying the Git SHA of the build for releases. WEBUI_BANNERS‚Äã Type: list of dict Default: [] Description: List of banners to show to users. The format for banners are: [{"id": "string", "type": "string [info, success, warning, error]", "title": "string", "content": "string", "dismissible": false, "timestamp": 1000}] Persistence: This environment variable is a PersistentConfig variable. infoWhen setting this environment variable in a .env file, make sure to escape the quotes by wrapping the entire value in double quotes and using escaped quotes (\") for the inner quotes. Example:WEBUI_BANNERS="[{\"id\": \"1\", \"type\": \"warning\", \"title\": \"Your messages are stored.\", \"content\": \"Your messages are stored and may be reviewed by human people. LLM's are prone to hallucinations, check sources.\", \"dismissible\": true, \"timestamp\": 1000}]" USE_CUDA_DOCKER‚Äã Type: bool Default: False Description: Builds the Docker image with NVIDIA CUDA support. Enables GPU acceleration for local Whisper and embeddings. DOCKER‚Äã Type: bool Default: False Description: Indicates whether Open WebUI is running inside a Docker container. Used internally for environment detection. USE_CUDA‚Äã Type: bool Default: False Description: Controls whether to use CUDA acceleration for local models. When set to true, attempts to detect and use available NVIDIA GPUs. The code reads the environment variable USE_CUDA_DOCKER to set this internal boolean variable. DEVICE_TYPE‚Äã Type: str Default: cpu Description: Specifies the device type for model execution. Automatically set to cuda if CUDA is available and enabled, or mps for Apple Silicon. EXTERNAL_PWA_MANIFEST_URL‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: When defined as a fully qualified URL (e.g., https://path/to/manifest.webmanifest), requests sent to /manifest.json will use the external manifest file. When not defined, the default manifest.json file will be used. ENABLE_TITLE_GENERATION‚Äã Type: bool Default: True Description: Enables or disables chat title generation. Persistence: This environment variable is a PersistentConfig variable. LICENSE_KEY‚Äã Type: str Default: None Description: Specifies the license key to use (for Enterprise users only). Persistence: This environment variable is a PersistentConfig variable. SSL_ASSERT_FINGERPRINT‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the SSL assert fingerprint to use. Persistence: This environment variable is a PersistentConfig variable. ENABLE_COMPRESSION_MIDDLEWARE‚Äã Type: bool Default: True Description: Enables gzip compression middleware for HTTP responses, reducing bandwidth usage and improving load times. DEFAULT_PROMPT_SUGGESTIONS‚Äã Type: list of dict Default: [] (which means to use the built-in default prompt suggestions) Description: List of prompt suggestions. The format for prompt suggestions are: [{"title": ["Title part 1", "Title part 2"], "content": "prompt"}] warningNEVER set this env var to debug in production. AIOHTTP Client‚Äã AIOHTTP_CLIENT_TIMEOUT‚Äã Type: int Default: 300 Description: Specifies the timeout duration in seconds for the AIOHTTP client. This impacts things such as connections to Ollama and OpenAI endpoints. infoThis is the maximum amount of time the client will wait for a response before timing out. If set to an empty string (' '), the timeout will be set to None, effectively disabling the timeout and allowing the client to wait indefinitely. AIOHTTP_CLIENT_TIMEOUT_MODEL_LIST‚Äã Type: int Default: 10 Description: Sets the timeout in seconds for fetching the model list. This can be useful in cases where network latency requires a longer timeout duration to successfully retrieve the model list. noteThe AIOHTTP_CLIENT_TIMEOUT_MODEL_LIST is set to 10 seconds by default to help ensure that all necessary connections are available when opening the web UI. This duration allows enough time for retrieving the model list even in cases of higher network latency. You can lower this value if quicker timeouts are preferred, but keep in mind that doing so may lead to some connections being dropped, depending on your network conditions. AIOHTTP_CLIENT_TIMEOUT_OPENAI_MODEL_LIST‚Äã Type: int Description: Sets the timeout in seconds for fetching the model list. This can be useful in cases where network latency requires a longer timeout duration to successfully retrieve the model list. AIOHTTP_CLIENT_SESSION_SSL‚Äã Type: bool Default: True Description: Controls SSL/TLS verification for AIOHTTP client sessions when connecting to external APIs. AIOHTTP_CLIENT_TIMEOUT_TOOL_SERVER_DATA‚Äã Type: int Default: 10 Description: Sets the timeout in seconds for retrieving data from tool servers via AIOHTTP client. AIOHTTP_CLIENT_SESSION_TOOL_SERVER_SSL‚Äã Type: bool Default: True Description: Controls SSL/TLS verification specifically for tool server connections via AIOHTTP client. Directories‚Äã DATA_DIR‚Äã Type: str Default: ./data Description: Specifies the base directory for data storage, including uploads, cache, vector database, etc. FONTS_DIR‚Äã Type: str Description: Specifies the directory for fonts. FRONTEND_BUILD_DIR‚Äã Type: str Default: ../build Description: Specifies the location of the built frontend files. STATIC_DIR‚Äã Type: str Default: ./static Description: Specifies the directory for static files, such as the favicon. Logging‚Äã GLOBAL_LOG_LEVEL‚Äã Type: str Default: INFO Description: Sets the global logging level for all Open WebUI components. Valid values: DEBUG, INFO, WARNING, ERROR, CRITICAL. AUDIT_LOGS_FILE_PATH‚Äã Type: str Default: ${DATA_DIR}/audit.log Description: Configures where the audit log file is stored. Enables storing logs in separate volumes or custom locations for better organization and persistence. Example: /var/log/openwebui/audit.log, /mnt/logs/audit.log AUDIT_LOG_FILE_ROTATION_SIZE‚Äã Type: str Default: 10MB Description: Specifies the maximum size of the audit log file before rotation occurs (e.g., 10MB, 100MB, 1GB). AUDIT_UVICORN_LOGGER_NAMES‚Äã Type: str Default: uvicorn.access Description: Comma-separated list of logger names to capture for audit logging. Defaults to Uvicorn's access logger. AUDIT_LOG_LEVEL‚Äã Type: str Default: NONE Options: NONE, METADATA, REQUEST, REQUEST_RESPONSE Description: Controls the verbosity level of audit logging. METADATA logs basic request info, REQUEST includes request bodies, REQUEST_RESPONSE includes both requests and responses. MAX_BODY_LOG_SIZE‚Äã Type: int Default: 2048 Description: Sets the maximum size in bytes for request/response bodies in audit logs. Bodies larger than this are truncated. AUDIT_EXCLUDED_PATHS‚Äã Type: str Default: /chats,/chat,/folders Description: Comma-separated list of URL paths to exclude from audit logging. Paths are matched without leading slashes.RetryTo run code, enable code execution and file creation in Settings > Capabilities.Claude can make mistakes. Please double-check responses. Ollama‚Äã ENABLE_OLLAMA_API‚Äã Type: bool Default: True Description: Enables the use of Ollama APIs. Persistence: This environment variable is a PersistentConfig variable. OLLAMA_BASE_URL (OLLAMA_API_BASE_URL is deprecated)‚Äã Type: str Default: http://localhost:11434 Docker Default: If K8S_FLAG is set: http://ollama-service.open-webui.svc.cluster.local:11434 If USE_OLLAMA_DOCKER=True: http://localhost:11434 Else http://host.docker.internal:11434 Description: Configures the Ollama backend URL. OLLAMA_BASE_URLS‚Äã Type: str Description: Configures load-balanced Ollama backend hosts, separated by ;. See OLLAMA_BASE_URL. Takes precedence overOLLAMA_BASE_URL. Example: http://host-one:11434;http://host-two:11434 Persistence: This environment variable is a PersistentConfig variable. USE_OLLAMA_DOCKER‚Äã Type: bool Default: False Description: Builds the Docker image with a bundled Ollama instance. K8S_FLAG‚Äã Type: bool Default: False Description: If set, assumes Helm chart deployment and sets OLLAMA_BASE_URL to http://ollama-service.open-webui.svc.cluster.local:11434 OpenAI‚Äã ENABLE_OPENAI_API‚Äã Type: bool Default: True Description: Enables the use of OpenAI APIs. Persistence: This environment variable is a PersistentConfig variable. OPENAI_API_BASE_URL‚Äã Type: str Default: https://api.openai.com/v1 Description: Configures the OpenAI base API URL. Persistence: This environment variable is a PersistentConfig variable. OPENAI_API_BASE_URLS‚Äã Type: str Description: Supports balanced OpenAI base API URLs, semicolon-separated. Example: http://host-one:11434;http://host-two:11434 Persistence: This environment variable is a PersistentConfig variable. OPENAI_API_KEY‚Äã Type: str Description: Sets the OpenAI API key. Example: sk-124781258123 Persistence: This environment variable is a PersistentConfig variable. OPENAI_API_KEYS‚Äã Type: str Description: Supports multiple OpenAI API keys, semicolon-separated. Example: sk-124781258123;sk-4389759834759834 Persistence: This environment variable is a PersistentConfig variable. Tasks‚Äã TASK_MODEL‚Äã Type: str Description: The default model to use for tasks such as title and web search query generation when using Ollama models. Persistence: This environment variable is a PersistentConfig variable. TASK_MODEL_EXTERNAL‚Äã Type: str Description: The default model to use for tasks such as title and web search query generation when using OpenAI-compatible endpoints. Persistence: This environment variable is a PersistentConfig variable. TITLE_GENERATION_PROMPT_TEMPLATE‚Äã Type: str Description: Prompt to use when generating chat titles. Default: The value of DEFAULT_TITLE_GENERATION_PROMPT_TEMPLATE environment variable. DEFAULT_TITLE_GENERATION_PROMPT_TEMPLATE: ### Task:Generate a concise, 3-5 word title with an emoji summarizing the chat history.### Guidelines:- The title should clearly represent the main theme or subject of the conversation.- Use emojis that enhance understanding of the topic, but avoid quotation marks or special formatting.- Write the title in the chat's primary language; default to English if multilingual.- Prioritize accuracy over excessive creativity; keep it clear and simple.### Output:JSON format: { "title": "your concise title here" }### Examples:- { "title": "üìâ Stock Market Trends" },- { "title": "üç™ Perfect Chocolate Chip Recipe" },- { "title": "Evolution of Music Streaming" },- { "title": "Remote Work Productivity Tips" },- { "title": "Artificial Intelligence in Healthcare" },- { "title": "üéÆ Video Game Development Insights" }### Chat History:<chat_history>{{MESSAGES:END:2}}</chat_history> Persistence: This environment variable is a PersistentConfig variable. ENABLE_FOLLOW_UP_GENERATION‚Äã Type: bool Default: True Description: Enables or disables follow up generation. Persistence: This environment variable is a PersistentConfig variable. FOLLOW_UP_GENERATION_PROMPT_TEMPLATE‚Äã Type: str Description: Prompt to use for generating several relevant follow-up questions. Default: The value of DEFAULT_FOLLOW_UP_GENERATION_PROMPT_TEMPLATE environment variable. DEFAULT_FOLLOW_UP_GENERATION_PROMPT_TEMPLATE: ### Task:Suggest 3-5 relevant follow-up questions or prompts that the user might naturally ask next in this conversation as a **user**, based on the chat history, to help continue or deepen the discussion.### Guidelines:- Write all follow-up questions from the user‚Äôs point of view, directed to the assistant.- Make questions concise, clear, and directly related to the discussed topic(s).- Only suggest follow-ups that make sense given the chat content and do not repeat what was already covered.- If the conversation is very short or not specific, suggest more general (but relevant) follow-ups the user might ask.- Use the conversation's primary language; default to English if multilingual.- Response must be a JSON array of strings, no extra text or formatting.### Output:JSON format: { "follow_ups": ["Question 1?", "Question 2?", "Question 3?"] }### Chat History:<chat_history>{{MESSAGES:END:6}}</chat_history>" Persistence: This environment variable is a PersistentConfig variable. TOOLS_FUNCTION_CALLING_PROMPT_TEMPLATE‚Äã Type: str Description: Prompt to use when calling tools. Default: The value of DEFAULT_TOOLS_FUNCTION_CALLING_PROMPT_TEMPLATE environment variable. DEFAULT_TOOLS_FUNCTION_CALLING_PROMPT_TEMPLATE: Available Tools: {{TOOLS}}Your task is to choose and return the correct tool(s) from the list of available tools based on the query. Follow these guidelines:- Return only the JSON object, without any additional text or explanation.- If no tools match the query, return an empty array: { "tool_calls": [] }- If one or more tools match the query, construct a JSON response containing a "tool_calls" array with objects that include: - "name": The tool's name. - "parameters": A dictionary of required parameters and their corresponding values.The format for the JSON response is strictly:{ "tool_calls": [ {"name": "toolName1", "parameters": {"key1": "value1"}}, {"name": "toolName2", "parameters": {"key2": "value2"}} ]} Persistence: This environment variable is a PersistentConfig variable. Code Execution‚Äã ENABLE_CODE_EXECUTION‚Äã Type: bool Default: True Description: Enables or disables code execution. Persistence: This environment variable is a PersistentConfig variable. CODE_EXECUTION_ENGINE‚Äã Type: str Default: pyodide Description: Specifies the code execution engine to use. Persistence: This environment variable is a PersistentConfig variable. CODE_EXECUTION_JUPYTER_URL‚Äã Type: str Default: None Description: Specifies the Jupyter URL to use for code execution. Persistence: This environment variable is a PersistentConfig variable. CODE_EXECUTION_JUPYTER_AUTH‚Äã Type: str Default: None Description: Specifies the Jupyter authentication method to use for code execution. Persistence: This environment variable is a PersistentConfig variable. CODE_EXECUTION_JUPYTER_AUTH_TOKEN‚Äã Type: str Default: None Description: Specifies the Jupyter authentication token to use for code execution. Persistence: This environment variable is a PersistentConfig variable. CODE_EXECUTION_JUPYTER_AUTH_PASSWORD‚Äã Type: str Default: None Description: Specifies the Jupyter authentication password to use for code execution. Persistence: This environment variable is a PersistentConfig variable. CODE_EXECUTION_JUPYTER_TIMEOUT‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the timeout for Jupyter code execution. Persistence: This environment variable is a PersistentConfig variable. Code Interpreter‚Äã ENABLE_CODE_INTERPRETER‚Äã Type: bool Default: True Description: Enables or disables code interpreter. Persistence: This environment variable is a PersistentConfig variable. CODE_INTERPRETER_ENGINE‚Äã Type: str Default: pyodide Description: Specifies the code interpreter engine to use. Persistence: This environment variable is a PersistentConfig variable. CODE_INTERPRETER_BLACKLISTED_MODULES‚Äã Type: str (comma-separated list of module names) Default: None Description: Specifies a comma-separated list of Python modules that are blacklisted and cannot be imported or used within the code interpreter. This enhances security by preventing access to potentially sensitive or system-level functionalities. CODE_INTERPRETER_PROMPT_TEMPLATE‚Äã Type: str Default: None Description: Specifies the prompt template to use for code interpreter. Persistence: This environment variable is a PersistentConfig variable. CODE_INTERPRETER_JUPYTER_URL‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the Jupyter URL to use for code interpreter. Persistence: This environment variable is a PersistentConfig variable. CODE_INTERPRETER_JUPYTER_AUTH‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the Jupyter authentication method to use for code interpreter. Persistence: This environment variable is a PersistentConfig variable. CODE_INTERPRETER_JUPYTER_AUTH_TOKEN‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the Jupyter authentication token to use for code interpreter. Persistence: This environment variable is a PersistentConfig variable. CODE_INTERPRETER_JUPYTER_AUTH_PASSWORD‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the Jupyter authentication password to use for code interpreter. Persistence: This environment variable is a PersistentConfig variable. CODE_INTERPRETER_JUPYTER_TIMEOUT‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the timeout for the Jupyter code interpreter. Persistence: This environment variable is a PersistentConfig variable. Direct Connections (OpenAPI/MCPO Tool Servers)‚Äã ENABLE_DIRECT_CONNECTIONS‚Äã Type: bool Default: True Description: Enables or disables direct connections. Persistence: This environment variable is a PersistentConfig variable. TOOL_SERVER_CONNECTIONS‚Äã Type: str (JSON array) Default: [] Description: Specifies a JSON array of tool server connection configurations. Each connection should define the necessary parameters to connect to external tool servers that implement the OpenAPI/MCPO protocol. The JSON must be properly formatted or it will fallback to an empty array. Example: [ { "type": "openapi", "url": "example-url", "spec_type": "url", "spec": "", "path": "openapi.json", "auth_type": "none", "key": "", "config": { "enable": true }, "info": { "id": "", "name": "example-server", "description": "MCP server description." } }] Persistence: This environment variable is a PersistentConfig variable. warningThe JSON data structure of TOOL_SERVER_CONNECTIONS might evolve over time as new features are added. Autocomplete‚Äã ENABLE_AUTOCOMPLETE_GENERATION‚Äã Type: bool Default: True Description: Enables or disables autocomplete generation. Persistence: This environment variable is a PersistentConfig variable. infoWhen enabling ENABLE_AUTOCOMPLETE_GENERATION, ensure that you also configure AUTOCOMPLETE_GENERATION_INPUT_MAX_LENGTH and AUTOCOMPLETE_GENERATION_PROMPT_TEMPLATE accordingly. AUTOCOMPLETE_GENERATION_INPUT_MAX_LENGTH‚Äã Type: int Default: -1 Description: Sets the maximum input length for autocomplete generation. Persistence: This environment variable is a PersistentConfig variable. AUTOCOMPLETE_GENERATION_PROMPT_TEMPLATE‚Äã Type: str Default: The value of the DEFAULT_AUTOCOMPLETE_GENERATION_PROMPT_TEMPLATE environment variable. DEFAULT_AUTOCOMPLETE_GENERATION_PROMPT_TEMPLATE: ### Task:You are an autocompletion system. Continue the text in `<text>` based on the **completion type** in `<type>` and the given language.### **Instructions**:1. Analyze `<text>` for context and meaning.2. Use `<type>` to guide your output: - **General**: Provide a natural, concise continuation. - **Search Query**: Complete as if generating a realistic search query.3. Start as if you are directly continuing `<text>`. Do **not** repeat, paraphrase, or respond as a model. Simply complete the text.4. Ensure the continuation: - Flows naturally from `<text>`. - Avoids repetition, overexplaining, or unrelated ideas.5. If unsure, return: `{ "text": "" }`.### **Output Rules**:- Respond only in JSON format: `{ "text": "<your_completion>" }`.### **Examples**:#### Example 1:Input:<type>General</type><text>The sun was setting over the horizon, painting the sky</text>Output:{ "text": "with vibrant shades of orange and pink." }#### Example 2:Input:<type>Search Query</type><text>Top-rated restaurants in</text>Output:{ "text": "New York City for Italian cuisine." }---### Context:<chat_history>{{MESSAGES:END:6}}</chat_history><type>{{TYPE}}</type><text>{{PROMPT}}</text>#### Output: Description: Sets the prompt template for autocomplete generation. Persistence: This environment variable is a PersistentConfig variable. Evaluation Arena Model‚Äã ENABLE_EVALUATION_ARENA_MODELS‚Äã Type: bool Default: True Description: Enables or disables evaluation arena models. Persistence: This environment variable is a PersistentConfig variable. ENABLE_MESSAGE_RATING‚Äã Type: bool Default: True Description: Enables message rating feature. Persistence: This environment variable is a PersistentConfig variable. ENABLE_COMMUNITY_SHARING‚Äã Type: bool Default: True Description: Controls whether users are shown the share to community button. Persistence: This environment variable is a PersistentConfig variable. Tags Generation‚Äã ENABLE_TAGS_GENERATION‚Äã Type: bool Default: True Description: Enables or disables tag generation. Persistence: This environment variable is a PersistentConfig variable. TAGS_GENERATION_PROMPT_TEMPLATE‚Äã Type: str Default: The value of DEFAULT_TAGS_GENERATION_PROMPT_TEMPLATE environment variable. DEFAULT_TAGS_GENERATION_PROMPT_TEMPLATE: ### Task:Generate 1-3 broad tags categorizing the main themes of the chat history, along with 1-3 more specific subtopic tags.### Guidelines:- Start with high-level domains (e.g., Science, Technology, Philosophy, Arts, Politics, Business, Health, Sports, Entertainment, Education)- Consider including relevant subfields/subdomains if they are strongly represented throughout the conversation- If content is too short (less than 3 messages) or too diverse, use only ["General"]- Use the chat's primary language; default to English if multilingual- Prioritize accuracy over specificity### Output:JSON format: { "tags": ["tag1", "tag2", "tag3"] }### Chat History:<chat_history>{{MESSAGES:END:6}}</chat_history> Description: Sets the prompt template for tag generation. Persistence: This environment variable is a PersistentConfig variable. API Key Endpoint Restrictions‚Äã ENABLE_API_KEYS‚Äã Type: bool Default: False Description: Enables the API key creation feature, allowing users to generate API keys for programmatic access to Open WebUI. Persistence: This environment variable is a PersistentConfig variable. infoThis variable replaces the deprecated ENABLE_API_KEY environment variable. infoFor API Key creation (and the API keys themselves) to work, you not only need to enable it globally, but also give specific user groups the permission for it ENABLE_API_KEYS_ENDPOINT_RESTRICTIONS‚Äã Type: bool Default: False Description: Enables API key endpoint restrictions for added security and configurability, allowing administrators to limit which endpoints can be accessed using API keys. Persistence: This environment variable is a PersistentConfig variable. infoThis variable replaces the deprecated ENABLE_API_KEY_ENDPOINT_RESTRICTIONS environment variable. API_KEYS_ALLOWED_ENDPOINTS‚Äã Type: str Description: Specifies a comma-separated list of allowed API endpoints when API key endpoint restrictions are enabled. Example: /api/v1/messages,/api/v1/channels,/api/v1/chat/completions Persistence: This environment variable is a PersistentConfig variable. noteThe value of API_KEYS_ALLOWED_ENDPOINTS should be a comma-separated list of endpoint URLs, such as /api/v1/messages, /api/v1/channels. infoThis variable replaces the deprecated API_KEY_ALLOWED_ENDPOINTS environment variable. JWT_EXPIRES_IN‚Äã Type: str Default: 4w Description: Sets the JWT expiration time in seconds. Valid time units: s, m, h, d, w or -1 for no expiration. Persistence: This environment variable is a PersistentConfig variable. warningSetting JWT_EXPIRES_IN to -1 disables JWT expiration, making issued tokens valid forever. This is extremely dangerous in production and exposes your system to severe security risks if tokens are leaked or compromised.Always set a reasonable expiration time in production environments (e.g., 3600s, 1h, 7d etc.) to limit the lifespan of authentication tokens.NEVER use -1 in a production environment.If you have already deployed with JWT_EXPIRES_IN=-1, you can rotate or change your WEBUI_SECRET_KEY to immediately invalidate all existing tokens. Security Variables‚Äã ENABLE_FORWARD_USER_INFO_HEADERS‚Äã type: bool Default: False Description: Forwards user information (name, ID, email, role and chat-id) as X-headers to OpenAI API and Ollama API. If enabled, the following headers are forwarded: X-OpenWebUI-User-Name X-OpenWebUI-User-Id X-OpenWebUI-User-Email X-OpenWebUI-User-Role X-OpenWebUI-Chat-Id ENABLE_WEB_LOADER_SSL_VERIFICATION‚Äã Type: bool Default: True Description: Bypass SSL Verification for RAG on Websites. Persistence: This environment variable is a PersistentConfig variable. WEBUI_SESSION_COOKIE_SAME_SITE‚Äã Type: str Options: lax - Sets the SameSite attribute to lax, allowing session cookies to be sent with requests initiated by third-party websites. strict - Sets the SameSite attribute to strict, blocking session cookies from being sent with requests initiated by third-party websites. none - Sets the SameSite attribute to none, allowing session cookies to be sent with requests initiated by third-party websites, but only over HTTPS. Default: lax Description: Sets the SameSite attribute for session cookies. warningWhen ENABLE_OAUTH_SIGNUP is enabled, setting WEBUI_SESSION_COOKIE_SAME_SITE to strict can cause login failures. This is because Open WebUI uses a session cookie to validate the callback from the OAuth provider, which helps prevent CSRF attacks.However, a strict session cookie is not sent with the callback request, leading to potential login issues. If you experience this problem, use the default lax value instead. WEBUI_SESSION_COOKIE_SECURE‚Äã Type: bool Default: False Description: Sets the Secure attribute for session cookies if set to True. WEBUI_AUTH_COOKIE_SAME_SITE‚Äã Type: str Options: lax - Sets the SameSite attribute to lax, allowing auth cookies to be sent with requests initiated by third-party websites. strict - Sets the SameSite attribute to strict, blocking auth cookies from being sent with requests initiated by third-party websites. none - Sets the SameSite attribute to none, allowing auth cookies to be sent with requests initiated by third-party websites, but only over HTTPS. Default: lax Description: Sets the SameSite attribute for auth cookies. infoIf the value is not set, WEBUI_SESSION_COOKIE_SAME_SITE will be used as a fallback. WEBUI_AUTH_COOKIE_SECURE‚Äã Type: bool Default: False Description: Sets the Secure attribute for auth cookies if set to True. infoIf the value is not set, WEBUI_SESSION_COOKIE_SECURE will be used as a fallback. WEBUI_AUTH‚Äã Type: bool Default: True Description: This setting enables or disables authentication. dangerIf set to False, authentication will be disabled for your Open WebUI instance. However, it's important to note that turning off authentication is only possible for fresh installations without any existing users. If there are already users registered, you cannot disable authentication directly. Ensure that no users are present in the database if you intend to turn off WEBUI_AUTH. ENABLE_PASSWORD_VALIDATION‚Äã Type: bool Default: False Description: Enables password complexity validation for user accounts. When enabled, passwords must meet the complexity requirements defined by PASSWORD_VALIDATION_REGEX_PATTERN during signup, password updates, and user creation operations. This helps enforce stronger password policies across the application. infoPassword validation is applied to: New user registration (signup) Password changes through user settings Admin-initiated user creation Password resets Existing users with passwords that don't meet the new requirements are not automatically forced to update their passwords, but will need to meet the requirements when they next change their password. PASSWORD_VALIDATION_REGEX_PATTERN‚Äã Type: str Default: ^(?=.*[a-z])(?=.*[A-Z])(?=.*\d)(?=.*[^\w\s]).{8,}$ Description: Regular expression pattern used to validate password complexity when ENABLE_PASSWORD_VALIDATION is enabled. The default pattern requires passwords to be at least 8 characters long and contain at least one uppercase letter, one lowercase letter, one digit, and one special character. warningCustom Pattern ConsiderationsWhen defining a custom regex pattern, ensure it: Is a valid regular expression that Python's re module can compile Balances security requirements with user experience Is thoroughly tested before deployment to avoid locking users out Invalid regex patterns will cause password validation to fail, potentially preventing user registration and password changes. WEBUI_SECRET_KEY‚Äã Type: str Default: t0p-s3cr3t Docker Default: Randomly generated on first start Description: Overrides the randomly generated string used for JSON Web Token and encryption of sensitive data (like OAuth tokens for MCP). Critical for Docker/ProductionYou MUST set WEBUI_SECRET_KEY to a secure, persistent value.If you do NOT set this: It will be randomly generated each time the container restarts/recreates. All OAuth sessions will become invalid. MCP Tools will break (Error: Error decrypting tokens) because they cannot decrypt the tokens stored with the previous key. You will be logged out. Do not leave this unset in production. warningRequired for Multi-Worker and Multi-Node Deployments AND HIGHLY RECOMMENDED IN SINGLE-WORKER ENVIRONMENTSWhen deploying Open WebUI with UVICORN_WORKERS > 1 or in a multi-node/worker cluster with a load balancer (e.g. helm/kubectl/kubernetes/k8s, you must set this variable. Without it, the following issues will occur: Session management will fail across workers Application state will be inconsistent between instances Websocket connections will not function properly in distributed setups Users may experience intermittent authentication failures ENABLE_VERSION_UPDATE_CHECK‚Äã Type: bool Default: True Description: When enabled, the application makes automatic update checks and notifies you about version updates. infoIf OFFLINE_MODE is enabled, this ENABLE_VERSION_UPDATE_CHECK flag is always set to false automatically. OFFLINE_MODE‚Äã Type: bool Default: False Description: Disables Open WebUI's network connections for update checks and automatic model downloads. infoDisabled when enabled: Automatic version update checks (see flag ENABLE_VERSION_UPDATE_CHECK) Downloads of embedding models from Hugging Face Hub If you did not download an embedding model prior to activating OFFLINE_MODE any RAG, web search and document analysis functionality may not work properly Update notifications in the UI (see flag ENABLE_VERSION_UPDATE_CHECK) Still functional: External LLM API connections (OpenAI, etc.) OAuth authentication providers Web search and RAG with external APIs Read more about offline mode in the offline mode guide. HF_HUB_OFFLINE‚Äã Type: int Default: 0 Description: Tells Hugging Face whether we want to launch in offline mode, so to not connect to hugging face and prevent all automatic model downloads infoDownloads of models, sentence transformers and other configurable items will NOT WORK when this is set to 1. RAG will also not work on a default installation, if this is set to True. RESET_CONFIG_ON_START‚Äã Type: bool Default: False Description: Resets the config.json file on startup. SAFE_MODE‚Äã Type: bool Default: False Description: Enables safe mode, which disables potentially unsafe features, deactivating all functions. CORS_ALLOW_ORIGIN‚Äã Type: str Default: * Description: Sets the allowed origins for Cross-Origin Resource Sharing (CORS). Smicolon ';' separated list of allowed origins. warningThis variable is required to be set, otherwise you may experience Websocket issues and weird "{}" responses or "Unexpected token 'd', "data: {"id"... is not valid JSON". infoIf you experience Websocket issues, check the logs of Open WebUI. If you see lines like this engineio.base_server:_log_error_once:354 - https://yourdomain.com is not an accepted origin. then you need to configure your CORS_ALLOW_ORIGIN more broadly.Example: CORS_ALLOW_ORIGIN: "https://yourdomain.com;http://yourdomain.com;https://yourhostname;http://youripaddress;http://localhost:3000"Add all valid IPs, Domains and Hostnames one might access your Open WebUI to the variable. Once you did, no more websocket issues or warnings in the console should occur. CORS_ALLOW_CUSTOM_SCHEME‚Äã Type str Default: "" (empty string) Description: Sets a list of further allowed schemes for Cross-Origin Resource Sharing (CORS). Allows you to specify additional custom URL schemes, beyond the standard http and https, that are permitted as valid origins for Cross-Origin Resource Sharing (CORS). infoThis is particularly useful for scenarios such as: Integrating with desktop applications that use custom protocols (e.g., app://, custom-app-scheme://). Local development environments or testing setups that might employ non-standard schemes (e.g., file:// if applicable, or electron://). Provide a semicolon-separated list of scheme names without the ://. For example: app;file;electron;my-custom-scheme.When configured, these custom schemes will be validated alongside http and https for any origins specified in CORS_ALLOW_ORIGIN. RAG_EMBEDDING_MODEL_TRUST_REMOTE_CODE‚Äã Type: bool Default: False Description: Determines whether to allow custom models defined on the Hub in their own modeling files. RAG_RERANKING_MODEL_TRUST_REMOTE_CODE‚Äã Type: bool Default: False Description: Determines whether to allow custom models defined on the Hub in their own. modeling files for reranking. RAG_EMBEDDING_MODEL_AUTO_UPDATE‚Äã Type: bool Default: True Description: Toggles automatic update of the Sentence-Transformer model. RAG_RERANKING_MODEL_AUTO_UPDATE‚Äã Type: bool Default: True Description: Toggles automatic update of the reranking model. Vector Database‚Äã VECTOR_DB‚Äã Type: str Options: chroma, elasticsearch, milvus, opensearch, pgvector, qdrant, pinecone, s3vector, oracle23ai, weaviate Default: chroma Description: Specifies which vector database system to use. This setting determines which vector storage system will be used for managing embeddings. notePostgreSQL Dependencies To use pgvector, ensure you have PostgreSQL dependencies installed:pip install open-webui[all] infoOnly PGVector and ChromaDB will be consistently maintained by the Open WebUI team. The other vector stores are community-added vector databases. ChromaDB‚Äã CHROMA_TENANT‚Äã Type: str Default: The value of chromadb.DEFAULT_TENANT (a constant in the chromadb module) Description: Sets the tenant for ChromaDB to use for RAG embeddings. CHROMA_DATABASE‚Äã Type: str Default: The value of chromadb.DEFAULT_DATABASE (a constant in the chromadb module) Description: Sets the database in the ChromaDB tenant to use for RAG embeddings. CHROMA_HTTP_HOST‚Äã Type: str Description: Specifies the hostname of a remote ChromaDB Server. Uses a local ChromaDB instance if not set. CHROMA_HTTP_PORT‚Äã Type: int Default: 8000 Description: Specifies the port of a remote ChromaDB Server. CHROMA_HTTP_HEADERS‚Äã Type: str Description: A comma-separated list of HTTP headers to include with every ChromaDB request. Example: Authorization=Bearer heuhagfuahefj,User-Agent=OpenWebUI. CHROMA_HTTP_SSL‚Äã Type: bool Default: False Description: Controls whether or not SSL is used for ChromaDB Server connections. CHROMA_CLIENT_AUTH_PROVIDER‚Äã Type: str Description: Specifies an authentication provider for remote ChromaDB Server. Example: chromadb.auth.basic_authn.BasicAuthClientProvider CHROMA_CLIENT_AUTH_CREDENTIALS‚Äã Type: str Description: Specifies auth credentials for remote ChromaDB Server. Example: username:password Elasticsearch‚Äã ELASTICSEARCH_API_KEY‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the Elasticsearch API key. Persistence: This environment variable is a PersistentConfig variable. ELASTICSEARCH_CA_CERTS‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the path to the CA certificates for Elasticsearch. Persistence: This environment variable is a PersistentConfig variable. ELASTICSEARCH_CLOUD_ID‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the Elasticsearch cloud ID. Persistence: This environment variable is a PersistentConfig variable. ELASTICSEARCH_INDEX_PREFIX‚Äã Type: str Default: open_webui_collections Description: Specifies the prefix for the Elasticsearch index. Persistence: This environment variable is a PersistentConfig variable. ELASTICSEARCH_PASSWORD‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the password for Elasticsearch. Persistence: This environment variable is a PersistentConfig variable. ELASTICSEARCH_URL‚Äã Type: str Default: https://localhost:9200 Description: Specifies the URL for the Elasticsearch instance. Persistence: This environment variable is a PersistentConfig variable. ELASTICSEARCH_USERNAME‚Äã Type: str Default: Empty string (' '), since None is set as default. Description: Specifies the username for Elasticsearch. Persistence: This environment variable is a PersistentConfig variable. Milvus‚Äã warningMilvus is not actively maintained by the Open WebUI team. It is an addition by the community and is maintained by the community. If you want to use Milvus, be careful when upgrading Open WebUI (crate backups and snapshots for rollbacks) in case internal changes in Open WebUI lead to breakage. MILVUS_URI (Required)‚Äã Type: str Default: ${DATA_DIR}/vector_db/milvus.db Example (Remote): http://your-server-ip:19530 Description: Specifies the URI for connecting to the Milvus vector database. This can point to a local or remote Milvus server based on the deployment configuration. MILVUS_DB‚Äã Type: str Default: default Example: default Description: Specifies the database to connect to within a Milvus instance. MILVUS_TOKEN (Required for remote connections with authentication)‚Äã Type: str Default: None Example: root:password (format: username:password) Description: Specifies an optional connection token for Milvus. Required when connecting to a remote Milvus server with authentication enabled. Format is username:password. MILVUS_INDEX_TYPE‚Äã Type: str Default: HNSW Options: AUTOINDEX, FLAT, IVF_FLAT, HNSW, DISKANN Description: Specifies the index type to use when creating a new collection in Milvus. AUTOINDEX is generally recommended for Milvus standalone. HNSW may offer better performance but requires a clustered Milvus setup and is not meant for standalone setups. Persistence: This environment variable is a PersistentConfig variable. MILVUS_METRIC_TYPE‚Äã Type: str Default: COSINE Options: COSINE, IP, L2 Description: Specifies the metric type for vector similarity search in Milvus. Persistence: This environment variable is a PersistentConfig variable. MILVUS_HNSW_M‚Äã Type: int Default: 16 Description: Specifies the M parameter for the HNSW index type in Milvus. This influences the number of bi-directional links created for each new element during construction. Only applicable if MILVUS_INDEX_TYPE is HNSW. Persistence: This environment variable is a PersistentConfig variable. MILVUS_HNSW_EFCONSTRUCTION‚Äã Type: int Default: 100 Description: Specifies the efConstruction parameter for the HNSW index type in Milvus. This influences the size of the dynamic list for the nearest neighbors during index construction. Only applicable if MILVUS_INDEX_TYPE is HNSW. Persistence: This environment variable is a PersistentConfig variable. MILVUS_IVF_FLAT_NLIST‚Äã Type: int Default: 128 Description: Specifies the nlist parameter for the IVF_FLAT index type in Milvus. This is the number of cluster units. Only applicable if MILVUS_INDEX_TYPE is IVF_FLAT. Persistence: This environment variable is a PersistentConfig variable. MILVUS_DISKANN_MAX_DEGREE‚Äã Type: int Default: 56 Description: Sets the max degree for Milvus if Milvus is in DISKANN indexing mode. Generally recommended to leave as is. MILVUS_DISKANN_SEARCH_LIST_SIZE‚Äã Type: int Default: 100 Description: Sets the Milvus DISKANN search list size. Generally recommended to leave as is. ENABLE_MILVUS_MULTITENANCY_MODE‚Äã Type: bool Default: false Description: Enables multitenancy pattern for Milvus collections management, which significantly reduces RAM usage and computational overhead by consolidating similar vector data structures. Controls whether Milvus uses multitenancy collection architecture. When enabled, all vector data is consolidated into 5 shared collections (memories, knowledge, files, web_search, hash_based) instead of creating individual collections per resource. Data isolation is achieved via a resource_id field rather than collection-level separation. infoBenefits of multitenancy mode: Significantly reduced RAM consumption (5 collections vs potentially hundreds) Lower computational overhead from collection management Faster cold-start times Reduced index maintenance burden Technical implementation: All memories go into {prefix}_memories All knowledge bases go into {prefix}_knowledge All uploaded files go into {prefix}_files Web search results go into {prefix}_web_search Hash-based collections go into {prefix}_hash_based Each entry includes a resource_id field matching the original collection name Queries automatically filter by resource_id to maintain data isolation Collection VariableDefault Name (Suffix)Trigger / Routing Logic in the CodePurposeHASH_BASED_COLLECTION_hash_basedCollection name is a 63-char hex string (SHA256 hash).Caching direct URL fetches (Websites) with the # feature.MEMORY_COLLECTION_memoriesCollection name starts with user-memory-.Storing user-specific long-term memories of the experimental memory system.FILE_COLLECTION_filesCollection name starts with file-.Storing uploaded documents (PDFs, DOCX, etc.).WEB_SEARCH_COLLECTION_web_searchCollection name starts with web-search-.Storing transient results from search engine queries.KNOWLEDGE_COLLECTION_knowledgeEverything else (Default fallback).Storing explicitly created Knowledge Bases. infoMigration from Legacy Mode to MultitenancyWhat happens when you enable multitenancy when you already have a normal milvus database with data in it: Existing collections (pattern: open_webui_{collection_name}) remain in Milvus but become inaccessible to Open WebUI New data is written to the 5 shared multitenancy collections Application treats knowledge bases as empty until reindexed Files and memories are NOT automatically migrated to the new collection schema and will appear missing Clean migration path from normal Milvus to multitenancy milvus: Before enabling multitenancy, export any critical knowledge content from the UI if possible Set ENABLE_MILVUS_MULTITENANCY_MODE=true and restart Open WebUI Navigate to Admin Settings > Documents > Click Reindex Knowledge Base This rebuilds ONLY knowledge base vectors into the new multitenancy collections Files, user memories, and web search history are NOT migrated by this operationVerify knowledge bases are accessible and functional Re-upload files if file-based retrieval is critical (file metadata remains but vectors are not migrated) User chat memories will need to be regenerated through new conversations Cleaning up legacy collections: After successful migration (from milvus to multitenancy milvus), legacy collections still consume resources. Remove them manually: Connect to Milvus using the native client (pymilvus or Attu UI) Delete all old collections Current UI limitations: No one-click "migrate and cleanup" button exists Vector DB reset from UI (Admin Settings > Documents > Reset Vector Storage/Knowledge) only affects the active mode's collections Legacy collections require manual cleanup via Milvus client tools warningCritical ConsiderationsBefore enabling multitenancy on an existing installation: Data loss risk: File vectors and user memory vectors are NOT migrated automatically. Only knowledge base content can be reindexed (migrated). Collection naming dependency: Multitenancy relies on Open WebUI's internal collection naming conventions (user-memory-, file-, web-search-, hash patterns). If Open WebUI changes these conventions in future updates, multitenancy routing may break, causing data corruption or incorrect data retrieval across isolated resources. No automatic rollback: Disabling multitenancy after data is written will not restore access to the shared collections. Data would need manual extraction and re-import. For fresh installations, no migration concerns existFor existing installations with valuable data: Do not migrate to multitenancy mode if you do not want to handle migration and risk data loss Understand that files and memories require re-upload/regeneration Test migration on a backup/staging environment first Consider if RAM savings justify the migration effort for your use case To perform a full reset and switch to multitenancy: Backup any critical knowledge base content externally Navigate to Admin Settings > Documents Click Reset Vector Storage/Knowledge (this deletes all active mode collections and stored knowledge metadata) Set ENABLE_MILVUS_MULTITENANCY_MODE=true Restart Open WebUI Re-upload/re-create knowledge bases from scratch warningThe mapping of multitenancy relies on current Open WebUI naming conventions for collection names.If Open WebUI changes how it generates collection names (e.g., "user-memory-" prefix, "file-" prefix, web search patterns, or hash formats), this mapping will break and route data to incorrect collections. POTENTIALLY CAUSING HUGE DATA CORRUPTION, DATA CONSISTENCY ISSUES AND INCORRECT DATA MAPPING INSIDE THE DATABASE.If you use Multitenancy Mode, you should always check for any changes to the collection names and data mapping before upgrading, and upgrade carefully (snapshots and backups for rollbacks)! MILVUS_COLLECTION_PREFIX‚Äã Type: str Default: open_webui Description: Sets the prefix for Milvus collection names. In multitenancy mode, collections become {prefix}_memories, {prefix}_knowledge, etc. In legacy mode, collections are {prefix}_{collection_name}. Changing this value creates an entirely separate namespace‚Äîexisting collections with the old prefix become invisible to Open WebUI but remain in Milvus consuming resources. Use this for true multi-instance isolation on a shared Milvus server, not for migration between modes. Milvus only accepts underscores, hyphens/dashes are not possible and will cause errors. OpenSearch‚Äã OPENSEARCH_CERT_VERIFY‚Äã Type: bool Default: False Description: Enables or disables OpenSearch certificate verification. OPENSEARCH_PASSWORD‚Äã Type: str Default: None Description: Sets the password for OpenSearch. OPENSEARCH_SSL‚Äã Type: bool Default: True Description: Enables or disables SSL for OpenSearch. OPENSEARCH_URI‚Äã Type: str Default: https://localhost:9200 Description: Sets the URI for OpenSearch. OPENSEARCH_USERNAME‚Äã Type: str Default: None Description: Sets the username for OpenSearch. PGVector‚Äã notePostgreSQL Dependencies To use pgvector, ensure you have PostgreSQL dependencies installed:pip install open-webui[all] PGVECTOR_DB_URL‚Äã Type: str Default: The value of the DATABASE_URL environment variable Description: Sets the database URL for model storage. PGVECTOR_INITIALIZE_MAX_VECTOR_LENGTH‚Äã Type: str Default: 1536 Description: Specifies the maximum vector length for PGVector initialization. PGVECTOR_CREATE_EXTENSION‚Äã Type: str Default true Description: Creates the vector extension in the database infoIf set to false, open-webui will assume the postgreSQL database where embeddings will be stored is pre-configured with the vector extension. This also allows open-webui to run as a non superuser database user. PGVECTOR_INDEX_METHOD‚Äã Type: str Options: ivfflat - Uses inverted file with flat compression, better for datasets with many dimensions. hnsw - Uses Hierarchical Navigable Small World graphs, generally provides better query performance. Default: Not specified (pgvector will use its default) Description: Specifies the index method for pgvector. The choice affects query performance and index build time. Persistence: This environment variable is a PersistentConfig variable. infoWhen choosing an index method, consider your dataset size and query patterns. HNSW generally provides better query performance but uses more memory, while IVFFlat can be more memory-efficient for larger datasets. PGVECTOR_HNSW_M‚Äã Type: int Default: 16 Description: HNSW index parameter that controls the maximum number of bi-directional connections per layer during index construction. Higher values improve recall but increase index size and build time. Only applicable when PGVECTOR_INDEX_METHOD is set to hnsw. Persistence: This environment variable is a PersistentConfig variable. PGVECTOR_HNSW_EF_CONSTRUCTION‚Äã Type: int Default: 64 Description: HNSW index parameter that controls the size of the dynamic candidate list during index construction. Higher values improve index quality but increase build time. Only applicable when PGVECTOR_INDEX_METHOD is set to hnsw. Persistence: This environment variable is a PersistentConfig variable. PGVECTOR_IVFFLAT_LISTS‚Äã Type: int Default: 100 Description: IVFFlat index parameter that specifies the number of inverted lists (clusters) to create. A good starting point is rows / 1000 for up to 1M rows and sqrt(rows) for over 1M rows. Only applicable when PGVECTOR_INDEX_METHOD is set to ivfflat. Persistence: This environment variable is a PersistentConfig variable. infoFor IVFFlat indexes, choosing the right number of lists is crucial for query performance. Too few lists will result in slow queries, while too many will increase index size without significant performance gains. PGVECTOR_USE_HALFVEC‚Äã Type: bool Default: False Description: Enables the use of halfvec data type instead of vector for storing embeddings. Required when PGVECTOR_INITIALIZE_MAX_VECTOR_LENGTH exceeds 2000 dimensions, as the vector type has a 2000-dimension limit. PGVECTOR_PGCRYPTO‚Äã Type: bool Default: False Description: Enables pgcrypto extension for encrypting sensitive data within PGVector. When enabled, PGVECTOR_PGCRYPTO_KEY must be set. PGVECTOR_PGCRYPTO_KEY‚Äã Type: str Default: None Description: Specifies the encryption key for pgcrypto when PGVECTOR_PGCRYPTO is enabled. Must be a secure, randomly generated key. PGVECTOR_POOL_SIZE‚Äã Type: int Default: None Description: Sets the number of connections to maintain in the PGVector database connection pool. If not set, uses SQLAlchemy defaults. PGVECTOR_POOL_MAX_OVERFLOW‚Äã Type: int Default: 0 Description: Specifies the maximum number of connections that can be created beyond PGVECTOR_POOL_SIZE when the pool is exhausted. PGVECTOR_POOL_TIMEOUT‚Äã Type: int Default: 30 Description: Sets the timeout in seconds for acquiring a connection from the PGVector pool. PGVECTOR_POOL_RECYCLE‚Äã Type: int Default: 3600 Description: Specifies the time in seconds after which connections are recycled in the PGVector pool to prevent stale connections. Qdrant‚Äã warningQdrant is not actively maintained by the Open WebUI team. It is an addition by the community and is maintained by the community. If you want to use Qdrant, be careful when upgrading Open WebUI (crate backups and snapshots for rollbacks) in case internal changes in Open WebUI lead to breakage. QDRANT_API_KEY‚Äã Type: str Description: Sets the API key for Qdrant. QDRANT_URI‚Äã Type: str Description: Sets the URI for Qdrant. QDRANT_ON_DISK‚Äã Type: bool Default: False Description: Enable the usage of memmap(also known as on-disk) storage QDRANT_PREFER_GRPC‚Äã Type: bool Default: False Description: Use gPRC interface whenever possible. infoIf set to True, and QDRANT_URI points to a self-hosted server with TLS enabled and certificate signed by a private CA, set the environment variable GRPC_DEFAULT_SSL_ROOTS_FILE_PATH to the path of your PEM-encoded CA certificates file. See the gRPC Core Docs for more information. QDRANT_GRPC_PORT‚Äã Type: int Default: 6334 Description: Sets the gRPC port number for Qdrant. QDRANT_TIMEOUT‚Äã Type: int Default: 5 Description: Sets the timeout in seconds for all requests made to the Qdrant server, helping to prevent long-running queries from stalling the application. QDRANT_HNSW_M‚Äã Type: int Default: 16 Description: Controls the HNSW (Hierarchical Navigable Small World) index construction. In standard mode, this sets the m parameter. In multi-tenancy mode, this value is used for the payload_m parameter to build indexes on the payload, as the global m is disabled for performance, following Qdrant best practices. ENABLE_QDRANT_MULTITENANCY_MODE‚Äã Type: bool Default: True Description: Enables multitenancy pattern for Qdrant collections management, which significantly reduces RAM usage and computational overhead by consolidating similar vector data structures. Recommend turn on infoThis will disconect all Qdrant collections created in the previous pattern, which is non-multitenancy. Go to Admin Settings > Documents > Reindex Knowledge Base to migrate existing knowledges.The Qdrant collections created in the previous pattern will still consume resources.Currently, there is no button in the UI to only reset the vector DB. If you want to migrate knowledge to multitenancy: Remove all collections with the open_webui-knowledge prefix (or open_webui prefix to remove all collections related to Open WebUI) using the native Qdrant client Go to Admin Settings > Documents > Reindex Knowledge Base to migrate existing knowledge base Reindex Knowledge Base will ONLY migrate the knowledge base dangerIf you decide to use the multitenancy pattern as your default and you don't need to migrate old knowledge, go to Admin Settings > Documents to reset vector and knowledge, which will delete all collections with the open_webui prefix and all stored knowledge. warningThe mapping of multitenancy relies on current Open WebUI naming conventions for collection names.If Open WebUI changes how it generates collection names (e.g., "user-memory-" prefix, "file-" prefix, web search patterns, or hash formats), this mapping will break and route data to incorrect collections. POTENTIALLY CAUSING HUGE DATA CORRUPTION, DATA CONSISTENCY ISSUES AND INCORRECT DATA MAPPING INSIDE THE DATABASE.If you use Multitenancy Mode, you should always check for any changes to the collection names and data mapping before upgrading, and upgrade carefully (snapshots and backups for rollbacks)! QDRANT_COLLECTION_PREFIX‚Äã Type: str Default: open-webui Description: Sets the prefix for Qdrant collection names. Useful for namespacing or isolating collections, especially in multitenancy mode. Changing this value will cause the application to use a different set of collections in Qdrant. Existing collections with a different prefix will not be affected. Pinecone‚Äã When using Pinecone as the vector store, the following environment variables are used to control its behavior. Make sure to set these variables in your .env file or deployment environment. PINECONE_API_KEY‚Äã Type: str Default: None Description: Sets the API key used to authenticate with the Pinecone service. PINECONE_ENVIRONMENT‚Äã Type: str Default: None Description: Specifies the Pinecone environment to connect to (e.g., us-west1-gcp, gcp-starter, etc.). PINECONE_INDEX_NAME‚Äã Type: str Default: open-webui-index Description: Defines the name of the Pinecone index that will be used to store and query vector embeddings. PINECONE_DIMENSION‚Äã Type: int Default: 1536 Description: The dimensionality of the vector embeddings. Must match the dimension expected by the index (commonly 768, 1024, 1536, or 3072 based on model used). PINECONE_METRIC‚Äã Type: str Default: cosine Options: cosine, dotproduct, euclidean Description: Specifies the similarity metric to use for vector comparisons within the Pinecone index. PINECONE_CLOUD‚Äã Type: str Default: aws Options: aws, gcp, azure Description: Specifies the cloud provider where the Pinecone index is hosted. Weaviate‚Äã WEAVIATE_HTTP_HOST‚Äã Type: str Default: Empty string (' ') Description: Specifies the hostname of the Weaviate server for HTTP connections. WEAVIATE_HTTP_PORT‚Äã Type: int Default: 8080 Description: Specifies the HTTP port for connecting to the Weaviate server. WEAVIATE_GRPC_PORT‚Äã Type: int Default: 50051 Description: Specifies the gRPC port for connecting to the Weaviate server. WEAVIATE_API_KEY‚Äã Type: str Default: None Description: Sets the API key for authenticating with Weaviate server. Oracle 23ai Vector Search (oracle23ai)‚Äã ORACLE_DB_USE_WALLET‚Äã Type: bool Default: false Description: Determines the connection method to the Oracle Database. Set to false for direct connections (e.g., to Oracle Database 23ai Free or DBCS instances) using host, port, and service name in ORACLE_DB_DSN. Set to true for wallet-based connections (e.g., to Oracle Autonomous Database (ADW/ATP)). When true, ORACLE_WALLET_DIR and ORACLE_WALLET_PASSWORD must also be configured. ORACLE_DB_USER‚Äã Type: str Default: DEMOUSER Description: Specifies the username used to connect to the Oracle Database. ORACLE_DB_PASSWORD‚Äã Type: str Default: Welcome123456 Description: Specifies the password for the ORACLE_DB_USER. ORACLE_DB_DSN‚Äã Type: str Default: localhost:1521/FREEPDB1 Description: Defines the Data Source Name for the Oracle Database connection. If ORACLE_DB_USE_WALLET is false, this should be in the format hostname:port/service_name (e.g., localhost:1521/FREEPDB1). If ORACLE_DB_USE_WALLET is true, this can be a TNS alias (e.g., medium for ADW/ATP), or a full connection string. ORACLE_WALLET_DIR‚Äã Type: str Default: Empty string (' ') Description: Required when ORACLE_DB_USE_WALLET is true. Specifies the absolute path to the directory containing the Oracle Cloud Wallet files (e.g., cwallet.sso, sqlnet.ora, tnsnames.ora). ORACLE_WALLET_PASSWORD‚Äã Type: str Default: Empty string (' ') Description: Required when ORACLE_DB_USE_WALLET is true. Specifies the password for the Oracle Cloud Wallet. ORACLE_VECTOR_LENGTH‚Äã Type: int Default: 768 Description: Sets the expected dimension or length of the vector embeddings stored in the Oracle Database. This must match the embedding model used. ORACLE_DB_POOL_MIN‚Äã Type: int Default: 2 Description: The minimum number of connections to maintain in the Oracle Database connection pool. ORACLE_DB_POOL_MAX‚Äã Type: int Default: 10 Description: The maximum number of connections allowed in the Oracle Database connection pool. ORACLE_DB_POOL_INCREMENT‚Äã Type: int Default: 1 Description: The number of connections to create when the pool needs to grow. S3 Vector Bucket‚Äã When using S3 Vector Bucket as the vector store, the following environment variables are used to control its behavior. Make sure to set these variables in your .env file or deployment environment. infoNote: this configuration assumes that AWS credentials will be available to your Open WebUI environment. This could be through environment variables like AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY, or through IAM role permissions. S3_VECTOR_BUCKET_NAME‚Äã Type: str Description: Specifies the name of the S3 Vector Bucket to store vectors in. S3_VECTOR_REGION‚Äã Type: str Description: Specifies the AWS region where the S3 Vector Bucket is hosted. RAG Content Extraction Engine‚Äã CONTENT_EXTRACTION_ENGINE‚Äã Type: str Options: Leave empty to use default external - Use external loader tika - Use a local Apache Tika server docling - Use Docling engine document_intelligence - Use Document Intelligence engine mistral_ocr - Use Mistral OCR engine mineru Description: Sets the content extraction engine to use for document ingestion. Persistence: This environment variable is a PersistentConfig variable. MISTRAL_OCR_API_KEY‚Äã Type: str Default: None Description: Specifies the Mistral OCR API key to use. Persistence: This environment variable is a PersistentConfig variable. MISTRAL_OCR_API_BASE_URL‚Äã Type: str Default: https://api.mistral.ai/v1 Description: Configures custom Mistral OCR API endpoints for flexible deployment options, allowing users to point to self-hosted or alternative Mistral OCR instances. Persistence: This environment variable is a PersistentConfig variable. EXTERNAL_DOCUMENT_LOADER_URL‚Äã Type: str Default: None Description: Sets the URL for the external document loader service. Persistence: This environment variable is a PersistentConfig variable. EXTERNAL_DOCUMENT_LOADER_API_KEY‚Äã Type: str Default: None Description: Sets the API key for authenticating with the external document loader service. Persistence: This environment variable is a PersistentConfig variable. TIKA_SERVER_URL‚Äã Type: str Default: http://localhost:9998 Description: Sets the URL for the Apache Tika server. Persistence: This environment variable is a PersistentConfig variable. DOCLING_SERVER_URL‚Äã Type: str Default: http://docling:5001 Description: Specifies the URL for the Docling server. Requires Docling version 2.0.0 or later for full compatibility with the new parameter-based configuration system. Persistence: This environment variable is a PersistentConfig variable. warningDocling 2.0.0+ RequiredThe Docling integration has been refactored to use server-side parameter passing. If you are using Docling: Upgrade to Docling server version 2.0.0 or later Migrate all individual DOCLING_* configuration variables to the DOCLING_PARAMS JSON object Remove all deprecated DOCLING_* environment variables from your configuration Add DOCLING_API_KEY if your server requires authentication The old individual environment variables (DOCLING_OCR_ENGINE, DOCLING_OCR_LANG, etc.) are no longer supported and will be ignored. DOCLING_API_KEY‚Äã Type: str Default: None Description: Sets the API key for authenticating with the Docling server. Required when the Docling server has authentication enabled. Persistence: This environment variable is a PersistentConfig variable. DOCLING_PARAMS‚Äã Type: str (JSON) Default: {} Description: Specifies all Docling processing parameters in JSON format. This is the primary configuration method for Docling processing options. All previously individual Docling settings are now configured through this single JSON object. Supported Parameters: do_ocr (bool): Enable OCR processing. force_ocr (bool): Force OCR even when text layer exists. ocr_engine (str): OCR engine to use. Options: tesseract, easyocr, ocrmac, rapidocr, tesserocr. ocr_lang (list[str]): OCR language codes. Note: Format depends on engine (e.g., ["eng", "fra"] for Tesseract; ["en", "fr"] for EasyOCR). pdf_backend (str): PDF processing backend. Options: dlparse_v1, dlparse_v2, dlparse_v4, pypdfium2. table_mode (str): Table extraction mode. Options: fast, accurate. pipeline (str): Processing pipeline to use. Options: fast, standard. do_picture_description (bool): Enable image description generation. picture_description_mode (str): Mode for picture descriptions. Options: local, api. picture_description_local (str): Local model configuration object for picture descriptions. picture_description_api (str): API endpoint configuration object for picture descriptions. vlm_pipeline_model_api (str): Vision-language model API configuration. (e.g., openai://gpt-4o). Example: { "do_ocr": true, "ocr_engine": "tesseract", "ocr_lang": ["eng", "fra", "deu", "spa"], "force_ocr": false, "pdf_backend": "dlparse_v4", "table_mode": "accurate", "do_picture_description": true, "picture_description_mode": "api", "vlm_pipeline_model_api": "openai://gpt-4o"} tipdlparse vs dbparse: Note that the backend names use dlparse (Deep Learning Parse), not dbparse. For modern Docling (v2+), dlparse_v4 is generally recommended for the best balance of features. Persistence: This environment variable is a PersistentConfig variable. infoMigration from Individual Docling VariablesIf you were previously using individual DOCLING_* environment variables (such as DOCLING_OCR_ENGINE, DOCLING_OCR_LANG, etc.), these are now deprecated. You must migrate to using DOCLING_PARAMS as a single JSON configuration object.Example Migration:# Old configuration (deprecated)DOCLING_OCR_ENGINE=tesseractDOCLING_OCR_LANG=eng,fraDOCLING_DO_OCR=true# New configuration (required)DOCLING_PARAMS='{"do_ocr": true, "ocr_engine": "tesseract", "ocr_lang": "eng,fra"}' warningWhen setting this environment variable in a .env file, ensure proper JSON formatting and escape quotes as needed:DOCLING_PARAMS="{\"do_ocr\": true, \"ocr_engine\": \"tesseract\", \"ocr_lang\": \"eng,fra,deu,spa\"}" MINERU_API_TIMEOUT‚Äã Type: str Default: 300 Description: Sets the timeout in seconds for MinerU API requests during document processing. Persistence: This environment variable is a PersistentConfig variable. Retrieval Augmented Generation (RAG)‚Äã Core Configuration‚Äã RAG_EMBEDDING_ENGINE‚Äã Type: str Options: Leave empty for Default (SentenceTransformers) - Uses SentenceTransformers for embeddings. ollama - Uses the Ollama API for embeddings. openai - Uses the OpenAI API for embeddings. azure_openai - Uses Azure OpenAI Services for embeddings. Description: Selects an embedding engine to use for RAG. Persistence: This environment variable is a PersistentConfig variable. RAG_EMBEDDING_MODEL‚Äã Type: str Default: sentence-transformers/all-MiniLM-L6-v2 Description: Sets a model for embeddings. Locally, a Sentence-Transformer model is used. Persistence: This environment variable is a PersistentConfig variable. RAG_TOP_K‚Äã Type: int Default: 3 Description: Sets the default number of results to consider for the embedding when using RAG. Persistence: This environment variable is a PersistentConfig variable. RAG_TOP_K_RERANKER‚Äã Type: int Default: 3 Description: Sets the default number of results to consider for the reranker when using RAG. Persistence: This environment variable is a PersistentConfig variable. RAG_RELEVANCE_THRESHOLD‚Äã Type: float Default: 0.0 Description: Sets the relevance threshold to consider for documents when used with reranking. Persistence: This environment variable is a PersistentConfig variable. ENABLE_RAG_HYBRID_SEARCH‚Äã Type: bool Default: False Description: Enables the use of ensemble search with BM25 + ChromaDB, with reranking using sentence_transformers models. Persistence: This environment variable is a PersistentConfig variable. RAG_HYBRID_BM25_WEIGHT‚Äã Type: float Default: 0.5 Description: Sets the weight given to the keyword search (BM25) during hybrid search. 1 means only keyword search, 0 means only vector search. Persistence: This environment variable is a PersistentConfig variable. ENABLE_RAG_HYBRID_SEARCH_ENRICHED_TEXTS‚Äã Type: bool Default: False Description: Enhances BM25 hybrid search by enriching indexed text with document metadata including filenames, titles, sections, and snippets. This improves keyword recall for metadata-based queries, allowing searches to match on document names and structural elements in addition to content. Persistence: This environment variable is a PersistentConfig variable. infoEnabling this feature increases the text volume indexed by BM25, which may impact storage requirements and indexing performance. However, it significantly improves search results when users query based on document names, titles, or structural elements rather than just content. RAG_TEMPLATE‚Äã Type: str Default: The value of DEFAULT_RAG_TEMPLATE environment variable. DEFAULT_RAG_TEMPLATE: ### Task:Respond to the user query using the provided context, incorporating inline citations in the format [id] **only when the <source> tag includes an explicit id attribute** (e.g., <source id="1">).### Guidelines:- If you don't know the answer, clearly state that.- If uncertain, ask the user for clarification.- Respond in the same language as the user's query.- If the context is unreadable or of poor quality, inform the user and provide the best possible answer.- If the answer isn't present in the context but you possess the knowledge, explain this to the user and provide the answer using your own understanding.- **Only include inline citations using [id] (e.g., [1], [2]) when the <source> tag includes an id attribute.**- Do not cite if the <source> tag does not contain an id attribute.- Do not use XML tags in your response.- Ensure citations are concise and directly related to the information provided.### Example of Citation:If the user asks about a specific topic and the information is found in a source with a provided id attribute, the response should include the citation like in the following example:* "According to the study, the proposed method increases efficiency by 20% [1]."### Output:Provide a clear and direct response to the user's query, including inline citations in the format [id] only when the <source> tag with id attribute is present in the context.<context>{{CONTEXT}}</context><user_query>{{QUERY}}</user_query> Description: Template to use when injecting RAG documents into chat completion. Persistence: This environment variable is a PersistentConfig variable. Document Processing‚Äã CHUNK_SIZE‚Äã Type: int Default: 1000 Description: Sets the document chunk size for embeddings. Persistence: This environment variable is a PersistentConfig variable. CHUNK_OVERLAP‚Äã Type: int Default: 100 Description: Specifies how much overlap there should be between chunks. Persistence: This environment variable is a PersistentConfig variable. RAG_TEXT_SPLITTER‚Äã Type: str Options: character token markdown_header Default: character Description: Sets the text splitter for RAG models. Persistence: This environment variable is a PersistentConfig variable. TIKTOKEN_CACHE_DIR‚Äã Type: str Default: {CACHE_DIR}/tiktoken Description: Sets the directory for TikToken cache. TIKTOKEN_ENCODING_NAME‚Äã Type: str Default: cl100k_base Description: Sets the encoding name for TikToken. Persistence: This environment variable is a PersistentConfig variable. PDF_EXTRACT_IMAGES‚Äã Type: bool Default: False Description: Extracts images from PDFs using OCR when loading documents. Persistence: This environment variable is a PersistentConfig variable. RAG_FILE_MAX_SIZE‚Äã Type: int Description: Sets the maximum size of a file in megabytes that can be uploaded for document ingestion. Persistence: This environment variable is a PersistentConfig variable. RAG_FILE_MAX_COUNT‚Äã Type: int Description: Sets the maximum number of files that can be uploaded at once for document ingestion. Persistence: This environment variable is a PersistentConfig variable. RAG_ALLOWED_FILE_EXTENSIONS‚Äã Type: list of str Default: [] (which means all supported file types are allowed) Description: Specifies which file extensions are permitted for upload. ["pdf,docx,txt"] Persistence: This environment variable is a PersistentConfig variable. infoWhen configuring RAG_FILE_MAX_SIZE and RAG_FILE_MAX_COUNT, ensure that the values are reasonable to prevent excessive file uploads and potential performance issues. Embedding Engine Configuration‚Äã General Embedding Settings‚Äã RAG_EMBEDDING_BATCH_SIZE‚Äã Type: int Default: 1 Description: Controls how many text chunks are embedded in a single API request when using external embedding providers (Ollama, OpenAI, or Azure OpenAI). Higher values (20-100+; max 16000 (not recommended)) may process documents faster by sending less, but larger API requests. Some external APIs do not support batching or sending more than 1 chunk per request. In such casey you must leave this at 1. Default is 1 (safest option if the API does not support batching / more than 1 chunk per request). This setting only applies to external embedding engines, not the default SentenceTransformers engine. Persistence: This environment variable is a PersistentConfig variable. infoCheck if your API and embedding model supports batched processing. Only increase this variable's value if it does - otherwise you might run into unexpected issues. ENABLE_ASYNC_EMBEDDING‚Äã Type: bool Default: true Description: Runs embedding tasks asynchronously (parallelized) for maximum performance. Only works for Ollama, OpenAI and Azure OpenAI, does not affect sentence transformer setups. Persistence: This environment variable is a PersistentConfig variable. tipIt may be needed to increase the value of THREAD_POOL_SIZE if many other users are simultaneously using your Open WebUI instance while having async embeddings turned on to preventwarningEnabling this will potentially send thousands of requests per minute. If you are embedding locally, ensure that you can handle this amount of requests, otherwise turn this off to return to sequential embedding (slower but will always work). If you are embedding externally via API, ensure your rate limits are high enough to handle parallel embedding. (Usually, OpenAI can handle thousands of embedding requests per minute, even on the lowest API tier). RAG_EMBEDDING_CONTENT_PREFIX‚Äã Type: str Default: None Description: Specifies the prefix for the RAG embedding content. Persistence: This environment variable is a PersistentConfig variable. RAG_EMBEDDING_PREFIX_FIELD_NAME‚Äã Type: str Default: None Description: Specifies the field name for the RAG embedding prefix. Persistence: This environment variable is a PersistentConfig variable. RAG_EMBEDDING_QUERY_PREFIX‚Äã Type: str Default: None Description: Specifies the prefix for the RAG embedding query. Persistence: This environment variable is a PersistentConfig variable. OpenAI Embeddings‚Äã RAG_OPENAI_API_BASE_URL‚Äã Type: str Default: ${OPENAI_API_BASE_URL} Description: Sets the OpenAI base API URL to use for RAG embeddings. Persistence: This environment variable is a PersistentConfig variable. RAG_OPENAI_API_KEY‚Äã Type: str Default: ${OPENAI_API_KEY} Description: Sets the OpenAI API key to use for RAG embeddings. Persistence: This environment variable is a PersistentConfig variable. RAG_EMBEDDING_OPENAI_BATCH_SIZE‚Äã Type: int Default: 1 Description: Sets the batch size for OpenAI embeddings. Azure OpenAI Embeddings‚Äã RAG_AZURE_OPENAI_BASE_URL‚Äã Type: str Default: None Description: Sets the base URL for Azure OpenAI Services when using Azure OpenAI for RAG embeddings. Should be in the format https://{your-resource-name}.openai.azure.com. Persistence: This environment variable is a PersistentConfig variable. RAG_AZURE_OPENAI_API_KEY‚Äã Type: str Default: None Description: Sets the API key for Azure OpenAI Services when using Azure OpenAI for RAG embeddings. Persistence: This environment variable is a PersistentConfig variable. RAG_AZURE_OPENAI_API_VERSION‚Äã Type: str Default: None Description: Sets the API version for Azure OpenAI Services when using Azure OpenAI for RAG embeddings. Common values include 2023-05-15, 2023-12-01-preview, or 2024-02-01. Persistence: This environment variable is a PersistentConfig variable. Ollama Embeddings‚Äã RAG_OLLAMA_BASE_URL‚Äã Type: str Description: Sets the base URL for Ollama API used in RAG models. Persistence: This environment variable is a PersistentConfig variable. RAG_OLLAMA_API_KEY‚Äã Type: str Description: Sets the API key for Ollama API used in RAG models. Persistence: This environment variable is a PersistentConfig variable. Reranking‚Äã RAG_RERANKING_MODEL‚Äã Type: str Description: Sets a model for reranking results. Locally, a Sentence-Transformer model is used. Persistence: This environment variable is a PersistentConfig variable. RAG_EXTERNAL_RERANKER_TIMEOUT‚Äã Type: str Default: Empty string (' ') Description: Sets the timeout in seconds for external reranker API requests during RAG document retrieval. Leave empty to use default timeout behavior. Persistence: This environment variable is a PersistentConfig variable. RAG_EXTERNAL_RERANKER_URL‚Äã Type: str Default: Empty string (' ') Description: Sets the full URL for the external reranking API. Persistence: This environment variable is a PersistentConfig variable. warningYou MUST provide the full URL, including the endpoint path (e.g., https://api.yourprovider.com/v1/rerank). The system does not automatically append /v1/rerank or any other path to the base URL you provide. RAG_EXTERNAL_RERANKER_API_KEY‚Äã Type: str Default: Empty string (' ') Description: Sets the API key for the external reranking API. Persistence: This environment variable is a PersistentConfig variable. Query Generation‚Äã ENABLE_RETRIEVAL_QUERY_GENERATION‚Äã Type: bool Default: True Description: Enables or disables retrieval query generation. Persistence: This environment variable is a PersistentConfig variable. ENABLE_QUERIES_CACHE‚Äã Type: bool Default: False Description: Enables request-scoped caching of LLM-generated search queries. When enabled, queries generated for web search are cached and automatically reused for file/knowledge base retrieval within the same request. This eliminates duplicate LLM calls when both web search and RAG are active, reducing token usage and latency while maintaining search quality. It is highly recommended to enable this especially in larger setups. QUERY_GENERATION_PROMPT_TEMPLATE‚Äã Type: str Default: The value of DEFAULT_QUERY_GENERATION_PROMPT_TEMPLATE environment variable. DEFAULT_QUERY_GENERATION_PROMPT_TEMPLATE: ### Task:Analyze the chat history to determine the necessity of generating search queries, in the given language. By default, **prioritize generating 1-3 broad and relevant search queries** unless it is absolutely certain that no additional information is required. The aim is to retrieve comprehensive, updated, and valuable information even with minimal uncertainty. If no search is unequivocally needed, return an empty list.### Guidelines:- Respond **EXCLUSIVELY** with a JSON object. Any form of extra commentary, explanation, or additional text is strictly prohibited.- When generating search queries, respond in the format: { "queries": ["query1", "query2"] }, ensuring each query is distinct, concise, and relevant to the topic.- If and only if it is entirely certain that no useful results can be retrieved by a search, return: { "queries": [] }.- Err on the side of suggesting search queries if there is **any chance** they might provide useful or updated information.- Be concise and focused on composing high-quality search queries, avoiding unnecessary elaboration, commentary, or assumptions.- Today's date is: {{CURRENT_DATE}}.- Always prioritize providing actionable and broad queries that maximize informational coverage.### Output:Strictly return in JSON format:{ "queries": ["query1", "query2"]}### Chat History:<chat_history>{{MESSAGES:END:6}}</chat_history> Description: Sets the prompt template for query generation. Persistence: This environment variable is a PersistentConfig variable. Document Intelligence (Azure)‚Äã DOCUMENT_INTELLIGENCE_ENDPOINT‚Äã Type: str Default: None Description: Specifies the endpoint for document intelligence. Persistence: This environment variable is a PersistentConfig variable. DOCUMENT_INTELLIGENCE_KEY‚Äã Type: str Default: None Description: Specifies the key for document intelligence. Persistence: This environment variable is a PersistentConfig variable. DOCUMENT_INTELLIGENCE_MODEL‚Äã Type: str Default: None Description: Specifies the model for document intelligence. Persistence: This environment variable is a PersistentConfig variable. Advanced Settings‚Äã BYPASS_EMBEDDING_AND_RETRIEVAL‚Äã Type: bool Default: False Description: Bypasses the embedding and retrieval process. Persistence: This environment variable is a PersistentConfig variable. RAG_FULL_CONTEXT‚Äã Type: bool Default: False Description: Specifies whether to use the full context for RAG. Persistence: This environment variable is a PersistentConfig variable. ENABLE_RAG_LOCAL_WEB_FETCH‚Äã Type: bool Default: False Description: Enables or disables local web fetch for RAG. Persistence: This environment variable is a PersistentConfig variable. Google Drive‚Äã ENABLE_GOOGLE_DRIVE_INTEGRATION‚Äã Type: bool Default: False Description: Enables or disables Google Drive integration. If set to true, and GOOGLE_DRIVE_CLIENT_ID & GOOGLE_DRIVE_API_KEY are both configured, Google Drive will appear as an upload option in the chat UI. Persistence: This environment variable is a PersistentConfig variable. infoWhen enabling GOOGLE_DRIVE_INTEGRATION, ensure that you have configured GOOGLE_DRIVE_CLIENT_ID and GOOGLE_DRIVE_API_KEY correctly, and have reviewed Google's terms of service and usage guidelines. GOOGLE_DRIVE_CLIENT_ID‚Äã Type: str Description: Sets the client ID for Google Drive (client must be configured with Drive API and Picker API enabled). Persistence: This environment variable is a PersistentConfig variable. GOOGLE_DRIVE_API_KEY‚Äã Type: str Description: Sets the API key for Google Drive integration. Persistence: This environment variable is a PersistentConfig variable. OneDrive‚Äã infoFor a step-by-step setup guide, check out our tutorial: Configuring OneDrive & SharePoint Integration. ENABLE_ONEDRIVE_INTEGRATION‚Äã Type: bool Default: False Description: Enables or disables the Microsoft OneDrive integration feature globally. Persistence: This environment variable is a PersistentConfig variable. warningConfiguring OneDrive integration is a multi-step process that requires creating and correctly configuring an Azure App Registration. The authentication flow also depends on a browser pop-up window. Please ensure that your browser's pop-up blocker is disabled for your Open WebUI domain to allow the authentication and file selection window to appear. ENABLE_ONEDRIVE_PERSONAL‚Äã Type: bool Default: True Description: Controls whether the "Personal OneDrive" option appears in the attachment menu. Requires ONEDRIVE_PERSONAL_CLIENT_ID to be configured. Persistence: This environment variable is a PersistentConfig variable. ENABLE_ONEDRIVE_BUSINESS‚Äã Type: bool Default: True Description: Controls whether the "Work/School OneDrive" option appears in the attachment menu. Requires ONEDRIVE_CLIENT_ID to be configured. Persistence: This environment variable is a PersistentConfig variable. ONEDRIVE_CLIENT_ID‚Äã Type: str Default: None Description: Generic environment variable for the OneDrive Client ID. You should rather use the specific ONEDRIVE_CLIENT_ID_PERSONAL or ONEDRIVE_CLIENT_ID_BUSINESS variables. This exists as a legacy option for backwards compatibility. ONEDRIVE_CLIENT_ID_PERSONAL‚Äã Type: str Default: None Description: Specifies the Application (client) ID for the Personal OneDrive integration. This requires a separate Azure App Registration configured to support personal Microsoft accounts. Do not put the business OneDrive client ID here! ONEDRIVE_CLIENT_ID_BUSINESS‚Äã Type: str Default: None Description: Specifies the Application (client) ID for the Work/School (Business) OneDrive integration. This requires a separate Azure App Registration configured to support personal Microsoft accounts. Do not put the personal OneDrive client ID here! infoThis Client ID (also known as Application ID) is obtained from an Azure App Registration within your Microsoft Entra ID (formerly Azure AD) tenant. When configuring the App Registration in Azure, the Redirect URI must be set to the URL of your Open WebUI instance and configured as a Single-page application (SPA) type for the authentication to succeed. ONEDRIVE_SHAREPOINT_URL‚Äã Type: str Default: None Description: Specifies the root SharePoint site URL for the work/school integration, e.g., https://companyname.sharepoint.com. Persistence: This environment variable is a PersistentConfig variable. infoThis variable is essential for the work/school integration. It should point to the root SharePoint site associated with your tenant, enabling access to SharePoint document libraries. ONEDRIVE_SHAREPOINT_TENANT_ID‚Äã Type: str Default: None Description: Specifies the Directory (tenant) ID for the work/school integration. This is obtained from your business-focused Azure App Registration. Persistence: This environment variable is a PersistentConfig variable. infoThis Tenant ID (also known as Directory ID) is required for the work/school integration. You can find this value on the main overview page of your Azure App Registration in the Microsoft Entra ID portal. Web Search‚Äã ENABLE_WEB_SEARCH‚Äã Type: bool Default: False Description: Enable web search toggle. Persistence: This environment variable is a PersistentConfig variable. ENABLE_SEARCH_QUERY_GENERATION‚Äã Type: bool Default: True Description: Enables or disables search query generation. Persistence: This environment variable is a PersistentConfig variable. WEB_SEARCH_TRUST_ENV‚Äã Type: bool Default: False Description: Enables proxy set by http_proxy and https_proxy during web search content fetching. Persistence: This environment variable is a PersistentConfig variable. WEB_FETCH_FILTER_LIST‚Äã Type: string (comma-separated list) Default: "" (empty, but default blocklist is always applied) Description: Configures additional URL filtering rules for web fetch operations to prevent Server-Side Request Forgery (SSRF) attacks. The system includes a default blocklist that protects against access to cloud metadata endpoints (AWS, Google Cloud, Azure, Alibaba Cloud). Entries without a ! prefix are treated as an allow list (only these domains are permitted), while entries with a ! prefix are added to the block list (these domains are always denied). The default blocklist includes !169.254.169.254, !fd00:ec2::254, !metadata.google.internal, !metadata.azure.com, and !100.100.100.200. Custom entries are merged with the default blocklist. infoExample:Block additional domains: WEB_FETCH_FILTER_LIST="!internal.company.com,!192.168.1.1" Allow only specific domains: WEB_FETCH_FILTER_LIST="example.com,trusted-site.org" WEB_SEARCH_DOMAIN_FILTER_LIST‚Äã Type: list of str Default: [] Description: Comma-separated list of domains to filter web search results. Domains prefixed with ! are blocked; domains without prefix create an allowlist (only those domains permitted). Example: wikipedia.org,github.com,!malicious-site.com Persistence: This environment variable is a PersistentConfig variable. WEB_SEARCH_RESULT_COUNT‚Äã Type: int Default: 3 Description: Maximum number of search results to crawl. Persistence: This environment variable is a PersistentConfig variable. WEB_SEARCH_CONCURRENT_REQUESTS‚Äã Type: int Default: 0 Description: Limits the number of concurrent search requests to the search engine provider. Set to 0 for unlimited concurrency (default). Set to 1 for sequential execution to prevent rate limiting errors (e.g., Brave Free Tier). Persistence: This environment variable is a PersistentConfig variable. WEB_LOADER_CONCURRENT_REQUESTS‚Äã Type: int Default: 10 Description: Specifies the number of concurrent requests used by the web loader to fetch content from web pages returned by search results. This directly impacts how many pages can be crawled simultaneously. Persistence: This environment variable is a PersistentConfig variable. info"WEB_LOADER_CONCURRENT_REQUESTS" was previously named "WEB_SEARCH_CONCURRENT_REQUESTS". The variable "WEB_SEARCH_CONCURRENT_REQUESTS" has been repurposed to control the concurrency of the search engine requests (see above). To control the web loader concurrency (fetching content from results), you MUST use "WEB_LOADER_CONCURRENT_REQUESTS". WEB_SEARCH_ENGINE‚Äã Type: str Options: searxng - Uses the SearXNG search engine. google_pse - Uses the Google Programmable Search Engine. brave - Uses the Brave search engine. kagi - Uses the Kagi search engine. mojeek - Uses the Mojeek search engine. bocha - Uses the Bocha search engine. serpstack - Uses the Serpstack search engine. serper - Uses the Serper search engine. serply - Uses the Serply search engine. searchapi - Uses the SearchAPI search engine. serpapi - Uses the SerpApi search engine. duckduckgo - Uses the DuckDuckGo search engine. tavily - Uses the Tavily search engine. jina - Uses the Jina search engine. bing - Uses the Bing search engine. exa - Uses the Exa search engine. perplexity - Uses the Perplexity API to access perplexity's AI models. Calls their AI models, which execute a search and also return a full response. perplexity_search - Uses the Perplexity Search API search engine. In contrast to the perplexity option, this uses Perplexity's web search API for searching the web and retrieving results. sougou - Uses the Sougou search engine. ollama_cloud - Uses the Ollama Cloud search engine. azure_ai_search yacy Persistence: This environment variable is a PersistentConfig variable. BYPASS_WEB_SEARCH_EMBEDDING_AND_RETRIEVAL‚Äã Type: bool Default: False Description: Bypasses the web search embedding and retrieval process. Persistence: This environment variable is a PersistentConfig variable. SEARXNG_QUERY_URL‚Äã Type: str Description: The SearXNG search API URL supporting JSON output. <query> is replaced with the search query. Example: http://searxng.local/search?q=<query> Persistence: This environment variable is a PersistentConfig variable. SEARXNG_LANGUAGE‚Äã Type: str Default: all Description: This variable is used in the request to searxng as the "search language" (arguement "language"). Persistence: This environment variable is a PersistentConfig variable. GOOGLE_PSE_API_KEY‚Äã Type: str Description: Sets the API key for the Google Programmable Search Engine (PSE) service. Persistence: This environment variable is a PersistentConfig variable. GOOGLE_PSE_ENGINE_ID‚Äã Type: str Description: The engine ID for the Google Programmable Search Engine (PSE) service. Persistence: This environment variable is a PersistentConfig variable. BRAVE_SEARCH_API_KEY‚Äã Type: str Description: Sets the API key for the Brave Search API. Persistence: This environment variable is a PersistentConfig variable. KAGI_SEARCH_API_KEY‚Äã Type: str Description: Sets the API key for Kagi Search API. Persistence: This environment variable is a PersistentConfig variable. MOJEEK_SEARCH_API_KEY‚Äã Type: str Description: Sets the API key for Mojeek Search API. Persistence: This environment variable is a PersistentConfig variable. SERPSTACK_API_KEY‚Äã Type: str Description: Sets the API key for Serpstack search API. Persistence: This environment variable is a PersistentConfig variable. SERPSTACK_HTTPS‚Äã Type: bool Default: True Description: Configures the use of HTTPS for Serpstack requests. Free tier requests are restricted to HTTP only. Persistence: This environment variable is a PersistentConfig variable. SERPER_API_KEY‚Äã Type: str Description: Sets the API key for Serper search API. Persistence: This environment variable is a PersistentConfig variable. SERPLY_API_KEY‚Äã Type: str Description: Sets the API key for Serply search API. Persistence: This environment variable is a PersistentConfig variable. SEARCHAPI_API_KEY‚Äã Type: str Description: Sets the API key for SearchAPI. Persistence: This environment variable is a PersistentConfig variable. SEARCHAPI_ENGINE‚Äã Type: str Description: Sets the SearchAPI engine. Persistence: This environment variable is a PersistentConfig variable. TAVILY_API_KEY‚Äã Type: str Description: Sets the API key for Tavily search API. Persistence: This environment variable is a PersistentConfig variable. JINA_API_KEY‚Äã Type: str Description: Sets the API key for Jina. Persistence: This environment variable is a PersistentConfig variable. BING_SEARCH_V7_ENDPOINT‚Äã Type: str Description: Sets the endpoint for Bing Search API. Persistence: This environment variable is a PersistentConfig variable. BING_SEARCH_V7_SUBSCRIPTION_KEY‚Äã Type: str Default: https://api.bing.microsoft.com/v7.0/search Description: Sets the subscription key for Bing Search API. Persistence: This environment variable is a PersistentConfig variable. BOCHA_SEARCH_API_KEY‚Äã Type: str Default: None Description: Sets the API key for Bocha Search API. Persistence: This environment variable is a PersistentConfig variable. EXA_API_KEY‚Äã Type: str Default: None Description: Sets the API key for Exa search API. Persistence: This environment variable is a PersistentConfig variable. SERPAPI_API_KEY‚Äã Type: str Default: None Description: Sets the API key for SerpAPI. Persistence: This environment variable is a PersistentConfig variable. SERPAPI_ENGINE‚Äã Type: str Default: None Description: Specifies the search engine to use for SerpAPI. Persistence: This environment variable is a PersistentConfig variable. AZURE_AI_SEARCH_API_KEY‚Äã Type: str Default: None Description: API key (query key or admin key) for authenticating with Azure AI Search service. Required for using Azure AI Search as a web search provider. Persistence: This environment variable is a PersistentConfig variable. AZURE_AI_SEARCH_ENDPOINT‚Äã Type: str Default: None Description: Azure Search service endpoint URL. Specifies which Azure Search service instance to connect to. Example: https://myservice.search.windows.net, https://company-search.search.windows.net Persistence: This environment variable is a PersistentConfig variable. AZURE_AI_SEARCH_INDEX_NAME‚Äã Type: str Default: None Description: Name of the search index to query within your Azure Search service. Different indexes can contain different types of searchable content. Example: my-search-index, documents-index, knowledge-base Persistence: This environment variable is a PersistentConfig variable. SOUGOU_API_SID‚Äã Type: str Default: None Description: Sets the Sogou API SID. Persistence: This environment variable is a PersistentConfig variable. SOUGOU_API_SK‚Äã Type: str Default: None Description: Sets the Sogou API SK. Persistence: This environment variable is a PersistentConfig variable. OLLAMA_CLOUD_WEB_SEARCH_API_KEY‚Äã Type: str Default: None Description: Sets the Ollama Cloud Web Search API Key. Persistence: This environment variable is a PersistentConfig variable. TAVILY_EXTRACT_DEPTH‚Äã Type: str Default: basic Description: Specifies the extract depth for Tavily search results. Persistence: This environment variable is a PersistentConfig variable. YACY_QUERY_URL‚Äã Type: str Default: Empty string (' ') Description: Sets the query URL for YaCy search engine integration. Should point to a YaCy instance's search API endpoint. Persistence: This environment variable is a PersistentConfig variable. YACY_USERNAME‚Äã Type: str Default: Empty string (' ') Description: Specifies the username for authenticated access to YaCy search engine. Persistence: This environment variable is a PersistentConfig variable. YACY_PASSWORD‚Äã Type: str Default: Empty string (' ') Description: Specifies the password for authenticated access to YaCy search engine. Persistence: This environment variable is a PersistentConfig variable. EXTERNAL_WEB_SEARCH_URL‚Äã Type: str Default: Empty string (' ') Description: Specifies the URL of an external web search service API endpoint for custom search integrations. Persistence: This environment variable is a PersistentConfig variable. EXTERNAL_WEB_SEARCH_API_KEY‚Äã Type: str Default: Empty string (' ') Description: Sets the API key for authenticating with the external web search service. Persistence: This environment variable is a PersistentConfig variable. EXTERNAL_WEB_LOADER_URL‚Äã Type: str Default: Empty string (' ') Description: Specifies the URL of an external web content loader service for fetching and processing web pages. Persistence: This environment variable is a PersistentConfig variable. EXTERNAL_WEB_LOADER_API_KEY‚Äã Type: str Default: Empty string (' ') Description: Sets the API key for authenticating with the external web loader service. Persistence: This environment variable is a PersistentConfig variable. PERPLEXITY_API_KEY‚Äã Type: str Default: Empty string (' ') Description: Sets the API key for Perplexity API. Persistence: This environment variable is a PersistentConfig variable. PERPLEXITY_SEARCH_API_URL‚Äã Type: str Default: https://api.perplexity.ai/search Description: Configures the API endpoint for Perplexity Search. Allows using custom or self-hosted Perplexity-compatible API endpoints (such as LiteLLM's /search endpoint) instead of the hardcoded default for the official Perplexity API. This enables flexibility in routing search requests to alternative providers or internal proxies. Note: If using LiteLLM, append the specific provider name to the URL path. Example: http://my-litellm-server.com/search/perplexity-search Persistence: This environment variable is a PersistentConfig variable. PERPLEXITY_MODEL‚Äã Type: str Default: sonar Description: Specifies the Perplexity AI model to use for search queries when using Perplexity as the web search engine. Persistence: This environment variable is a PersistentConfig variable. infoPerplexity is different from perplexity_search. If you use perplexity_search, this variable is not relevant to you. PERPLEXITY_SEARCH_CONTEXT_USAGE‚Äã Type: str Default: medium Description: Controls the amount of search context used by Perplexity AI. Options typically include low, medium, high. Persistence: This environment variable is a PersistentConfig variable. infoPerplexity is different from perplexity_search. If you use perplexity, this variable is not relevant to you. Web Loader Configuration‚Äã WEB_LOADER_ENGINE‚Äã Type: str Default: (empty) Description: Specifies the loader to use for retrieving and processing web content. Options: safe_web (default) - Uses internal fetching with enhanced error handling. playwright - Uses Playwright for rendering pages with JavaScript support. firecrawl - Uses Firecrawl service. tavily - Uses Tavily service. external - Uses an external web loader API. Persistence: This environment variable is a PersistentConfig variable. infoWhen using playwright, you have two options: If PLAYWRIGHT_WS_URI is not set, Playwright with Chromium dependencies will be automatically installed in the Open WebUI container on launch. If PLAYWRIGHT_WS_URI is set, Open WebUI will connect to a remote browser instance instead of installing dependencies locally. PLAYWRIGHT_WS_URL‚Äã Type: str Default: None Description: Specifies the WebSocket URI of a remote Playwright browser instance. When set, Open WebUI will use this remote browser instead of installing browser dependencies locally. This is particularly useful in containerized environments where you want to keep the Open WebUI container lightweight and separate browser concerns. Example: ws://playwright:3000 Persistence: This environment variable is a PersistentConfig variable. tipUsing a remote Playwright browser via PLAYWRIGHT_WS_URL can be beneficial for: Reducing the size of the Open WebUI container Using a different browser other than the default Chromium Connecting to a non-headless (GUI) browser FIRECRAWL_API_BASE_URL‚Äã Type: str Default: https://api.firecrawl.dev Description: Sets the base URL for Firecrawl API. Persistence: This environment variable is a PersistentConfig variable. FIRECRAWL_API_KEY‚Äã Type: str Default: None Description: Sets the API key for Firecrawl API. Persistence: This environment variable is a PersistentConfig variable. PLAYWRIGHT_TIMEOUT‚Äã Type: int Default: Empty string (' '), since None is set as default. Description: Specifies the timeout for Playwright requests. Persistence: This environment variable is a PersistentConfig variable. WEB_LOADER_TIMEOUT‚Äã Type: float Default: Empty string (' '), since None is set as default. Description: Specifies the request timeout in seconds for the SafeWebBaseLoader when scraping web pages. Without this setting, web scraping operations can hang indefinitely on slow or unresponsive pages. Recommended values are 10‚Äì30 seconds depending on your network conditions. Persistence: This environment variable is a PersistentConfig variable. warningThis timeout only applies when WEB_LOADER_ENGINE is set to safe_web or left empty (the default). It has no effect on Playwright or Firecrawl loader engines, which have their own timeout configurations (PLAYWRIGHT_TIMEOUT and Firecrawl's internal settings respectively). YouTube Loader‚Äã YouTube Loader‚Äã YOUTUBE_LOADER_PROXY_URL‚Äã Type: str Description: Sets the proxy URL for YouTube loader. Persistence: This environment variable is a PersistentConfig variable. YOUTUBE_LOADER_LANGUAGE‚Äã Type: str Default: en Description: Comma-separated list of language codes to try when fetching YouTube video transcriptions, in priority order. Example: If set to es,de, Spanish transcriptions will be attempted first, then German if Spanish was not available, and lastly English. noteNote: If none of the specified languages are available and en was not in your list, the system will automatically try English as a final fallback. Persistence: This environment variable is a PersistentConfig variable. Audio‚Äã Whisper Speech-to-Text (Local)‚Äã WHISPER_MODEL‚Äã Type: str Default: base Description: Sets the Whisper model to use for Speech-to-Text. The backend used is faster_whisper with quantization to int8. Persistence: This environment variable is a PersistentConfig variable. WHISPER_MODEL_DIR‚Äã Type: str Default: ${DATA_DIR}/cache/whisper/models Description: Specifies the directory to store Whisper model files. WHISPER_VAD_FILTER‚Äã Type: bool Default: False Description: Specifies whether to apply a Voice Activity Detection (VAD) filter to Whisper Speech-to-Text. Persistence: This environment variable is a PersistentConfig variable. WHISPER_MODEL_AUTO_UPDATE‚Äã Type: bool Default: False Description: Toggles automatic update of the Whisper model. WHISPER_LANGUAGE‚Äã Type: str Default: None Description: Specifies the ISO 639-1 language Whisper uses for STT (ISO 639-2 for Hawaiian and Cantonese). Whisper predicts the language by default. Speech-to-Text (OpenAI)‚Äã AUDIO_STT_ENGINE‚Äã Type: str Options: Leave empty to use the built-in local Whisper engine for Speech-to-Text. openai - Uses OpenAI engine for Speech-to-Text. deepgram- Uses Deepgram engine for Speech-to-Text. azure Uses Azure engine for Speech-to-Text. Description: Specifies the Speech-to-Text engine to use. Persistence: This environment variable is a PersistentConfig variable. AUDIO_STT_MODEL‚Äã Type: str Default: whisper-1 Description: Specifies the Speech-to-Text model to use for OpenAI-compatible endpoints. Persistence: This environment variable is a PersistentConfig variable. AUDIO_STT_OPENAI_API_BASE_URL‚Äã Type: str Default: ${OPENAI_API_BASE_URL} Description: Sets the OpenAI-compatible base URL to use for Speech-to-Text. Persistence: This environment variable is a PersistentConfig variable. AUDIO_STT_OPENAI_API_KEY‚Äã Type: str Default: ${OPENAI_API_KEY} Description: Sets the OpenAI API key to use for Speech-to-Text. Persistence: This environment variable is a PersistentConfig variable. Speech-to-Text (Azure)‚Äã AUDIO_STT_AZURE_API_KEY‚Äã Type: str Default: None Description: Specifies the Azure API key to use for Speech-to-Text. Persistence: This environment variable is a PersistentConfig variable. AUDIO_STT_AZURE_REGION‚Äã Type: str Default: None Description: Specifies the Azure region to use for Speech-to-Text. Persistence: This environment variable is a PersistentConfig variable. AUDIO_STT_AZURE_LOCALES‚Äã Type: str Default: None Description: Specifies the locales to use for Azure Speech-to-Text. Persistence: This environment variable is a PersistentConfig variable. Speech-to-Text (Deepgram)‚Äã DEEPGRAM_API_KEY‚Äã Type: str Default: None Description: Specifies the Deepgram API key to use for Speech-to-Text. Persistence: This environment variable is a PersistentConfig variable. Text-to-Speech‚Äã AUDIO_TTS_API_KEY‚Äã Type: str Description: Sets the API key for Text-to-Speech. Persistence: This environment variable is a PersistentConfig variable. AUDIO_TTS_ENGINE‚Äã Type: str Options: Leave empty to use the built-in WebAPI engine for Text-to-Speech. azure - Uses Azure engine for Text-to-Speech. elevenlabs - Uses ElevenLabs engine for Text-to-Speech openai - Uses OpenAI engine for Text-to-Speech. transformers - Uses SentenceTransformers for Text-to-Speech. Description: Specifies the Text-to-Speech engine to use. Persistence: This environment variable is a PersistentConfig variable. AUDIO_TTS_MODEL‚Äã Type: str Default: tts-1 Description: Specifies the OpenAI text-to-speech model to use. Persistence: This environment variable is a PersistentConfig variable. AUDIO_TTS_VOICE‚Äã Type: str Default: alloy Description: Sets the OpenAI text-to-speech voice to use. Persistence: This environment variable is a PersistentConfig variable. AUDIO_TTS_SPLIT_ON‚Äã Type: str Default: punctuation Description: Sets the OpenAI text-to-speech split on to use. Persistence: This environment variable is a PersistentConfig variable. Azure Text-to-Speech‚Äã AUDIO_TTS_AZURE_SPEECH_REGION‚Äã Type: str Description: Sets the region for Azure Text to Speech. Persistence: This environment variable is a PersistentConfig variable. AUDIO_TTS_AZURE_SPEECH_OUTPUT_FORMAT‚Äã Type: str Description: Sets the output format for Azure Text to Speech. Persistence: This environment variable is a PersistentConfig variable. Voice Mode‚Äã VOICE_MODE_PROMPT_TEMPLATE‚Äã Type: str Default: The value of DEFAULT_VOICE_MODE_PROMPT_TEMPLATE environment variable. Description: Configures a custom system prompt for voice mode interactions. Allows administrators to control how the AI responds in voice conversations (style, length, tone). Leave empty to use the default prompt optimized for voice conversations, or provide custom instructions to tailor the voice assistant's behavior. Persistence: This environment variable is a PersistentConfig variable. OpenAI Text-to-Speech‚Äã AUDIO_TTS_OPENAI_API_BASE_URL‚Äã Type: str Default: ${OPENAI_API_BASE_URL} Description: Sets the OpenAI-compatible base URL to use for text-to-speech. Persistence: This environment variable is a PersistentConfig variable. AUDIO_TTS_OPENAI_API_KEY‚Äã Type: str Default: ${OPENAI_API_KEY} Description: Sets the API key to use for text-to-speech. Persistence: This environment variable is a PersistentConfig variable. Elevenlabs Text-to-Speech‚Äã ELEVENLABS_API_BASE_URL‚Äã Type: str Default: https://api.elevenlabs.io Description: Configures custom ElevenLabs API endpoints, enabling support for EU residency API requirements and other regional deployments. Persistence: This environment variable is a PersistentConfig variable. Image Generation‚Äã General Settings‚Äã ENABLE_IMAGE_GENERATION‚Äã Type: bool Default: False Description: Enables or disables image generation features. Persistence: This environment variable is a PersistentConfig variable. ENABLE_IMAGE_PROMPT_GENERATION‚Äã Type: bool Default: True Description: Enables or disables automatic enhancement of user prompts for better image generation results. Persistence: This environment variable is a PersistentConfig variable. IMAGE_PROMPT_GENERATION_PROMPT_TEMPLATE‚Äã Type: str Default: None Description: Specifies the template to use for generating image prompts. Persistence: This environment variable is a PersistentConfig variable. DEFAULT_IMAGE_PROMPT_GENERATION_PROMPT_TEMPLATE: ### Task:Generate a detailed prompt for an image generation task based on the given language and context. Describe the image as if you were explaining it to someone who cannot see it. Include relevant details, colors, shapes, and any other important elements.### Guidelines:- Be descriptive and detailed, focusing on the most important aspects of the image.- Avoid making assumptions or adding information not present in the image.- Use the chat's primary language; default to English if multilingual.- If the image is too complex, focus on the most prominent elements.### Output:Strictly return in JSON format:{ "prompt": "Your detailed description here."}### Chat History:<chat_history>{{MESSAGES:END:6}}</chat_history> Image Creation‚Äã IMAGE_GENERATION_ENGINE‚Äã Type: str Options: openai - Uses OpenAI DALL-E for image generation. comfyui - Uses ComfyUI engine for image generation. automatic1111 - Uses AUTOMATIC1111 engine for image generation. gemini - Uses Gemini for image generation. Default: openai Description: Specifies the engine to use for image generation. Persistence: This environment variable is a PersistentConfig variable. IMAGE_GENERATION_MODEL‚Äã Type: str Default: `` Description: Default model to use for image generation (e.g., dall-e-3, gemini-2.0-flash-exp). Persistence: This environment variable is a PersistentConfig variable. IMAGE_SIZE‚Äã Type: str Default: 512x512 Description: Sets the default output dimensions for generated images in WIDTHxHEIGHT format (e.g., 1024x1024). Persistence: This environment variable is a PersistentConfig variable. IMAGE_STEPS‚Äã Type: int Default: 50 Description: Sets the default iteration steps for image generation. Used for ComfyUI and AUTOMATIC1111 engines. Persistence: This environment variable is a PersistentConfig variable. Image Editing‚Äã ENABLE_IMAGE_EDIT‚Äã Type: boolean Default: true Description: When disabled, Image Editing will not be used and instead, images will be created only using the image generation engine. Persistence: This environment variable is a PersistentConfig variable. IMAGE_EDIT_ENGINE‚Äã Type: str Options: openai - Uses OpenAI DALL-E for image editing. gemini - Uses Gemini for image editing. comfyui - Uses ComfyUI engine for image editing. Default: openai Description: Configures the engine used for image editing operations, enabling modification of existing images using text prompts. Persistence: This environment variable is a PersistentConfig variable. IMAGE_EDIT_MODEL‚Äã Type: str Default: `` Description: Specifies the model to use for image editing operations within the selected engine (e.g., dall-e-2, gemini-2.5-flash). Persistence: This environment variable is a PersistentConfig variable. IMAGE_EDIT_SIZE‚Äã Type: str Default: `` Description: Defines the output dimensions for edited images in WIDTHxHEIGHT format (e.g., 1024x1024). Leave empty to preserve original dimensions. Persistence: This environment variable is a PersistentConfig variable. OpenAI DALL-E‚Äã Image Generation‚Äã IMAGES_OPENAI_API_BASE_URL‚Äã Type: str Default: ${OPENAI_API_BASE_URL} Description: Sets the OpenAI-compatible base URL to use for DALL-E image generation. Persistence: This environment variable is a PersistentConfig variable. IMAGES_OPENAI_API_VERSION‚Äã Type: str Default: ${OPENAI_API_VERSION} Description: Optional setting. If provided it sets the api-version query parameter when calling the image generation endpoint. Required for Azure OpenAI deployments. Persistence: This environment variable is a PersistentConfig variable. IMAGES_OPENAI_API_KEY‚Äã Type: str Default: ${OPENAI_API_KEY} Description: Sets the API key to use for DALL-E image generation. Persistence: This environment variable is a PersistentConfig variable. IMAGES_OPENAI_API_PARAMS‚Äã Type: str (JSON) Default: {} Description: Additional parameters for OpenAI image generation API in JSON format. Allows customization of API-specific settings such as quality parameters for DALL-E models (e.g., {"quality": "hd"} for dall-e-3). Example: {"quality": "hd", "style": "vivid"} Persistence: This environment variable is a PersistentConfig variable. Image Editing‚Äã IMAGES_EDIT_OPENAI_API_BASE_URL‚Äã Type: str Default: ${OPENAI_API_BASE_URL} Description: Configures the OpenAI API base URL specifically for image editing operations, allowing separate endpoints from image generation. Persistence: This environment variable is a PersistentConfig variable. IMAGES_EDIT_OPENAI_API_VERSION‚Äã Type: str Default: `` Description: Specifies the OpenAI API version for image editing, enabling support for Azure OpenAI deployments with versioned endpoints. Persistence: This environment variable is a PersistentConfig variable. IMAGES_EDIT_OPENAI_API_KEY‚Äã Type: str Default: ${OPENAI_API_KEY} Description: Provides authentication for OpenAI image editing API requests, with support for separate keys from image generation. Persistence: This environment variable is a PersistentConfig variable. Gemini‚Äã tipOne minimalistic working setup for Gemini can look like this: Create Image Model: gemini-2.5-flash-image Image Size: 2816x1536 Image Prompt Generation: on Image Generation Engine: Gemini Gemini Base URL: https://generativelanguage.googleapis.com/v1beta Gemini API Key: Enter your API Key Gemini Endpoint Method: generateContent Edit Image Image Edit Engine: Gemini Model: gemini-2.5-flash-image Image Size: (can be left empty) Gemini Base URL: https://generativelanguage.googleapis.com/v1beta Gemini API Key: Enter your API Key Image Generation‚Äã IMAGES_GEMINI_API_BASE_URL‚Äã Type: str Default: ${GEMINI_API_BASE_URL} Description: Specifies the URL to Gemini's image generation API. Persistence: This environment variable is a PersistentConfig variable. IMAGES_GEMINI_API_KEY‚Äã Type: str Default: ${GEMINI_API_KEY} Description: Sets the Gemini API key for image generation. Persistence: This environment variable is a PersistentConfig variable. IMAGES_GEMINI_ENDPOINT_METHOD‚Äã Type: str Options: predict - Uses the predict endpoint (default for Imagen models). generateContent - Uses the generateContent endpoint (for Gemini 2.5 Flash and newer models). Default: `` Description: Specifies the Gemini API endpoint method for image generation, supporting both legacy Imagen models and newer Gemini models with image generation capabilities. Persistence: This environment variable is a PersistentConfig variable. Image Editing‚Äã IMAGES_EDIT_GEMINI_API_BASE_URL‚Äã Type: str Default: ${GEMINI_API_BASE_URL} Description: Configures the Gemini API base URL for image editing operations with Gemini models. Persistence: This environment variable is a PersistentConfig variable. IMAGES_EDIT_GEMINI_API_KEY‚Äã Type: str Default: ${GEMINI_API_KEY} Description: Provides authentication for Gemini image editing API requests. Persistence: This environment variable is a PersistentConfig variable. ComfyUI‚Äã Image Generation‚Äã COMFYUI_BASE_URL‚Äã Type: str Default: `` Description: Specifies the URL to the ComfyUI image generation API (e.g., http://127.0.0.1:8188). Persistence: This environment variable is a PersistentConfig variable. COMFYUI_API_KEY‚Äã Type: str Default: `` Description: Sets the API key for ComfyUI authentication. Persistence: This environment variable is a PersistentConfig variable. COMFYUI_WORKFLOW‚Äã Type: str (JSON) Default: { "3": { "inputs": { "seed": 0, "steps": 20, "cfg": 8, "sampler_name": "euler", "scheduler": "normal", "denoise": 1, "model": ["4", 0], "positive": ["6", 0], "negative": ["7", 0], "latent_image": ["5", 0] }, "class_type": "KSampler", "_meta": { "title": "KSampler" } }, "4": { "inputs": { "ckpt_name": "model.safetensors" }, "class_type": "CheckpointLoaderSimple", "_meta": { "title": "Load Checkpoint" } }, "5": { "inputs": { "width": 512, "height": 512, "batch_size": 1 }, "class_type": "EmptyLatentImage", "_meta": { "title": "Empty Latent Image" } }, "6": { "inputs": { "text": "Prompt", "clip": ["4", 1] }, "class_type": "CLIPTextEncode", "_meta": { "title": "CLIP Text Encode (Prompt)" } }, "7": { "inputs": { "text": "", "clip": ["4", 1] }, "class_type": "CLIPTextEncode", "_meta": { "title": "CLIP Text Encode (Prompt)" } }, "8": { "inputs": { "samples": ["3", 0], "vae": ["4", 2] }, "class_type": "VAEDecode", "_meta": { "title": "VAE Decode" } }, "9": { "inputs": { "filename_prefix": "ComfyUI", "images": ["8", 0] }, "class_type": "SaveImage", "_meta": { "title": "Save Image" } }} Description: Defines the ComfyUI workflow configuration in JSON format. Export from ComfyUI using "Save (API Format)" to ensure compatibility. Persistence: This environment variable is a PersistentConfig variable. COMFYUI_WORKFLOW_NODES‚Äã Type: list[dict] Default: [] Description: Specifies the ComfyUI workflow node mappings for image generation, defining which nodes handle prompt, model, dimensions, and other parameters. Configured automatically via the admin UI. Persistence: This environment variable is a PersistentConfig variable. Image Editing‚Äã IMAGES_EDIT_COMFYUI_BASE_URL‚Äã Type: str Default: `` Description: Configures the ComfyUI base URL for image editing operations, enabling self-hosted ComfyUI workflows for image manipulation. Persistence: This environment variable is a PersistentConfig variable. IMAGES_EDIT_COMFYUI_API_KEY‚Äã Type: str Default: `` Description: Provides authentication for ComfyUI image editing API requests when the ComfyUI instance requires API key authentication. Persistence: This environment variable is a PersistentConfig variable. IMAGES_EDIT_COMFYUI_WORKFLOW‚Äã Type: str (JSON) Default: `` Description: Defines the ComfyUI workflow configuration in JSON format for image editing operations. Must include nodes for image input, prompt, and output. Export from ComfyUI using "Save (API Format)". Persistence: This environment variable is a PersistentConfig variable. IMAGES_EDIT_COMFYUI_WORKFLOW_NODES‚Äã Type: list[dict] Default: [] Description: Specifies the ComfyUI workflow node mappings for image editing, defining which nodes handle image input, prompt, model, dimensions, and other parameters. Configured automatically via the admin UI. Persistence: This environment variable is a PersistentConfig variable. AUTOMATIC1111‚Äã AUTOMATIC1111_BASE_URL‚Äã Type: str Default: `` Description: Specifies the URL to AUTOMATIC1111's Stable Diffusion API (e.g., http://127.0.0.1:7860). Persistence: This environment variable is a PersistentConfig variable. AUTOMATIC1111_API_AUTH‚Äã Type: str Default: `` Description: Sets the AUTOMATIC1111 API authentication credentials if required. Persistence: This environment variable is a PersistentConfig variable. AUTOMATIC1111_PARAMS‚Äã Type: str (JSON) Default: {} Description: Additional parameters in JSON format to pass to AUTOMATIC1111 API requests (e.g., {"cfg_scale": 7, "sampler_name": "Euler a", "scheduler": "normal"}). Persistence: This environment variable is a PersistentConfig variable. OAuth‚Äã infoYou can only configure one OAUTH provider at a time. You cannot have two or more OAUTH providers configured simultaneously. ENABLE_OAUTH_SIGNUP‚Äã Type: bool Default: False Description: Enables account creation when signing up via OAuth. Distinct from ENABLE_SIGNUP. Persistence: This environment variable is a PersistentConfig variable. dangerENABLE_LOGIN_FORM must be set to False when ENABLE_OAUTH_SIGNUP is set to True. Failure to do so will result in the inability to login. ENABLE_OAUTH_PERSISTENT_CONFIG‚Äã Type: bool Default: True Description: Controls whether OAuth-related settings are persisted in the database after the first launch. infoBy default, OAuth configurations are stored in the database and managed via the Admin Panel after the initial setup. Set this variable to False to force Open WebUI to always read OAuth settings from the environment variables on every restart. This is ideal for environments using GitOps or immutable infrastructure where configuration is managed exclusively through external files (e.g., Docker Compose, Kubernetes ConfigMaps). OAUTH_SUB_CLAIM‚Äã Type: str Default: None Description: Overrides the default claim used to identify a user's unique ID (sub) from the OAuth/OIDC provider's user info response. By default, Open WebUI attempts to infer this from the provider's configuration. This variable allows you to explicitly specify which claim to use. For example, if your identity provider uses 'employee_id' as the unique identifier, you would set this variable to 'employee_id'. Persistence: This environment variable is a PersistentConfig variable. OAUTH_MERGE_ACCOUNTS_BY_EMAIL‚Äã Type: bool Default: False Description: If enabled, merges OAuth accounts with existing accounts using the same email address. This is considered unsafe as not all OAuth providers will verify email addresses and can lead to potential account takeovers. Persistence: This environment variable is a PersistentConfig variable. ENABLE_OAUTH_WITHOUT_EMAIL‚Äã Type: bool Default: False Description: Enables authentication with OpenID Connect (OIDC) providers that do not support or expose an email scope. When enabled, Open WebUI will create and manage user accounts without requiring an email address from the OAuth provider. Persistence: This environment variable is a PersistentConfig variable. warningUse with CautionEnabling this option bypasses email-based user identification, which is the standard method for uniquely identifying users across authentication systems. When enabled: User accounts will be created using the sub claim (or the claim specified in OAUTH_SUB_CLAIM) as the primary identifier Email-based features such as password recovery, email notifications, and account merging via OAUTH_MERGE_ACCOUNTS_BY_EMAIL will not function properly Ensure your OIDC provider's sub claim is stable and unique to prevent authentication conflicts Only enable this if your identity provider does not support email scope and you have alternative user identification mechanisms in place.This setting is designed for enterprise environments using identity providers that: Use employee IDs, usernames, or other non-email identifiers as the primary user claim Have privacy policies that prevent sharing email addresses via OAuth Operate in air-gapped or highly restricted networks where email-based services are unavailable For most standard OAuth providers (Google, Microsoft, GitHub, etc.), this setting should remain False. OAUTH_UPDATE_PICTURE_ON_LOGIN‚Äã Type: bool Default: False Description: If enabled, updates the local user profile picture with the OAuth-provided picture on login. Persistence: This environment variable is a PersistentConfig variable. infoIf the OAuth picture claim is disabled by setting OAUTH_PICTURE_CLAIM to '' (empty string), then setting this variable to true will not update the user profile pictures. ENABLE_OAUTH_ID_TOKEN_COOKIE‚Äã Type: bool Default: True Description: Controls whether the legacy oauth_id_token cookie (unsafe, not recommended, token can go stale/orphaned) is set in the browser upon a successful OAuth login. This is provided for backward compatibility with custom tools or older versions that might rely on scraping this cookie. The new, recommended approach is to use the server-side session management. Usage: For new and secure deployments, it is recommended to set this to False to minimize the information exposed to the client-side. Keep it as True only if you have integrations that depend on the old cookie-based method. OAUTH_CLIENT_INFO_ENCRYPTION_KEY‚Äã Type: str Default: Falls back to the value of WEBUI_SECRET_KEY. Description: Specifies the secret key used to encrypt and decrypt OAuth client tokens stored server-side in the database. This is a critical security component for OAuth client tokens. If not set, it defaults to using the main WEBUI_SECRET_KEY, but it is highly recommended to set it to a unique, securely generated value for production environments. OAUTH_CLIENT_INFO_ENCRYPTION_KEY is used in conjunction with OAuth 2.1 MCP server authentication. OAUTH_SESSION_TOKEN_ENCRYPTION_KEY‚Äã Type: str Default: Falls back to the value of WEBUI_SECRET_KEY. Description: Specifies the secret key used to encrypt and decrypt OAuth tokens stored server-side in the database. This is a critical security component for protecting user credentials at rest. If not set, it defaults to using the main WEBUI_SECRET_KEY, but it is highly recommended to set it to a unique, securely generated value for production environments. warningRequired for Multi-Replica Deployments In any production environment running more than one instance of Open WebUI (e.g., Docker Swarm, Kubernetes), this variable MUST be explicitly set to a persistent, shared secret. If left unset, each replica will generate or use a different key, causing session decryption to fail intermittently as user requests are load-balanced across instances. WEBUI_AUTH_TRUSTED_EMAIL_HEADER‚Äã Type: str Description: Defines the trusted request header for authentication. See SSO docs. WEBUI_AUTH_TRUSTED_NAME_HEADER‚Äã Type: str Description: Defines the trusted request header for the username of anyone registering with the WEBUI_AUTH_TRUSTED_EMAIL_HEADER header. See SSO docs. WEBUI_AUTH_TRUSTED_GROUPS_HEADER‚Äã Type: str Description: Defines the trusted request header containing a comma-separated list of group memberships for the user when using trusted header authentication. See SSO docs. Google‚Äã See https://support.google.com/cloud/answer/6158849?hl=en infoYou must also set OPENID_PROVIDER_URL or otherwise logout may not work. GOOGLE_CLIENT_ID‚Äã Type: str Description: Sets the client ID for Google OAuth. Persistence: This environment variable is a PersistentConfig variable. GOOGLE_CLIENT_SECRET‚Äã Type: str Description: Sets the client secret for Google OAuth. Persistence: This environment variable is a PersistentConfig variable. GOOGLE_OAUTH_SCOPE‚Äã Type: str Default: openid email profile Description: Sets the scope for Google OAuth authentication. Persistence: This environment variable is a PersistentConfig variable. GOOGLE_REDIRECT_URI‚Äã Type: str Default: <backend>/oauth/google/callback Description: Sets the redirect URI for Google OAuth. Persistence: This environment variable is a PersistentConfig variable. Microsoft‚Äã See https://learn.microsoft.com/en-us/entra/identity-platform/quickstart-register-app infoYou must also set OPENID_PROVIDER_URL or otherwise logout may not work. MICROSOFT_CLIENT_ID‚Äã Type: str Description: Sets the client ID for Microsoft OAuth. Persistence: This environment variable is a PersistentConfig variable. MICROSOFT_CLIENT_SECRET‚Äã Type: str Description: Sets the client secret for Microsoft OAuth. Persistence: This environment variable is a PersistentConfig variable. MICROSOFT_CLIENT_TENANT_ID‚Äã Type: str Description: Sets the tenant ID for Microsoft OAuth. Persistence: This environment variable is a PersistentConfig variable. MICROSOFT_OAUTH_SCOPE‚Äã Type: str Default: openid email profile Description: Sets the scope for Microsoft OAuth authentication. Persistence: This environment variable is a PersistentConfig variable. MICROSOFT_REDIRECT_URI‚Äã Type: str Default: <backend>/oauth/microsoft/callback Description: Sets the redirect URI for Microsoft OAuth. Persistence: This environment variable is a PersistentConfig variable. MICROSOFT_CLIENT_LOGIN_BASE_URL‚Äã Type: str Default: https://login.microsoftonline.com Description: Sets the base login URL for Microsoft OAuth authentication. Allows configuration of alternative login endpoints for government clouds or custom deployments. Persistence: This environment variable is a PersistentConfig variable. MICROSOFT_CLIENT_PICTURE_URL‚Äã Type: str Default: https://graph.microsoft.com/v1.0/me/photo/$value Description: Specifies the Microsoft Graph API endpoint for retrieving user profile pictures during OAuth authentication. Persistence: This environment variable is a PersistentConfig variable. GitHub‚Äã See https://docs.github.com/en/apps/oauth-apps/building-oauth-apps/authorizing-oauth-apps infoYou must also set OPENID_PROVIDER_URL or otherwise logout may not work. GITHUB_CLIENT_ID‚Äã Type: str Description: Sets the client ID for GitHub OAuth. Persistence: This environment variable is a PersistentConfig variable. GITHUB_CLIENT_SECRET‚Äã Type: str Description: Sets the client secret for GitHub OAuth. Persistence: This environment variable is a PersistentConfig variable. GITHUB_CLIENT_SCOPE‚Äã Type: str Default: user:email Description: Specifies the scope for GitHub OAuth authentication. Persistence: This environment variable is a PersistentConfig variable. GITHUB_CLIENT_REDIRECT_URI‚Äã Type: str Default: <backend>/oauth/github/callback Description: Sets the redirect URI for GitHub OAuth. Persistence: This environment variable is a PersistentConfig variable. Feishu‚Äã See https://open.feishu.cn/document/sso/web-application-sso/login-overview FEISHU_CLIENT_ID‚Äã Type: str Description: Sets the client ID for Feishu OAuth. Persistence: This environment variable is a PersistentConfig variable. FEISHU_CLIENT_SECRET‚Äã Type: str Description: Sets the client secret for Feishu OAuth. Persistence: This environment variable is a PersistentConfig variable. FEISHU_CLIENT_SCOPE‚Äã Type: str Default: contact:user.base:readonly Description: Specifies the scope for Feishu OAuth authentication. Persistence: This environment variable is a PersistentConfig variable. FEISHU_CLIENT_REDIRECT_URI‚Äã Type: str Description: Sets the redirect URI for Feishu OAuth. Persistence: This environment variable is a PersistentConfig variable. OpenID (OIDC)‚Äã OAUTH_CLIENT_ID‚Äã Type: str Description: Sets the client ID for OIDC. Persistence: This environment variable is a PersistentConfig variable. OAUTH_CLIENT_SECRET‚Äã Type: str Description: Sets the client secret for OIDC. Persistence: This environment variable is a PersistentConfig variable. OPENID_PROVIDER_URL‚Äã Type: str Description: Path to the .well-known/openid-configuration endpoint Persistence: This environment variable is a PersistentConfig variable. dangerThe environment variable OPENID_PROVIDER_URL MUST be configured, otherwise the logout functionality will not work for most providers. Even when using Microsoft, GitHub or other providers, you MUST set the OPENID_PROVIDER_URL environment variable. OPENID_REDIRECT_URI‚Äã Type: str Default: <backend>/oauth/oidc/callback Description: Sets the redirect URI for OIDC Persistence: This environment variable is a PersistentConfig variable. OAUTH_SCOPES‚Äã Type: str Default: openid email profile Description: Sets the scope for OIDC authentication. openid and email are required. Persistence: This environment variable is a PersistentConfig variable. OAUTH_CODE_CHALLENGE_METHOD‚Äã Type: str Options: S256 - Hash code_verifier with SHA-256. Default: Empty string (' '), since None is set as default. Description: Specifies the code challenge method for OAuth authentication. Set to S256 when PKCE is required by the provider. Persistence: This environment variable is a PersistentConfig variable. OAUTH_PROVIDER_NAME‚Äã Type: str Default: SSO Description: Sets the name for the OIDC provider. Persistence: This environment variable is a PersistentConfig variable. OAUTH_USERNAME_CLAIM‚Äã Type: str Default: name Description: Set username claim for OpenID. Persistence: This environment variable is a PersistentConfig variable. OAUTH_EMAIL_CLAIM‚Äã Type: str Default: email Description: Set email claim for OpenID. Persistence: This environment variable is a PersistentConfig variable. OAUTH_PICTURE_CLAIM‚Äã Type: str Default: picture Description: Set picture (avatar) claim for OpenID. Persistence: This environment variable is a PersistentConfig variable. infoIf OAUTH_PICTURE_CLAIM is set to '' (empty string), then the OAuth picture claim is disabled and the user profile pictures will not be saved. OAUTH_GROUP_CLAIM‚Äã Type: str Default: groups Description: Specifies the group claim for OAuth authentication. Persistence: This environment variable is a PersistentConfig variable. ENABLE_OAUTH_ROLE_MANAGEMENT‚Äã Type: bool Default: False Description: Enables role management for OAuth delegation. Persistence: This environment variable is a PersistentConfig variable. ENABLE_OAUTH_GROUP_MANAGEMENT‚Äã Type: bool Default: False Description: Enables or disables OAuth group management. Persistence: This environment variable is a PersistentConfig variable. ENABLE_OAUTH_GROUP_CREATION‚Äã Type: bool Default: False Description: When enabled, groups from OAuth claims that don't exist in Open WebUI will be automatically created. Persistence: This environment variable is a PersistentConfig variable. OAUTH_BLOCKED_GROUPS‚Äã Type: str Default: [] Description: JSON array of group names that are blocked from accessing the application. Users belonging to these groups will be denied access even if they have valid OAuth credentials. Persistence: This environment variable is a PersistentConfig variable. OAUTH_ROLES_CLAIM‚Äã Type: str Default: roles Description: Sets the roles claim to look for in the OIDC token. Persistence: This environment variable is a PersistentConfig variable. OAUTH_ALLOWED_ROLES‚Äã Type: str Default: user,admin Description: Sets the roles that are allowed access to the platform. Persistence: This environment variable is a PersistentConfig variable. OAUTH_ADMIN_ROLES‚Äã Type: str Default: admin Description: Sets the roles that are considered administrators. Persistence: This environment variable is a PersistentConfig variable. OAUTH_ROLES_SEPARATOR‚Äã Type: str Default: , Description: Allows custom role separators for for splitting the OAUTH_*_ROLES variables. Meant for OAuth roles that contain commas; useful for roles specified in LDAP syntax or other systems where commas are part of role names. If the claim is a string and contains the separator, it will be also split by that separator. OAUTH_GROUPS_SEPARATOR‚Äã Type: str Default: ; Description: Specifies the delimiter used to parse multiple group names from the OAuth group claim. This separator is used when the identity provider returns group memberships as a delimited string rather than an array. Useful when integrating with systems that use non-standard separators or when group names themselves contain commas. OAUTH_ALLOWED_DOMAINS‚Äã Type: str Default: * Description: Specifies the allowed domains for OAuth authentication. (e.g., "example1.com,example2.com"). Persistence: This environment variable is a PersistentConfig variable. OAUTH_AUDIENCE‚Äã Type: str Default: Empty string (' ') Description: Specifies an audience parameter passed to the OAuth provider's authorization endpoint during login. Some providers (such as Auth0 and Ory) use this value to determine the type of access token returned‚Äîwithout it, providers typically return an opaque token, while with it, they return a JWT that can be decoded and validated. This parameter is not part of the official OAuth/OIDC spec for authorization endpoints but is widely supported by some providers. infoThis is useful when you need a JWT access token for downstream validation or when your OAuth provider requires an audience hint for proper token generation. For Auth0, this is typically your API identifier (e.g., https://your-api.auth0.com/api/v2/). For Ory, specify the resource server you want to access. LDAP‚Äã ENABLE_LDAP‚Äã Type: bool Default: False Description: Enables or disables LDAP authentication. Persistence: This environment variable is a PersistentConfig variable. LDAP_SERVER_LABEL‚Äã Type: str Description: Sets the label of the LDAP server. Persistence: This environment variable is a PersistentConfig variable. LDAP_SERVER_HOST‚Äã Type: str Default: localhost Description: Sets the hostname of the LDAP server. Persistence: This environment variable is a PersistentConfig variable. LDAP_SERVER_PORT‚Äã Type: int Default: 389 Description: Sets the port number of the LDAP server. Persistence: This environment variable is a PersistentConfig variable. LDAP_ATTRIBUTE_FOR_MAIL‚Äã Type: str Description: Sets the attribute to use as mail for LDAP authentication. Persistence: This environment variable is a PersistentConfig variable. LDAP_ATTRIBUTE_FOR_USERNAME‚Äã Type: str Description: Sets the attribute to use as a username for LDAP authentication. Persistence: This environment variable is a PersistentConfig variable. LDAP_APP_DN‚Äã Type: str Description: Sets the distinguished name for the LDAP application. Persistence: This environment variable is a PersistentConfig variable. LDAP_APP_PASSWORD‚Äã Type: str Description: Sets the password for the LDAP application. Persistence: This environment variable is a PersistentConfig variable. LDAP_SEARCH_BASE‚Äã Type: str Description: Sets the base to search for LDAP authentication. Persistence: This environment variable is a PersistentConfig variable. LDAP_SEARCH_FILTER‚Äã Type: str Default: None Description: Sets a single filter to use for LDAP search. Alternative to LDAP_SEARCH_FILTERS. Persistence: This environment variable is a PersistentConfig variable. LDAP_SEARCH_FILTERS‚Äã Type: str Description: Sets the filter to use for LDAP search. Persistence: This environment variable is a PersistentConfig variable. LDAP_USE_TLS‚Äã Type: bool Default: True Description: Enables or disables TLS for LDAP connection. Persistence: This environment variable is a PersistentConfig variable. LDAP_CA_CERT_FILE‚Äã Type: str Description: Sets the path to the LDAP CA certificate file. Persistence: This environment variable is a PersistentConfig variable. LDAP_VALIDATE_CERT‚Äã Type: bool Description: Sets whether to validate the LDAP CA certificate. Persistence: This environment variable is a PersistentConfig variable. LDAP_CIPHERS‚Äã Type: str Default: ALL Description: Sets the ciphers to use for LDAP connection. Persistence: This environment variable is a PersistentConfig variable. ENABLE_LDAP_GROUP_MANAGEMENT‚Äã Type: bool Default: False Description: Enables the group management feature. Persistence: This environment variable is a PersistentConfig variable. ENABLE_LDAP_GROUP_CREATION‚Äã Type: bool Default: False Description: If a group from LDAP does not exist in Open WebUI, it will be created automatically. Persistence: This environment variable is a PersistentConfig variable. LDAP_ATTRIBUTE_FOR_GROUPS‚Äã Type: str Default: memberOf Description: Specifies the LDAP attribute that contains the user's group memberships. memberOf is a standard attribute for this purpose in Active Directory environments. Persistence: This environment variable is a PersistentConfig variable. SCIM‚Äã SCIM_ENABLED‚Äã Type: bool Default: False Description: Enables or disables SCIM 2.0 (System for Cross-domain Identity Management) support for automated user and group provisioning from identity providers like Okta, Azure AD, and Google Workspace. Persistence: This environment variable is a PersistentConfig variable. SCIM_TOKEN‚Äã Type: str Default: "" Description: Sets the bearer token for SCIM authentication. This token must be provided by identity providers when making SCIM API requests. Generate a secure random token (e.g., using openssl rand -base64 32) and configure it in both Open WebUI and your identity provider. Persistence: This environment variable is a PersistentConfig variable. User Permissions‚Äã Chat Permissions‚Äã USER_PERMISSIONS_CHAT_CONTROLS‚Äã Type: bool Default: True Description: Acts as a master switch to enable or disable the main "Controls" button and panel in the chat interface. If this is set to False, users will not see the Controls button, and the granular permissions below will have no effect. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_VALVES‚Äã Type: bool Default: True Description: When USER_PERMISSIONS_CHAT_CONTROLS is enabled, this setting specifically controls the visibility of the "Valves" section within the chat controls panel. USER_PERMISSIONS_CHAT_SYSTEM_PROMPT‚Äã Type: bool Default: True Description: When USER_PERMISSIONS_CHAT_CONTROLS is enabled, this setting specifically controls the visibility of the customizable "System Prompt" section within the chat controls panel, folders and the user settings. USER_PERMISSIONS_CHAT_PARAMS‚Äã Type: bool Default: True Description: When USER_PERMISSIONS_CHAT_CONTROLS is enabled, this setting specifically controls the visibility of the "Advanced Parameters" section within the chat controls panel. USER_PERMISSIONS_CHAT_FILE_UPLOAD‚Äã Type: bool Default: True Description: Enables or disables user permission to upload files to chats. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_DELETE‚Äã Type: bool Default: True Description: Enables or disables user permission to delete chats. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_EDIT‚Äã Type: bool Default: True Description: Enables or disables user permission to edit chats. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_DELETE_MESSAGE‚Äã Type: bool Default: True Description: Enables or disables user permission to delete individual messages within chats. This provides granular control over message deletion capabilities separate from full chat deletion. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_CONTINUE_RESPONSE‚Äã Type: bool Default: True Description: Enables or disables user permission to continue AI responses. When disabled, users cannot use the "Continue Response" button, which helps prevent potential system prompt leakage through response continuation manipulation. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_REGENERATE_RESPONSE‚Äã Type: bool Default: True Description: Enables or disables user permission to regenerate AI responses. Controls access to both the standard regenerate button and the guided regeneration menu. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_RATE_RESPONSE‚Äã Type: bool Default: True Description: Enables or disables user permission to rate AI responses using the thumbs up/down feedback system. This controls access to the response rating functionality for evaluation and feedback collection. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_STT‚Äã Type: bool Default: True Description: Enables or disables user permission to use Speech-to-Text in chats. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_TTS‚Äã Type: bool Default: True Description: Enables or disables user permission to use Text-to-Speech in chats. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_CALL‚Äã Type: str Default: True Description: Enables or disables user permission to make calls in chats. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_MULTIPLE_MODELS‚Äã Type: str Default: True Description: Enables or disables user permission to use multiple models in chats. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_TEMPORARY‚Äã Type: bool Default: True Description: Enables or disables user permission to create temporary chats. Note: Temporary chats disable backend document parsing for privacy. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_CHAT_TEMPORARY_ENFORCED‚Äã Type: str Default: False Description: Enables or disables enforced temporary chats for users. Persistence: This environment variable is a PersistentConfig variable. Feature Permissions‚Äã USER_PERMISSIONS_FEATURES_DIRECT_TOOL_SERVERS‚Äã Type: str Default: False Description: Enables or disables user permission to access direct tool servers. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_FEATURES_WEB_SEARCH‚Äã Type: str Default: True Description: Enables or disables user permission to use the web search feature. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_FEATURES_IMAGE_GENERATION‚Äã Type: str Default: True Description: Enables or disables user permission to use the image generation feature. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_FEATURES_CODE_INTERPRETER‚Äã Type: str Default: True Description: Enables or disables user permission to use code interpreter feature. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_FEATURES_FOLDERS‚Äã Type: str Default: True Description: Enables or disables the visibility of the Folders feature (chat sidebar) to users. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_FEATURES_NOTES‚Äã Type: str Default: True Description: Enables or disables the visibility of the Notes feature to users. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_FEATURES_CHANNELS‚Äã Type: str Default: True Description: Enables or disables the ability for users to create their own group channels. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_FEATURES_API_KEYS‚Äã Type: bool Default: False Description: Sets the permission for API key creation feature for users. When enabled, users will have the ability to create and manage API keys for programmatic access. Persistence: This environment variable is a PersistentConfig variable. infoFor API Key creation (and the API keys themselves) to work, you not only need to give specific user groups the permission for it, but also enable it globally using ENABLE_API_KEYS Workspace Permissions‚Äã USER_PERMISSIONS_WORKSPACE_MODELS_ACCESS‚Äã Type: bool Default: False Description: Enables or disables user permission to access workspace models. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_WORKSPACE_KNOWLEDGE_ACCESS‚Äã Type: bool Default: False Description: Enables or disables user permission to access workspace knowledge. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_WORKSPACE_PROMPTS_ACCESS‚Äã Type: bool Default: False Description: Enables or disables user permission to access workspace prompts. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_WORKSPACE_TOOLS_ACCESS‚Äã Type: bool Default: False Description: Enables or disables user permission to access workspace tools. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_WORKSPACE_MODELS_ALLOW_PUBLIC_SHARING‚Äã Type: str Default: False Description: Enables or disables public sharing of workspace models. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_WORKSPACE_KNOWLEDGE_ALLOW_PUBLIC_SHARING‚Äã Type: str Default: False Description: Enables or disables public sharing of workspace knowledge. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_WORKSPACE_PROMPTS_ALLOW_PUBLIC_SHARING‚Äã Type: str Default: False Description: Enables or disables public sharing of workspace prompts. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_WORKSPACE_TOOLS_ALLOW_PUBLIC_SHARING‚Äã Type: str Default: False Description: Enables or disables public sharing of workspace tools. Persistence: This environment variable is a PersistentConfig variable. USER_PERMISSIONS_NOTES_ALLOW_PUBLIC_SHARING‚Äã Type: str Default: True Description: Enables or disables public sharing of notes. Misc Environment Variables‚Äã These variables are not specific to Open WebUI but can still be valuable in certain contexts. Cloud Storage‚Äã STORAGE_PROVIDER‚Äã Type: str Options: s3 - uses the S3 client library and related environment variables mentioned in Amazon S3 Storage gcs - uses the GCS client library and related environment variables mentioned in Google Cloud Storage azure - uses the Azure client library and related environment variables mentioned in Microsoft Azure Storage Default: empty string (' '), which defaults to local Description: Sets the storage provider. Amazon S3 Storage‚Äã S3_ACCESS_KEY_ID‚Äã Type: str Description: Sets the access key ID for S3 storage. S3_ADDRESSING_STYLE‚Äã Type: str Default: None Description: Specifies the addressing style to use for S3 storage (e.g., 'path', 'virtual'). S3_BUCKET_NAME‚Äã Type: str Description: Sets the bucket name for S3 storage. S3_ENDPOINT_URL‚Äã Type: str Description: Sets the endpoint URL for S3 storage. infoIf the endpoint is an S3-compatible provider like MinIO that uses a TLS certificate signed by a private CA, set the environment variable AWS_CA_BUNDLE to the path of your PEM-encoded CA certificates file. See the Amazon SDK Docs for more information. S3_KEY_PREFIX‚Äã Type: str Description: Sets the key prefix for a S3 object. S3_REGION_NAME‚Äã Type: str Description: Sets the region name for S3 storage. S3_SECRET_ACCESS_KEY‚Äã Type: str Description: Sets the secret access key for S3 storage. S3_USE_ACCELERATE_ENDPOINT‚Äã Type: str Default: False Description: Specifies whether to use the accelerated endpoint for S3 storage. S3_ENABLE_TAGGING‚Äã Type: str Default: False Description: Enables S3 object tagging after uploads for better organization, searching, and integration with file management policies. Always set to False when using Cloudflare R2, as R2 does not support object tagging. Google Cloud Storage‚Äã GOOGLE_APPLICATION_CREDENTIALS_JSON‚Äã Type: str Description: Contents of Google Application Credentials JSON file. Optional - if not provided, credentials will be taken from the environment. User credentials if run locally and Google Metadata server if run on a Google Compute Engine. A file can be generated for a service account following this guide. GCS_BUCKET_NAME‚Äã Type: str Description: Sets the bucket name for Google Cloud Storage. Bucket must already exist. Microsoft Azure Storage‚Äã AZURE_STORAGE_ENDPOINT‚Äã Type: str Description: Sets the endpoint URL for Azure Storage. AZURE_STORAGE_CONTAINER_NAME‚Äã Type: str Description: Sets the container name for Azure Storage. AZURE_STORAGE_KEY‚Äã Type: str Description: Set the access key for Azure Storage. Optional - if not provided, credentials will be taken from the environment. User credentials if run locally and Managed Identity if run in Azure services. OpenTelemetry Configuration‚Äã ENABLE_OTEL‚Äã Type: bool Default: False Description: Enables or disables OpenTelemetry for observability. When enabled, tracing, metrics, and logging data can be collected and exported to an OTLP endpoint. ENABLE_OTEL_TRACES‚Äã Type: bool Default: False Description: Enables or disables OpenTelemetry traces collection and export. This variable works in conjunction with ENABLE_OTEL. ENABLE_OTEL_METRICS‚Äã Type: bool Default: False Description: Enables or disables OpenTelemetry metrics collection and export. This variable works in conjunction with ENABLE_OTEL. ENABLE_OTEL_LOGS‚Äã Type: bool Default: False Description: Enables or disables OpenTelemetry logging export. When enabled, application logs are sent to the configured OTLP endpoint. This variable works in conjunction with ENABLE_OTEL. OTEL_EXPORTER_OTLP_ENDPOINT‚Äã Type: str Default: http://localhost:4317 Description: Specifies the default OTLP (OpenTelemetry Protocol) endpoint for exporting traces, metrics, and logs. This can be overridden for metrics if OTEL_METRICS_EXPORTER_OTLP_ENDPOINT is set, and for logs if OTEL_LOGS_EXPORTER_OTLP_ENDPOINT is set. OTEL_METRICS_EXPORTER_OTLP_ENDPOINT‚Äã Type: str Default: Value of OTEL_EXPORTER_OTLP_ENDPOINT Description: Specifies the dedicated OTLP endpoint for exporting OpenTelemetry metrics. If not set, it defaults to the value of OTEL_EXPORTER_OTLP_ENDPOINT. This is useful when separate endpoints for traces and metrics are used. OTEL_LOGS_EXPORTER_OTLP_ENDPOINT‚Äã Type: str Default: Value of OTEL_EXPORTER_OTLP_ENDPOINT Description: Specifies the dedicated OTLP endpoint for exporting OpenTelemetry logs. If not set, it defaults to the value of OTEL_EXPORTER_OTLP_ENDPOINT. This is useful when separate endpoints for logs, traces, and metrics are used. OTEL_EXPORTER_OTLP_INSECURE‚Äã Type: bool Default: False Description: If set to True, the OTLP exporter will use an insecure connection (e.g., HTTP for gRPC) for traces. For metrics, its behavior is governed by OTEL_METRICS_EXPORTER_OTLP_INSECURE, and for logs by OTEL_LOGS_EXPORTER_OTLP_INSECURE. OTEL_METRICS_EXPORTER_OTLP_INSECURE‚Äã Type: bool Default: Value of OTEL_EXPORTER_OTLP_INSECURE Description: If set to True, the OTLP exporter will use an insecure connection for metrics. If not specified, it uses the value of OTEL_EXPORTER_OTLP_INSECURE. OTEL_LOGS_EXPORTER_OTLP_INSECURE‚Äã Type: bool Default: Value of OTEL_EXPORTER_OTLP_INSECURE Description: If set to True, the OTLP exporter will use an insecure connection for logs. If not specified, it uses the value of OTEL_EXPORTER_OTLP_INSECURE. OTEL_SERVICE_NAME‚Äã Type: str Default: open-webui Description: Sets the service name that will be reported to your OpenTelemetry collector or observability platform. This helps identify your Open WebUI instance. OTEL_RESOURCE_ATTRIBUTES‚Äã Type: str Default: Empty string (' ') Description: Allows you to define additional resource attributes to be attached to all telemetry data, in a comma-separated key1=val1,key2=val2 format. OTEL_TRACES_SAMPLER‚Äã Type: str Options: parentbased_always_on, always_on, always_off, parentbased_always_off, etc. Default: parentbased_always_on Description: Configures the sampling strategy for OpenTelemetry traces. This determines which traces are collected and exported to reduce data volume. OTEL_BASIC_AUTH_USERNAME‚Äã Type: str Default: Empty string (' ') Description: Sets the username for basic authentication with the default OTLP endpoint. This applies to traces, and by default, to metrics and logs unless overridden by their specific authentication variables. OTEL_BASIC_AUTH_PASSWORD‚Äã Type: str Default: Empty string (' ') Description: Sets the password for basic authentication with the default OTLP endpoint. This applies to traces, and by default, to metrics and logs unless overridden by their specific authentication variables. OTEL_METRICS_BASIC_AUTH_USERNAME‚Äã Type: str Default: Value of OTEL_BASIC_AUTH_USERNAME Description: Sets the username for basic authentication specifically for the OTLP metrics endpoint. If not specified, it uses the value of OTEL_BASIC_AUTH_USERNAME. OTEL_METRICS_BASIC_AUTH_PASSWORD‚Äã Type: str Default: Value of OTEL_BASIC_AUTH_PASSWORD Description: Sets the password for basic authentication specifically for the OTLP metrics endpoint. If not specified, it uses the value of OTEL_BASIC_AUTH_PASSWORD. OTEL_LOGS_BASIC_AUTH_USERNAME‚Äã Type: str Default: Value of OTEL_BASIC_AUTH_USERNAME Description: Sets the username for basic authentication specifically for the OTLP logs endpoint. If not specified, it uses the value of OTEL_BASIC_AUTH_USERNAME. OTEL_LOGS_BASIC_AUTH_PASSWORD‚Äã Type: str Default: Value of OTEL_BASIC_AUTH_PASSWORD Description: Sets the password for basic authentication specifically for the OTLP logs endpoint. If not specified, it uses the value of OTEL_BASIC_AUTH_PASSWORD. OTEL_OTLP_SPAN_EXPORTER‚Äã Type: str Options: grpc, http Default: grpc Description: Specifies the default protocol for exporting OpenTelemetry traces (gRPC or HTTP). This can be overridden for metrics if OTEL_METRICS_OTLP_SPAN_EXPORTER is set, and for logs if OTEL_LOGS_OTLP_SPAN_EXPORTER is set. OTEL_METRICS_OTLP_SPAN_EXPORTER‚Äã Type: str Options: grpc, http Default: Value of OTEL_OTLP_SPAN_EXPORTER Description: Specifies the protocol for exporting OpenTelemetry metrics (gRPC or HTTP). If not specified, it uses the value of OTEL_OTLP_SPAN_EXPORTER. OTEL_LOGS_OTLP_SPAN_EXPORTER‚Äã Type: str Options: grpc, http Default: Value of OTEL_OTLP_SPAN_EXPORTER Description: Specifies the protocol for exporting OpenTelemetry logs (gRPC or HTTP). If not specified, it uses the value of OTEL_OTLP_SPAN_EXPORTER. Database Pool‚Äã DATABASE_URL‚Äã Type: str Default: sqlite:///${DATA_DIR}/webui.db Description: Specifies the complete database connection URL, following SQLAlchemy's URL scheme. This variable takes precedence over individual database connection parameters if explicitly set. infoFor PostgreSQL support, ensure you installed with pip install open-webui[all] instead of the basic installation. Supports SQLite, Postgres, and encrypted SQLite via SQLCipher. Changing the URL does not migrate data between databases.Documentation on the URL scheme is available here.If your database password contains special characters, please ensure they are properly URL-encoded. For example, a password like p@ssword should be encoded as p%40ssword.For configuration using individual parameters or encrypted SQLite, see the relevant sections below. warningRequired for Multi-Replica Setups For multi-replica or high-availability deployments (Kubernetes, Docker Swarm), you MUST use an external database (PostgreSQL) instead of SQLite. SQLite does not support concurrent writes from multiple instances and will result in database corruption or data inconsistency. DATABASE_TYPE‚Äã Type: str Default: None (automatically set to sqlite if DATABASE_URL uses default SQLite path) Description: Specifies the database type (e.g., sqlite, postgresql, sqlite+sqlcipher). This is used in conjunction with other individual parameters to construct the DATABASE_URL if a complete DATABASE_URL is not explicitly defined. Persistence: No DATABASE_USER‚Äã Type: str Default: None Description: Specifies the username for database authentication. This is used to construct the DATABASE_URL when a complete DATABASE_URL is not explicitly defined. Persistence: No DATABASE_PASSWORD‚Äã Type: str Default: None Description: Specifies the password for database authentication. This is used to construct the DATABASE_URL when a complete DATABASE_URL is not explicitly defined. If your password contains special characters, please ensure they are properly URL-encoded. Persistence: No DATABASE_HOST‚Äã Type: str Default: None Description: Specifies the hostname or IP address of the database server. This is used to construct the DATABASE_URL when a complete DATABASE_URL is not explicitly defined. Persistence: No DATABASE_PORT‚Äã Type: int Default: None Description: Specifies the port number of the database server. This is used to construct the DATABASE_URL when a complete DATABASE_URL is not explicitly defined. Persistence: No DATABASE_NAME‚Äã Type: str Default: None Description: Specifies the name of the database to connect to. This is used to construct the DATABASE_URL when a complete DATABASE_URL is not explicitly defined. Persistence: No infoWhen DATABASE_URL is not explicitly set, Open WebUI will attempt to construct it using a combination of DATABASE_TYPE, DATABASE_USER, DATABASE_PASSWORD, DATABASE_HOST, DATABASE_PORT, and DATABASE_NAME. For this automatic construction to occur, all of these individual parameters must be provided. If any are missing, the default DATABASE_URL (SQLite file) or any explicitly set DATABASE_URL will be used instead. DATABASE_USER_ACTIVE_STATUS_UPDATE_INTERVAL‚Äã Type: float Default: None Description: Sets the minimum time interval in seconds between user active status updates in the database. Helps reduce write operations for high-traffic instances. Set to 0.0 to update on every activity. Encrypted SQLite with SQLCipher‚Äã For enhanced security, Open WebUI supports at-rest encryption for its primary SQLite database using SQLCipher. This is recommended for deployments handling sensitive data where using a larger database like PostgreSQL is not needed. Additional Dependencies RequiredSQLCipher encryption requires additional dependencies that are not included by default. Before using this feature, you must install: The SQLCipher system library (e.g., libsqlcipher-dev on Debian/Ubuntu, sqlcipher on macOS via Homebrew) The sqlcipher3-wheels Python package (pip install sqlcipher3-wheels) For Docker users, this means building a custom image with these dependencies included. To enable encryption, you must configure two environment variables: Set DATABASE_TYPE="sqlite+sqlcipher". Set DATABASE_PASSWORD="your-secure-password". When these are set and a full DATABASE_URL is not explicitly defined, Open WebUI will automatically create and use an encrypted database file at ./data/webui.db. danger The DATABASE_PASSWORD environment variable is required when using sqlite+sqlcipher. The DATABASE_TYPE variable tells Open WebUI which connection logic to use. Setting it to sqlite+sqlcipher activates the encryption feature. Ensure the database password is kept secure, as it is needed to decrypt and access all application data. DATABASE_SCHEMA‚Äã Type: str Default: None Description: Specifies the database schema to connect to. DATABASE_POOL_SIZE‚Äã Type: int Default: None Description: Specifies the pooling strategy and size of the database pool. By default SQLAlchemy will automatically chose the proper pooling strategy for the selected database connection. A value of 0 disables pooling. A value larger 0 will set the pooling strategy to QueuePool and the pool size accordingly. DATABASE_POOL_MAX_OVERFLOW‚Äã Type: int Default: 0 Description: Specifies the database pool max overflow. infoMore information about this setting can be found here. DATABASE_POOL_TIMEOUT‚Äã Type: int Default: 30 Description: Specifies the database pool timeout in seconds to get a connection. infoMore information about this setting can be found here. DATABASE_POOL_RECYCLE‚Äã Type: int Default: 3600 Description: Specifies the database pool recycle time in seconds. infoMore information about this setting can be found here. DATABASE_ENABLE_SQLITE_WAL‚Äã Type: bool Default: False Description: Enables or disables SQLite WAL (Write-Ahead Logging) mode. When enabled, SQLite transactions can be managed more efficiently, allowing multiple readers and one writer concurrently, which can improve database performance, especially under high concurrency. This setting only applies to SQLite databases. DATABASE_DEDUPLICATE_INTERVAL‚Äã Type: float Default: 0.0 Description: Sets a time interval in seconds during which certain database write operations (e.g., updating a user's last_active_at timestamp) will be deduplicated. If a write operation is attempted within this interval for the same entity, it will be skipped. A value of 0.0 disables deduplication. Enabling this can reduce write conflicts and improve performance, but may result in less real-time accuracy for the affected fields. Redis‚Äã Type: str Description: Specifies the URL of the Redis instance or cluster host for storing application state. Examples: redis://localhost:6379/0 rediss://:password@localhost:6379/0 (with password and TLS) rediss://redis-cluster.redis.svc.cluster.local:6379/0?ssl_cert_reqs=required&ssl_certfile=/tls/redis/tls.crt&ssl_keyfile=/tls/redis/tls.key&ssl_ca_certs=/tls/redis/ca.crt (with mTLS) warningRequired for Multi-Worker and Multi-Node DeploymentsWhen deploying Open WebUI with UVICORN_WORKERS > 1 or in a multi-node/worker cluster with a load balancer (e.g. helm/kubectl/kubernetes/k8s, you must set the REDIS_URL value. Without it, the following issues will occur: Session management will fail across workers Application state will be inconsistent between instances Websocket connections will not function properly in distributed setups Users may experience intermittent authentication failures Redis serves as the central state store that allows multiple Open WebUI instances to coordinate and share critical application data. infoSingle Instance DeploymentsIf you're running Open WebUI as a single instance with UVICORN_WORKERS=1 (the default), Redis is not required. The application will function normally without it. REDIS_SENTINEL_HOSTS‚Äã Type: str Description: Comma-separated list of Redis Sentinels for app state. If specified, the "hostname" in REDIS_URL will be interpreted as the Sentinel service name. REDIS_SENTINEL_PORT‚Äã Type: int Default: 26379 Description: Sentinel port for app state Redis. REDIS_CLUSTER‚Äã Type: bool Default: False Description: Connect to a Redis Cluster instead of a single instance or using Redis Sentinels. If True, REDIS_URL must also be defined. infoThis option has no effect if REDIS_SENTINEL_HOSTS is defined. REDIS_KEY_PREFIX‚Äã Type: str Default: open-webui Description: Customizes the Redis key prefix used for storing configuration values. This allows multiple Open WebUI instances to share the same Redis instance without key conflicts. When operating in Redis cluster mode, the prefix is formatted as {prefix}: (e.g., {open-webui}:config:*) to enable multi-key operations on configuration keys within the same hash slot. REDIS_SOCKET_CONNECT_TIMEOUT‚Äã Type: float (seconds) or empty string for None Default: None (no timeout, uses redis-py library default) Description: Sets the socket connection timeout in seconds for Redis and Sentinel connections. This timeout applies to the initial TCP connection establishment. When set, it prevents indefinite blocking when attempting to connect to unreachable Redis nodes. dangerCritical for Redis Sentinel DeploymentsWithout a socket connection timeout, Redis Sentinel failover can cause the application to hang indefinitely when a master node goes offline. The application may become completely unresponsive and even fail to restart.For Sentinel deployments, it is strongly recommended to set this value (e.g., REDIS_SOCKET_CONNECT_TIMEOUT=5). warningInteraction with WEBSOCKET_REDIS_OPTIONSIf you explicitly set WEBSOCKET_REDIS_OPTIONS, this variable will not apply to the AsyncRedisManager used for websocket communication. In that case, you must include socket_connect_timeout directly within WEBSOCKET_REDIS_OPTIONS:WEBSOCKET_REDIS_OPTIONS='{"socket_connect_timeout": 5}'If WEBSOCKET_REDIS_OPTIONS is not set, REDIS_SOCKET_CONNECT_TIMEOUT will be applied to websocket connections automatically. ENABLE_WEBSOCKET_SUPPORT‚Äã Type: bool Default: True Description: Enables websocket support in Open WebUI. warningRequired for Multi-Worker and Multi-Node DeploymentsWhen deploying Open WebUI with UVICORN_WORKERS > 1 or in a multi-node/worker cluster with a load balancer (e.g. helm/kubectl/kubernetes/k8s, you must set this variable. Without it, the following issues will occur: Session management will fail across workers Application state will be inconsistent between instances Websocket connections will not function properly in distributed setups Users may experience intermittent authentication failures WEBSOCKET_MANAGER‚Äã Type: str Default: "" (empty string) Description: Specifies the websocket manager to use. Allowed values include: redis warningRequired for Multi-Worker and Multi-Node DeploymentsWhen deploying Open WebUI with UVICORN_WORKERS > 1 or in a multi-node/worker cluster with a load balancer (e.g. helm/kubectl/kubernetes/k8s, you must set this variable. Without it, the following issues will occur: Session management will fail across workers Application state will be inconsistent between instances Websocket connections will not function properly in distributed setups Users may experience intermittent authentication failures WEBSOCKET_REDIS_URL‚Äã Type: str Default: ${REDIS_URL} Description: Specifies the URL of the Redis instance or cluster host for websocket communication. It is distinct from REDIS_URL and in practice, it is recommended to set both. warningRequired for Multi-Worker and Multi-Node DeploymentsWhen deploying Open WebUI with UVICORN_WORKERS > 1 or in a multi-node/worker cluster with a load balancer (e.g. helm/kubectl/kubernetes/k8s, you must set this variable. Without it, the following issues will occur: Session management will fail across workers Application state will be inconsistent between instances Websocket connections will not function properly in distributed setups Users may experience intermittent authentication failures WEBSOCKET_SENTINEL_HOSTS‚Äã Type: str Description: Comma-separated list of Redis Sentinels for websocket. If specified, the "hostname" in WEBSOCKET_REDIS_URL will be interpreted as the Sentinel service name. WEBSOCKET_SENTINEL_PORT‚Äã Type: int Default: 26379 Description: Sentinel port for websocket Redis. WEBSOCKET_REDIS_CLUSTER‚Äã Type: bool Default: ${REDIS_CLUSTER} Description: Specifies that websocket should communicate with a Redis Cluster instead of a single instance or using Redis Sentinels. If True, WEBSOCKET_REDIS_URL and/or REDIS_URL must also be defined. infoThis option has no effect if WEBSOCKET_SENTINEL_HOSTS is defined. WEBSOCKET_REDIS_OPTIONS‚Äã Type: str Default: {} (empty, which allows REDIS_SOCKET_CONNECT_TIMEOUT to apply if set) Description: A string representation of a dictionary containing additional Redis connection options for the websocket Redis client (AsyncRedisManager). This allows you to specify advanced connection parameters such as SSL settings, timeouts, or other Redis client configurations that are not covered by the standard WEBSOCKET_REDIS_URL. The string should be formatted as valid JSON. For example: {"retry_on_timeout": true, "socket_connect_timeout": 5, "socket_timeout": 5, "max_connections": 8}. All JSON encodable options listed here can be used. warningAWS SSM and Docker compose cannot ingest raw JSON, as such you need to escape any double quotes like the following: {\"retry_on_timeout\": true, \"socket_connect_timeout\": 5, \"socket_timeout\": 5, \"max_connections\": 8} infoPrecedence with REDIS_SOCKET_CONNECT_TIMEOUTWhen this variable is left empty (default), REDIS_SOCKET_CONNECT_TIMEOUT is automatically applied to websocket connections if set. However, if you explicitly set WEBSOCKET_REDIS_OPTIONS to any value, REDIS_SOCKET_CONNECT_TIMEOUT will not be injected‚Äîyou must include socket_connect_timeout manually within this JSON if needed. WEBSOCKET_SERVER_LOGGING‚Äã Type: bool Default: false Description: Controls logging for SocketIO server related to websocket operations. warningThis can be very verbose, it is only recommended to use this flag when debugging Redis related issues. WEBSOCKET_SERVER_ENGINEIO_LOGGING‚Äã Type: bool Default: false Description: Controls logging for EngineIO server related to websocket operations. warningThis can be very verbose, it is only recommended to use this flag when debugging Redis related issues. WEBSOCKET_SERVER_PING_TIMEOUT‚Äã Type: int Default: 20 Description: The timeout for a ping to Redis in seconds. WEBSOCKET_SERVER_PING_INTERVAL‚Äã Type: int Default: 25 Description: The frequency for a ping to Redis in seconds. ENABLE_STAR_SESSIONS_MIDDLEWARE‚Äã Type: bool Default: False Description: Enables Redis-based session storage for OAuth authentication flows using the StarSessions middleware. When enabled, OAuth session state is stored in Redis instead of browser cookies, which can help resolve CSRF errors in multi-replica deployments where session data needs to be shared across pods. Experimental feature that enables Redis-based session storage for OAuth flows using StarSessions middleware, helping resolve CSRF errors in multi-replica deployments. Persistence: This is an experimental environment variable. warningExperimental Feature - Known LimitationsThis feature is currently experimental and has known compatibility issues: Redis Sentinel and Redis Cluster configurations are not yet supported and will cause authentication failures if this setting is enabled Only basic Redis setups (single instance or standard Redis URL) are currently compatible This feature was introduced to address CSRF "mismatching_state" errors in multi-pod deployments, but it is disabled by default due to ongoing compatibility work Only enable this setting if: You are experiencing persistent CSRF errors during OAuth login in a multi-replica deployment You are using a basic Redis setup (not Sentinel or Cluster) You have confirmed that WEBUI_SECRET_KEY is set to the same value across all replicas You understand this is an experimental feature that may change or be removed in future releases For most deployments, the default browser cookie-based session management is sufficient and more stable. Uvicorn Settings‚Äã UVICORN_WORKERS‚Äã Type: int Default: 1 Description: Controls the number of worker processes that Uvicorn spawns to handle requests. Each worker runs its own instance of the application in a separate process. infoWhen deploying in orchestrated environments like Kubernetes or using Helm charts, it's recommended to keep UVICORN_WORKERS set to 1. Container orchestration platforms already provide their own scaling mechanisms through pod replication, and using multiple workers inside containers can lead to resource allocation issues and complicate horizontal scaling strategies.If you use UVICORN_WORKERS, you also need to ensure that related environment variables for scalable multi-worker setups are set accordingly. Database Migrations with Multiple WorkersWhen UVICORN_WORKERS > 1, starting the application can trigger concurrent database migrations from multiple worker processes, potentially causing database schema corruption or inconsistent states.Recommendation: After pulling a new image or installing an update, always run Open WebUI with a single worker (UVICORN_WORKERS=1) first. This ensures the database migration completes successfully in a single process. Once the migration is finished and the application has started, you can then restart it with your desired number of workers.For Kubernetes, Helm, Minikube, and other orchestrated setups: Ensure that your deployment strategy allows for a single-replica or single-worker init container/job to handle migrations before scaling up to multiple replicas or workers. This is critical to prevent race conditions during schema updates. Cache Settings‚Äã CACHE_CONTROL‚Äã Type: str Default: Not set (no Cache-Control header added) Description: Sets the Cache-Control header for all HTTP responses. Supports standard directives like public, private, no-cache, no-store, must-revalidate, max-age=seconds, etc. If an invalid value is provided, defaults to "no-store, max-age=0" (no caching). Examples: "private, max-age=86400" - Cache privately for 24 hours "public, max-age=3600, must-revalidate" - Cache publicly for 1 hour, then revalidate "no-cache, no-store, must-revalidate" - Never cache Proxy Settings‚Äã Open WebUI supports using proxies for HTTP and HTTPS retrievals. To specify proxy settings, Open WebUI uses the following environment variables: http_proxy‚Äã Type: str Description: Sets the URL for the HTTP proxy. https_proxy‚Äã Type: str Description: Sets the URL for the HTTPS proxy. no_proxy‚Äã Type: str Description: Lists domain extensions (or IP addresses) for which the proxy should not be used, separated by commas. For example, setting no_proxy to '.mit.edu' ensures that the proxy is bypassed when accessing documents from MIT. Install Required Python Packages‚Äã Open WebUI provides environment variables to customize the pip installation process. Below are the environment variables used by Open WebUI for adjusting package installation behavior: PIP_OPTIONS‚Äã Type: str Description: Specifies additional command-line options that pip should use when installing packages. For example, you can include flags such as --upgrade, --user, or --no-cache-dir to control the installation process. PIP_PACKAGE_INDEX_OPTIONS‚Äã Type: str Description: Defines custom package index behavior for pip. This can include specifying additional or alternate index URLs (e.g., --extra-index-url), authentication credentials, or other parameters to manage how packages are retrieved from different locations.

```
PersistentConfig
```

### Example Code Patterns

**Example 1** (bash):
```bash
curl -H "Authorization: Bearer YOUR_API_KEY" http://localhost:3000/api/models
```

**Example 2** (bash):
```bash
curl -H "Authorization: Bearer YOUR_API_KEY" http://localhost:3000/api/models
```

**Example 3** (bash):
```bash
# Find your database location firstdocker inspect open-webui | grep -A 5 Mounts# Create timestamped backupcp /path/to/webui.db /path/to/webui.db.backup.$(date +%Y%m%d_%H%M%S)
```

**Example 4** (bash):
```bash
pg_dump -h localhost -U your_user -d open_webui_db > backup_$(date +%Y%m%d_%H%M%S).sql
```

**Example 5** (bash):
```bash
docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
```

## Reference Files

This skill includes comprehensive documentation in `references/`:

- **category.md** - Category documentation
- **features.md** - Features documentation
- **integrations.md** - Integrations documentation
- **other.md** - Other documentation
- **tutorials.md** - Tutorials documentation
- **web-search.md** - Web-Search documentation

Use `view` to read specific reference files when detailed information is needed.

## Working with This Skill

### For Beginners
Start with the getting_started or tutorials reference files for foundational concepts.

### For Specific Features
Use the appropriate category reference file (api, guides, etc.) for detailed information.

### For Code Examples
The quick reference section above contains common patterns extracted from the official docs.

## Resources

### references/
Organized documentation extracted from official sources. These files contain:
- Detailed explanations
- Code examples with language annotations
- Links to original documentation
- Table of contents for quick navigation

### scripts/
Add helper scripts here for common automation tasks.

### assets/
Add templates, boilerplate, or example projects here.

## Notes

- This skill was automatically generated from official documentation
- Reference files preserve the structure and examples from source docs
- Code examples include language detection for better syntax highlighting
- Quick reference patterns are extracted from common usage examples in the docs

## Updating

To refresh this skill with updated documentation:
1. Re-run the scraper with the same configuration
2. The skill will be rebuilt with the latest information
